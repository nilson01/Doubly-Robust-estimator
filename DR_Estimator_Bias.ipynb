{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EtoqrJZNRXp"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GaGDesd3L5WP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "\n",
    "import sys\n",
    "from itertools import product\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gqa9h8xbL5Lr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khh1C95xMIRr"
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hXZ-PCnMEW6"
   },
   "source": [
    "## Simulation run utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7rhKPDQL-qI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 0. Simulation run utils\n",
    "\n",
    "\n",
    "\n",
    "def setup_logging(job_id):\n",
    "    file_name = f\"Output_DS_{job_id}.txt\"\n",
    "    logging.basicConfig(\n",
    "        filename=file_name,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FlushFile:\n",
    "    \"\"\"File-like wrapper that flushes on every write.\"\"\"\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()  # Flush output after write\n",
    "\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "\n",
    "\n",
    "\n",
    "def load_config(file_path='config.yaml'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def extract_unique_treatment_values(df, columns_to_process):\n",
    "    unique_values = {}\n",
    "\n",
    "    for key, cols in columns_to_process.items():\n",
    "        unique_values[key] = {}\n",
    "\n",
    "        for col in cols:\n",
    "            all_values = [item for sublist in df[col] for item in sublist]\n",
    "            unique_values[key][col] = set(all_values)\n",
    "\n",
    "    log_message = \"\\nUnique values:\\n\" + \"\\n\".join(f\"{k}: {v}\" for k, v in unique_values.items()) + \"\\n\"\n",
    "    logger.info(log_message)\n",
    "\n",
    "    return unique_values\n",
    "\n",
    "\n",
    "def save_simulation_data(global_df, all_losses_dicts, all_epoch_num_lists, results, folder):\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Define paths for saving files\n",
    "    df_path = os.path.join(folder, 'simulation_data.pkl')\n",
    "    losses_path = os.path.join(folder, 'losses_dicts.pkl')\n",
    "    epochs_path = os.path.join(folder, 'epoch_num_lists.pkl')\n",
    "    results_path = os.path.join(folder, 'simulation_results.pkl')\n",
    "\n",
    "    # Save DataFrame\n",
    "    # global_df.to_csv(df_path, index=False)\n",
    "    with open(df_path, 'wb') as f:\n",
    "        pickle.dump(global_df, f)\n",
    "\n",
    "    # Save lists and dictionaries with pickle\n",
    "\n",
    "    with open(losses_path, 'wb') as f:\n",
    "        pickle.dump(all_losses_dicts, f)\n",
    "    with open(epochs_path, 'wb') as f:\n",
    "        pickle.dump(all_epoch_num_lists, f)\n",
    "    with open(results_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    logger.info(\"Data saved successfully in the folder: %s\", folder)\n",
    "\n",
    "\n",
    "def save_results_to_dataframe(results, folder):\n",
    "    data = {\n",
    "        \"Configuration\": [],\n",
    "        \"Accuracy_A1\": [],\n",
    "        \"Accuracy_A2\": [],\n",
    "        \"Behavioral Value fn.\": [],\n",
    "        \"Method's Value fn.\": [],\n",
    "        \"Optimal Value fn.\": []\n",
    "    }\n",
    "\n",
    "    for config_key, performance in results.items():\n",
    "        data[\"Configuration\"].append(config_key)\n",
    "        data[\"Accuracy_A1\"].append(performance.get(\"Accuracy_A1\", None))\n",
    "        data[\"Accuracy_A2\"].append(performance.get(\"Accuracy_A2\", None))\n",
    "        data[\"Behavioral Value fn.\"].append(performance.get(\"Behavioral Value fn.\", None))\n",
    "        data[\"Method's Value fn.\"].append(performance.get(\"Method's Value fn.\", None))\n",
    "        data[\"Optimal Value fn.\"].append(performance.get(\"Optimal Value fn.\", None))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Sort the DataFrame by 'Method's Value fn.' in descending order\n",
    "    df = df.sort_values(by=\"Method's Value fn.\", ascending=False)\n",
    "\n",
    "    df.to_csv(f'{folder}/configurations_performance.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_and_process_data(params, folder):\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Define paths to the files\n",
    "    df_path = os.path.join(folder, 'simulation_data.pkl')\n",
    "    losses_path = os.path.join(folder, 'losses_dicts.pkl')\n",
    "    epochs_path = os.path.join(folder, 'epoch_num_lists.pkl')\n",
    "    results_path = os.path.join(folder, 'simulation_results.pkl')\n",
    "\n",
    "    # Load DataFrame\n",
    "    # global_df = pd.read_csv(df_path)\n",
    "    with open(df_path, 'rb') as f:\n",
    "        global_df = pickle.load(f)\n",
    "\n",
    "    # Load lists and dictionaries with pickle\n",
    "    with open(losses_path, 'rb') as f:\n",
    "        all_losses_dicts = pickle.load(f)\n",
    "    with open(epochs_path, 'rb') as f:\n",
    "        all_epoch_num_lists = pickle.load(f)\n",
    "    with open(results_path, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    # Extract and process unique values\n",
    "    columns_to_process = {\n",
    "        'Predicted': ['Predicted_A1', 'Predicted_A2'],\n",
    "        'Optimal': ['Optimal_A1', 'Optimal_A2']\n",
    "    }\n",
    "    # unique_values = extract_unique_treatment_values(global_df, columns_to_process)\n",
    "\n",
    "    # Process and plot results from all simulations\n",
    "    for i, losses_dict in enumerate(all_losses_dicts):\n",
    "        run_name = f\"Simulation run trainVval_{i}\"\n",
    "        selected_indices = [i for i in range(params['num_replications'])]\n",
    "        if  params['f_model'] == 'surr_opt' :\n",
    "            plot_simulation_surLoss_losses_in_grid(selected_indices, losses_dict, params['n_epoch'], run_name, folder)\n",
    "        else:\n",
    "            plot_simulation_Qlearning_losses_in_grid(selected_indices, losses_dict, run_name, folder)\n",
    "\n",
    "    # Print results for each configuration\n",
    "    logger.info(\"\\n\\n\")\n",
    "    for config_key, performance in results.items():\n",
    "        logger.info(\"Configuration: %s\\nAverage Performance:\\n %s\\n\", config_key, performance.to_string(index=True, header=False))\n",
    "\n",
    "    # Call the function to plot value functions\n",
    "    df = save_results_to_dataframe(results, folder)\n",
    "    # plot_value_functions(results, folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3iIfT8mrL-tS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii4ez6YnMK1j"
   },
   "source": [
    "## DGP utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPwTQd7KL-u5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. DGP utils\n",
    "\n",
    "def A_sim(matrix_pi, stage):\n",
    "    N, K = matrix_pi.shape  # sample size and treatment options\n",
    "    if N <= 1 or K <= 1:\n",
    "        logger.error(\"Sample size or treatment options are insufficient! N: %d, K: %d\", N, K)\n",
    "        raise ValueError(\"Sample size or treatment options are insufficient!\")\n",
    "    if torch.any(matrix_pi < 0):\n",
    "        logger.error(\"Treatment probabilities should not be negative!\")\n",
    "        raise ValueError(\"Treatment probabilities should not be negative!\")\n",
    "\n",
    "    # Normalize probabilities to add up to 1 and simulate treatment A for each row\n",
    "    pis = matrix_pi.sum(dim=1, keepdim=True)\n",
    "    probs = matrix_pi / pis\n",
    "    A = torch.multinomial(probs, 1).squeeze()\n",
    "\n",
    "    if stage == 1:\n",
    "        col_names = ['pi_10', 'pi_11', 'pi_12']\n",
    "    else:\n",
    "        col_names = ['pi_20', 'pi_21', 'pi_22']\n",
    "\n",
    "    probs_dict = {name: probs[:, idx] for idx, name in enumerate(col_names)}\n",
    "\n",
    "    return {'A': A, 'probs': probs_dict}\n",
    "\n",
    "def transform_Y(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Adjusts Y1 and Y2 values to ensure they are non-negative.\n",
    "    \"\"\"\n",
    "    # Identify the minimum value among Y1 and Y2, only if they are negative\n",
    "    min_negative_Y = torch.min(torch.cat([Y1, Y2])).item()\n",
    "    if min_negative_Y < 0:\n",
    "        Y1_trans = Y1 - min_negative_Y + 1\n",
    "        Y2_trans = Y2 - min_negative_Y + 1\n",
    "    else:\n",
    "        Y1_trans = Y1\n",
    "        Y2_trans = Y2\n",
    "\n",
    "    return Y1_trans, Y2_trans\n",
    "\n",
    "\n",
    "\n",
    "def M_propen(A, Xs, stage):\n",
    "    \"\"\"Estimate propensity scores using logistic or multinomial regression.\"\"\"\n",
    "    A = np.asarray(A).reshape(-1, 1)\n",
    "    if A.shape[1] != 1:\n",
    "        raise ValueError(\"Cannot handle multiple stages of treatments together!\")\n",
    "    if A.shape[0] != Xs.shape[0]:\n",
    "        print(\"A.shape, Xs.shape: \", A.shape, Xs.shape)\n",
    "        raise ValueError(\"A and Xs do not match in dimension!\")\n",
    "    if len(np.unique(A)) <= 1:\n",
    "        raise ValueError(\"Treatment options are insufficient!\")\n",
    "\n",
    "    # Handle multinomial case using Logistic Regression\n",
    "    encoder = OneHotEncoder(sparse_output=False)  # Updated parameter name\n",
    "    A_encoded = encoder.fit_transform(A)\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    # Suppressing warnings from the solver, if not converged\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "        model.fit(Xs, A.ravel())\n",
    "\n",
    "    # Predicting probabilities\n",
    "    s_p = model.predict_proba(Xs)\n",
    "\n",
    "    if stage == 1:\n",
    "        col_names = ['pi_10', 'pi_11', 'pi_12']\n",
    "    else:\n",
    "        col_names = ['pi_20', 'pi_21', 'pi_22']\n",
    "\n",
    "    #probs_df = pd.DataFrame(s_p, columns=col_names)\n",
    "    #probs_df = {name: s_p[:, idx] for idx, name in enumerate(col_names)}\n",
    "    probs_dict = {name: torch.tensor(s_p[:, idx], dtype=torch.float32) for idx, name in enumerate(col_names)}\n",
    "\n",
    "    return probs_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G0xKAxL-L-xm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ssk_EAnMSBV"
   },
   "source": [
    "## Neural networks utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mefjw1wUL-za"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Neural networks utils\n",
    "\n",
    "\n",
    "def initialize_nn(params, stage):\n",
    "    nn = NNClass(\n",
    "        input_dim=params[f'input_dim_stage{stage}'],\n",
    "        hidden_dim=params[f'hidden_dim_stage{stage}'],\n",
    "        output_dim=params[f'output_dim_stage{stage}'],\n",
    "        num_networks=params['num_networks'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        activation_fn_name=params['activation_function'],\n",
    "        num_hidden_layers=params['num_layers'] - 1  # num_layers is the number of hidden layers\n",
    "    ).to(params['device'])\n",
    "    return nn\n",
    "\n",
    "\n",
    "\n",
    "def batches(N, batch_size, seed=0):\n",
    "    # Set the seed for PyTorch random number generator for reproducibility\n",
    "    # torch.manual_seed(seed)\n",
    "\n",
    "    # Create a tensor of indices from 0 to N-1\n",
    "    indices = torch.arange(N)\n",
    "\n",
    "    # Shuffle the indices\n",
    "    indices = indices[torch.randperm(N)]\n",
    "\n",
    "    # Yield batches of indices\n",
    "    for start_idx in range(0, N, batch_size):\n",
    "        batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "        yield batch_indices\n",
    "\n",
    "\n",
    "class NNClass(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate, activation_fn_name, num_hidden_layers):\n",
    "        super(NNClass, self).__init__()\n",
    "        self.networks = nn.ModuleList()\n",
    "\n",
    "        # Map the string name to the actual activation function class\n",
    "        if activation_fn_name.lower() == 'elu':\n",
    "            activation_fn = nn.ELU\n",
    "        elif activation_fn_name.lower() == 'relu':\n",
    "            activation_fn = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation_fn_name}\")\n",
    "\n",
    "        for _ in range(num_networks):\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(activation_fn())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            for _ in range(num_hidden_layers):  # Adjusting the hidden layers count\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(activation_fn())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            layers.append(nn.BatchNorm1d(output_dim))\n",
    "\n",
    "            network = nn.Sequential(*layers)\n",
    "            self.networks.append(network)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for network in self.networks:\n",
    "            outputs.append(network(x))\n",
    "        return outputs\n",
    "\n",
    "    def he_initializer(self):\n",
    "        for network in self.networks:\n",
    "            for layer in network:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "    def reset_weights(self):\n",
    "        for network in self.networks:\n",
    "            for layer in network:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.constant_(layer.weight, 0.1)\n",
    "                    nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate, activation_fn_name):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "\n",
    "#         # Map the string name to the actual activation function class\n",
    "#         if activation_fn_name.lower() == 'elu':\n",
    "#             activation_fn = nn.ELU\n",
    "#         elif activation_fn_name.lower() == 'relu':\n",
    "#             activation_fn = nn.ReLU\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported activation function: {activation_fn_name}\")\n",
    "\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 activation_fn(),  # Instantiate the activation function\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.ELU(alpha=0.4),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.BatchNorm1d(hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.BatchNorm1d(hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(hidden_dim, hidden_dim),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "40MxSRTCMX73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3dooXKtMZWN"
   },
   "source": [
    "## plotting and summary utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8VHkvqTvMX-3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. plotting and summary utils\n",
    "\n",
    "\n",
    "def plot_v_values(v_dict, num_replications, train_size):\n",
    "\n",
    "    # Plotting all categories of V values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for category, values in v_dict.items():\n",
    "        plt.plot(range(1, num_replications + 1), values, 'o-', label=f'{category} Value function')\n",
    "    plt.xlabel('Replications (Total: {})'.format(num_replications))\n",
    "    plt.ylabel('Value function')\n",
    "    plt.title('Value functions for {} Test Replications (Training Size: {})'.format(num_replications, train_size))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def abbreviate_config(config):\n",
    "    abbreviations = {\n",
    "        \"activation_function\": \"AF\",\n",
    "        \"batch_size\": \"BS\",\n",
    "        \"learning_rate\": \"LR\",\n",
    "        \"num_layers\": \"NL\"\n",
    "    }\n",
    "    abbreviated_config = {abbreviations[k]: v for k, v in config.items()}\n",
    "    return str(abbreviated_config)\n",
    "\n",
    "def plot_value_functions(results, folder):\n",
    "    data = {\n",
    "        \"Configuration\": [],\n",
    "        \"Value Function\": []\n",
    "    }\n",
    "\n",
    "    for config_key, performance in results.items():\n",
    "        config_dict = json.loads(config_key)\n",
    "        abbreviated_config = abbreviate_config(config_dict)\n",
    "        data[\"Configuration\"].append(abbreviated_config)\n",
    "        data[\"Value Function\"].append(performance[\"Method's Value fn.\"])\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Sort the DataFrame by 'Value Function' in descending order\n",
    "    df = df.sort_values(by=\"Value Function\", ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df[\"Configuration\"], df[\"Value Function\"], color='skyblue')\n",
    "    plt.xlabel(\"Value Function\")\n",
    "    plt.title(\"Value Function of Each Method\")\n",
    "    plt.yticks(rotation=0)  # Rotate configuration labels to vertical\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f'{folder}/value_function_plot.png')\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "def plot_epoch_frequency(epoch_num_model_lst, n_epoch, run_name, folder='data'):\n",
    "    \"\"\"\n",
    "    Plots a bar diagram showing the frequency of each epoch number where the model was saved.\n",
    "\n",
    "    Args:\n",
    "        epoch_num_model_lst (list of int): List containing the epoch numbers where models were saved.\n",
    "        n_epoch (int): Total number of epochs for reference in the title.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each number in the list\n",
    "    frequency_counts = Counter(epoch_num_model_lst)\n",
    "\n",
    "    # Separate the keys and values for plotting\n",
    "    keys = sorted(frequency_counts.keys())\n",
    "    values = [frequency_counts[key] for key in keys]\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys, values, color='skyblue')\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'Bar Diagram of Epoch Numbers: n_epoch={n_epoch}')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"plot_epoch_frequency Plot saved as: {plot_filename}\")\n",
    "    # plt.close()  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "\n",
    "def plot_simulation_surLoss_losses_in_grid(selected_indices, losses_dict, n_epoch, run_name, folder, cols=3):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Calculate the number of rows needed based on the number of selected indices and desired number of columns\n",
    "    rows = len(selected_indices) // cols + (len(selected_indices) % cols > 0)\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))  # Adjust figure size as needed\n",
    "    fig.suptitle(f'Training and Validation Loss for Selected Simulations @ n_epoch = {n_epoch}')\n",
    "\n",
    "    # Flatten the axes array for easy indexing, in case of a single row or column\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        train_loss, val_loss = losses_dict[idx]\n",
    "\n",
    "        # Plot on the ith subplot\n",
    "        axes[i].plot(train_loss, label='Training')\n",
    "        axes[i].plot(val_loss, label='Validation')\n",
    "        axes[i].set_title(f'Simulation {idx}')\n",
    "        axes[i].set_xlabel('Epochs')\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the layout to make room for the subtitle\n",
    "    plt.show()\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"TrainVval Plot saved as: {plot_filename}\")\n",
    "    # plt.close(fig)  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "def plot_simulation_Qlearning_losses_in_grid(selected_indices, losses_dict, run_name, folder, cols=3):\n",
    "\n",
    "    all_losses = {\n",
    "        'train_losses_stage1': {},\n",
    "        'train_losses_stage2': {},\n",
    "        'val_losses_stage1': {},\n",
    "        'val_losses_stage2': {}\n",
    "    }\n",
    "\n",
    "    # Iterate over each simulation and extract losses\n",
    "    for simulation, losses in losses_dict.items():\n",
    "        train_losses_stage1, train_losses_stage2, val_losses_stage1, val_losses_stage2 = losses\n",
    "\n",
    "        all_losses['train_losses_stage1'][simulation] = train_losses_stage1\n",
    "        all_losses['train_losses_stage2'][simulation] = train_losses_stage2\n",
    "        all_losses['val_losses_stage1'][simulation] = val_losses_stage1\n",
    "        all_losses['val_losses_stage2'][simulation] = val_losses_stage2\n",
    "\n",
    "\n",
    "    rows = len(selected_indices) // cols + (len(selected_indices) % cols > 0)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    fig.suptitle('Training and Validation Loss for Selected Simulations')\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        # Check if the replication index exists in the losses for each type\n",
    "        if idx in all_losses['train_losses_stage1']:\n",
    "            axes[i].plot(all_losses['train_losses_stage1'][idx], label='Training Stage 1', linestyle='--')\n",
    "            axes[i].plot(all_losses['val_losses_stage1'][idx], label='Validation Stage 1', linestyle='-.')\n",
    "            axes[i].plot(all_losses['train_losses_stage2'][idx], label='Training Stage 2', linestyle='--')\n",
    "            axes[i].plot(all_losses['val_losses_stage2'][idx], label='Validation Stage 2', linestyle='-.')\n",
    "            axes[i].set_title(f'Simulation {idx}')\n",
    "            axes[i].set_xlabel('Epochs')\n",
    "            axes[i].set_ylabel('Loss')\n",
    "            axes[i].legend()\n",
    "        else:\n",
    "            axes[i].set_title(f'Simulation {idx} - Data not available')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"TrainVval Plot Deep Q Learning saved as: {plot_filename}\")\n",
    "    # plt.close(fig)  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3-Flsln-MYBu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoeb5gn2MpYU"
   },
   "source": [
    "## Loss function and surrogate opt utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j8a_VpnbMYG3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Loss function and surrogate opt utils\n",
    "\n",
    "def compute_phi(x, option):\n",
    "    if option == 1:\n",
    "        return 1 + torch.tanh(5*x)\n",
    "    elif option == 2:\n",
    "        return 1 + 2 * torch.atan(torch.pi * x / 2) / torch.pi\n",
    "    elif option == 3:\n",
    "        return 1 + x / torch.sqrt(1 + x ** 2)\n",
    "    elif option == 4:\n",
    "        return 1 + x / (1 + torch.abs(x))\n",
    "    elif option == 5:\n",
    "        return torch.where(x >= 0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "    else:\n",
    "        logger.error(\"Invalid phi option: %s\", option)\n",
    "        raise ValueError(\"Invalid phi option\")\n",
    "\n",
    "\n",
    "def gamma_function_old_vec(a, b, A, option):\n",
    "    a = a.to(device)\n",
    "    b = b.to(device)\n",
    "\n",
    "    phi_a = compute_phi(a, option)\n",
    "    phi_b = compute_phi(b, option)\n",
    "    phi_b_minus_a = compute_phi(b - a, option)\n",
    "    phi_a_minus_b = compute_phi(a - b, option)\n",
    "    phi_neg_a = compute_phi(-a, option)\n",
    "    phi_neg_b = compute_phi(-b, option)\n",
    "\n",
    "    gamma = torch.where(A == 1, phi_a * phi_b,\n",
    "                        torch.where(A == 2, phi_b_minus_a * phi_neg_a,\n",
    "                                    torch.where(A == 3, phi_a_minus_b * phi_neg_b,\n",
    "                                                torch.tensor(0.0).to(device))))\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def compute_gamma(a, b, option):\n",
    "    # Assume a and b are already tensors, check if they need to be sent to a specific device and ensure they have gradients if required\n",
    "    a = a.detach().requires_grad_(True)\n",
    "    b = b.detach().requires_grad_(True)\n",
    "\n",
    "    # asymmetric\n",
    "    if option == 1:\n",
    "        result = ((torch.exp(a + b) - 1) / ((1 + torch.exp(a)) * (1 + torch.exp(b))) ) +  ( 1 / (1 + torch.exp(a) + torch.exp(b)))\n",
    "    # symmetric\n",
    "    elif option == 2:\n",
    "        result = (torch.exp(a + b) * ((a * (torch.exp(b) - 1))**2 + (torch.exp(a) - 1) * (-torch.exp(a) + (torch.exp(b) - 1) * (torch.exp(a) - torch.exp(b) + b)))) / ((torch.exp(a) - 1)**2 * (torch.exp(b) - 1)**2 * (torch.exp(a) - torch.exp(b)))\n",
    "    else:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "\n",
    "def gamma_function_new_vec(a, b, A, option):\n",
    "    # a, b, and A are torch tensors and move them to the specified device\n",
    "    a = torch.tensor(a, dtype=torch.float32, requires_grad=True).to(device)\n",
    "    b = torch.tensor(b, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "    # a = torch.tensor(a, dtype=torch.float32).to(device)\n",
    "    # b = torch.tensor(b, dtype=torch.float32).to(device)\n",
    "    A = torch.tensor(A, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Apply compute_gamma_vectorized across the entire tensors based on A\n",
    "    result_1 = compute_gamma(a, b, option)\n",
    "    result_2 = compute_gamma(b - a, -a, option)\n",
    "    result_3 = compute_gamma(a - b, -b, option)\n",
    "\n",
    "    gamma = torch.where(A == 1, result_1,\n",
    "                        torch.where(A == 2, result_2,\n",
    "                                    torch.where(A == 3, result_3,\n",
    "                                                torch.tensor(0.0).to(device) )))\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def main_loss_gamma(stage1_outputs, stage2_outputs, A1, A2, Ci, option, surrogate_num):\n",
    "\n",
    "    if surrogate_num == 1:\n",
    "        # # surrogate 1\n",
    "        gamma_stage1 = gamma_function_old_vec(stage1_outputs[:, 0], stage1_outputs[:, 1], A1.int(), option)\n",
    "        gamma_stage2 = gamma_function_old_vec(stage2_outputs[:, 0], stage2_outputs[:, 1], A2.int(), option)\n",
    "    else:\n",
    "        # surrogate 2 - contains symmetric and non symmetic cases\n",
    "        gamma_stage1 = gamma_function_new_vec(stage1_outputs[:, 0], stage1_outputs[:, 1], A1.int(), option)\n",
    "        gamma_stage2 = gamma_function_new_vec(stage2_outputs[:, 0], stage2_outputs[:, 1], A2.int(), option)\n",
    "\n",
    "    loss = -torch.mean(Ci * gamma_stage1 * gamma_stage2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_batches(model1, model2, data, params, optimizer, is_train=True):\n",
    "    batch_size = params['batch_size']\n",
    "    total_loss = 0\n",
    "    num_batches = (data['input1'].shape[0] + batch_size - 1) // batch_size\n",
    "\n",
    "    if is_train:\n",
    "        model1.train()\n",
    "        model2.train()\n",
    "    else:\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "\n",
    "    for batch_idx in batches(data['input1'].shape[0], batch_size):\n",
    "        batch_data = {k: v[batch_idx].to(params['device']) for k, v in data.items()}\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            outputs_stage1 = model1(batch_data['input1'])\n",
    "            outputs_stage2 = model2(batch_data['input2'])\n",
    "\n",
    "            outputs_stage1 = torch.stack(outputs_stage1, dim=1).squeeze()\n",
    "            outputs_stage2 = torch.stack(outputs_stage2, dim=1).squeeze()\n",
    "\n",
    "            loss = main_loss_gamma(outputs_stage1, outputs_stage2, batch_data['A1'], batch_data['A2'],\n",
    "                                   batch_data['Ci'], option=params['option_sur'], surrogate_num=params['surrogate_num'])\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def initialize_and_prepare_model(stage, params, sample_size):\n",
    "    model = initialize_nn(params, stage).to(params['device'])\n",
    "\n",
    "    # Check for the initializer type in params and apply accordingly\n",
    "    if params['initializer'] == 'he':\n",
    "        model.he_initializer()  # He initialization (aka Kaiming initialization)\n",
    "    else:\n",
    "        model.reset_weights()  # Custom reset weights to a specific constant eg. 0.1\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_optimizer_and_scheduler(nn_stage1, nn_stage2, params):\n",
    "    # Combine parameters from both models\n",
    "    combined_params = list(nn_stage1.parameters()) + list(nn_stage2.parameters())\n",
    "\n",
    "    # Select optimizer based on params\n",
    "    if params['optimizer_type'] == 'adam':\n",
    "        optimizer = optim.Adam(combined_params, lr=params['optimizer_lr'])\n",
    "    elif params['optimizer_type'] == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(combined_params, lr=params['optimizer_lr'], weight_decay=params['optimizer_weight_decay'])\n",
    "    else:\n",
    "        logging.warning(\"No valid optimizer type found in params['optimizer_type'], defaulting to Adam.\")\n",
    "        optimizer = optim.Adam(combined_params, lr=params['optimizer_lr'])  # Default to Adam if none specified\n",
    "\n",
    "    # Initialize scheduler only if use_scheduler is True\n",
    "    scheduler = None\n",
    "    if params.get('use_scheduler', False):  # Defaults to False if 'use_scheduler' is not in params\n",
    "        if params['scheduler_type'] == 'reducelronplateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.01, patience=10)\n",
    "        elif params['scheduler_type'] == 'steplr':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])\n",
    "        elif params['scheduler_type'] == 'cosineannealing':\n",
    "            T_max = (params['sample_size'] // params['batch_size']) * params['n_epoch']\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=0.0001)\n",
    "        else:\n",
    "            logging.warning(\"No valid scheduler type found in params['scheduler_type'], defaulting to StepLR.\")\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])  # Default to StepLR if none specified\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def update_scheduler(scheduler, params, val_loss=None):\n",
    "\n",
    "    if scheduler is None:\n",
    "        logging.warning(\"Scheduler is not initialized but update_scheduler was called.\")\n",
    "        return\n",
    "\n",
    "    # Check the type of scheduler and step accordingly\n",
    "    if params['scheduler_type'] == 'reducelronplateau':\n",
    "        # ReduceLROnPlateau expects a metric, usually the validation loss, to step\n",
    "        if val_loss is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            logging.warning(\"Validation loss required for ReduceLROnPlateau but not provided.\")\n",
    "    else:\n",
    "        # Other schedulers like StepLR or CosineAnnealingLR do not use the validation loss\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "om1LW_ABMv35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYnglpGTMxo7"
   },
   "source": [
    "## Q learning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dTBe-2xmMv6x"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Q learning utils\n",
    "\n",
    "def train_and_validate(model, optimizer, scheduler, train_inputs, train_actions, train_targets, val_inputs, val_actions, val_targets, params, stage_number):\n",
    "\n",
    "    batch_size, device, n_epoch, sample_size = params['batch_size'], params['device'], params['n_epoch'], params['sample_size']\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    epoch_num_model = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx in batches(train_inputs.shape[0], batch_size, epoch):\n",
    "            batch_idx = batch_idx.to(device)\n",
    "            inputs_batch = torch.index_select(train_inputs, 0, batch_idx).to(device)\n",
    "            actions_batch = torch.index_select(train_actions, 0, batch_idx).to(device)\n",
    "            targets_batch = torch.index_select(train_targets, 0, batch_idx).to(device)\n",
    "            combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_inputs)\n",
    "            loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        num_batches_t = (train_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_train_loss = total_train_loss / num_batches_t\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in batches(val_inputs.shape[0], batch_size):\n",
    "                batch_idx = batch_idx.to(device)\n",
    "                inputs_batch = torch.index_select(val_inputs, 0, batch_idx).to(device)\n",
    "                actions_batch = torch.index_select(val_actions, 0, batch_idx).to(device)\n",
    "                targets_batch = torch.index_select(val_targets, 0, batch_idx).to(device)\n",
    "                combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "                outputs = model(combined_inputs)\n",
    "                loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        num_batches_v = (val_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_val_loss = total_val_loss / num_batches_v\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss and epoch > 20:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "\n",
    "        # scheduler.step()\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Save the best model parameters after all epochs\n",
    "    if best_model_params is not None:\n",
    "        model_path = os.path.join(model_dir, f'best_model_stage_Q_{stage_number}_{sample_size}.pt')\n",
    "        torch.save(best_model_params, model_path)\n",
    "\n",
    "    return train_losses, val_losses, epoch_num_model\n",
    "\n",
    "\n",
    "def initialize_model_and_optimizer(params, stage):\n",
    "    nn = initialize_nn(params, stage).to(device)\n",
    "    optimizer = optim.Adam(nn.parameters(), lr=params['optimizer_lr'])\n",
    "    # optimizer = optim.Adam(nn.parameters(), lr=params['optimizer_lr'], betas=params['optimizer_betas'], eps=params['optimizer_eps'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])\n",
    "    return nn, optimizer, scheduler\n",
    "\n",
    "def evaluate_model_on_actions(model, inputs, action_t):\n",
    "    actions_list = [1, 2, 3]\n",
    "    outputs_list = []\n",
    "    for action_value in actions_list:\n",
    "        action_tensor = torch.full_like(action_t, action_value).unsqueeze(-1)\n",
    "        combined_inputs = torch.cat((inputs, action_tensor), dim=1).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(combined_inputs)\n",
    "        outputs_list.append(outputs[0])\n",
    "\n",
    "    max_outputs, _ = torch.max(torch.cat(outputs_list, dim=1), dim=1)\n",
    "    return max_outputs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N_FBP0pRMv83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eN-4SDiM6Ju"
   },
   "source": [
    "## Eval fn utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z8owLGgRMv_q"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5. Eval fn utils\n",
    "\n",
    "def compute_test_outputs(nn, test_input, A_tensor, params, is_stage1=True):\n",
    "    with torch.no_grad():\n",
    "        if params['f_model'] == \"surr_opt\":\n",
    "            # Perform the forward pass\n",
    "            test_outputs_i = nn(test_input)\n",
    "\n",
    "            # Directly stack the required outputs and perform computations in a single step\n",
    "            test_outputs = torch.stack(test_outputs_i[:2], dim=1).squeeze()\n",
    "\n",
    "            # Compute treatment assignments directly without intermediate variables\n",
    "            test_outputs = torch.stack([\n",
    "                torch.zeros_like(test_outputs[:, 0]),\n",
    "                -test_outputs[:, 0],\n",
    "                -test_outputs[:, 1]\n",
    "            ], dim=1)\n",
    "        else:\n",
    "            # Modify input for each action and perform a forward pass\n",
    "            input_tests = [\n",
    "                torch.cat((test_input, torch.full_like(A_tensor, i).unsqueeze(-1)), dim=1).to(params['device'])\n",
    "                for i in range(1, 4)  # Assuming there are 3 actions\n",
    "            ]\n",
    "\n",
    "            # Forward pass for each modified input and stack the results\n",
    "            test_outputs = torch.stack([\n",
    "                nn(input_stage)[0] for input_stage in input_tests\n",
    "            ], dim=1)\n",
    "\n",
    "    # Determine the optimal action based on the computed outputs\n",
    "    optimal_actions = torch.argmax(test_outputs, dim=1) + 1\n",
    "    return optimal_actions.squeeze().to(params['device']), test_outputs\n",
    "\n",
    "def prepare_stage2_test_input(O1_tensor_test, A1, g1_opt_conditions, Z1_tensor_test):\n",
    "\n",
    "    # g1_opt_conditions gives the optimal action, we use it to compute Y1_pred\n",
    "    Y1_pred = torch.exp(1.5 - torch.abs(1.5 * O1_tensor_test[:, 0] + 2) * (A1 - g1_opt_conditions)**2) + Z1_tensor_test\n",
    "\n",
    "    # Form the test input for stage 2 by concatenating the necessary tensors\n",
    "    test_input_stage2 = torch.cat([O1_tensor_test, A1.unsqueeze(1), Y1_pred.unsqueeze(1)], dim=1)\n",
    "\n",
    "    # # DEBUG PRINT\n",
    "    # Y1_stats = [torch.min(Y1_pred), torch.max(Y1_pred), torch.mean(Y1_pred)]\n",
    "    # stats_message = f\"Y1_pred [min, max, mean]: {Y1_stats}\"\n",
    "    # tqdm.write(stats_message)\n",
    "\n",
    "    return test_input_stage2, Y1_pred\n",
    "\n",
    "\n",
    "\n",
    "def prepare_Y2_pred(O1_tensor_test, A1, A2, g2_opt_conditions, Z1_tensor_test, Z2_tensor_test):\n",
    "\n",
    "    # g2_opt_conditions gives the optimal action, we use it to compute Y2_pred\n",
    "    Y2_pred = torch.exp(1.26 - torch.abs(1.5 * O1_tensor_test[:, 2] - 2) * (A2 - g2_opt_conditions)**2) + Z2_tensor_test\n",
    "\n",
    "    # # DEBUG PRINT\n",
    "    # stats_message = f\"Y2_pred [min, max, mean]: [{torch.min(Y2_pred)}, {torch.max(Y2_pred)}, {torch.mean(Y2_pred)}]\"\n",
    "    # tqdm.write(stats_message)\n",
    "\n",
    "    return Y2_pred\n",
    "\n",
    "\n",
    "\n",
    "def calculate_policy_values(Y1_tensor, Y2_tensor, d1_star, d2_star, Y1_pred, Y2_pred, V_replications, Z1_tensor_test, Z2_tensor_test):\n",
    "    # Rewards using Optimal policy\n",
    "    Y1_test_opt = torch.exp(torch.tensor(1.5)) + Z1_tensor_test\n",
    "    Y2_test_opt = torch.exp(torch.tensor(1.26)) + Z2_tensor_test\n",
    "\n",
    "    # DEBUG PRINT\n",
    "    message = f'\\nY1_opt mean: {torch.mean(Y1_test_opt)}, Y2_opt mean: {torch.mean(Y2_test_opt)}, Y1_opt+Y2_opt mean: {torch.mean(Y1_test_opt + Y2_test_opt)} \\n\\n'\n",
    "    print(message)\n",
    "\n",
    "    V_d1_d2_opt = torch.mean(Y1_test_opt + Y2_test_opt).cpu().item()  # Calculate the mean value and convert to Python scalar\n",
    "    V_replications[\"V_replications_M1_optimal\"].append(V_d1_d2_opt)  # Append to the list for optimal policy values\n",
    "\n",
    "    # Value function using Behavioral policy\n",
    "    V_d1_d2 = torch.mean(Y1_tensor + Y2_tensor).cpu().item()  # Calculate the mean value and convert to Python scalar\n",
    "    V_replications[\"V_replications_M1_behavioral\"].append(V_d1_d2)  # Append to the list for behavioral policy values\n",
    "\n",
    "    # Value function using Current method's policy\n",
    "    V_replications[\"V_replications_M1_pred\"].append(torch.mean(Y1_pred + Y2_pred).item())  # Append the mean value as a Python scalar to the list for current approach values\n",
    "\n",
    "    return V_replications\n",
    "\n",
    "\n",
    "\n",
    "def initialize_and_load_model(stage, sample_size, params):\n",
    "    # Initialize the neural network model\n",
    "    nn_model = initialize_nn(params, stage).to(params['device'])\n",
    "\n",
    "    # Define the directory and file name for the model\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    if params['f_model']==\"surr_opt\":\n",
    "        model_filename = f'best_model_stage_surr_{stage}_{sample_size}.pt'\n",
    "    else:\n",
    "        model_filename = f'best_model_stage_Q_{stage}_{sample_size}.pt'\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Check if the model file exists before attempting to load\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.error(f\"No model file found at {model_path}. Please check the file path and model directory.\")\n",
    "        return None  # or handle the error as needed\n",
    "\n",
    "    # Load the model's state dictionary from the file\n",
    "    nn_model.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    nn_model.eval()\n",
    "\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oJsdAveRTEQo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "McO1KPvjTETr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk2LJR_VTEeO"
   },
   "source": [
    "# Value function Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-Mxk4pNdM-KN"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_and_validate_W_estimator(model, optimizer, scheduler, train_inputs, train_actions, train_targets, val_inputs, val_actions, val_targets, batch_size, device, n_epoch, stage_number, sample_size, params):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    epoch_num_model = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx in batches(train_inputs.shape[0], batch_size, epoch):\n",
    "            batch_idx = batch_idx.to(device)\n",
    "            inputs_batch = torch.index_select(train_inputs, 0, batch_idx).to(device)\n",
    "            actions_batch = torch.index_select(train_actions, 0, batch_idx).to(device)\n",
    "            targets_batch = torch.index_select(train_targets, 0, batch_idx).to(device)\n",
    "            combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_inputs)\n",
    "\n",
    "\n",
    "            loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        num_batches_t = (train_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_train_loss = total_train_loss / num_batches_t\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in batches(val_inputs.shape[0], batch_size):\n",
    "                batch_idx = batch_idx.to(device)\n",
    "                inputs_batch = torch.index_select(val_inputs, 0, batch_idx).to(device)\n",
    "                actions_batch = torch.index_select(val_actions, 0, batch_idx).to(device)\n",
    "                targets_batch = torch.index_select(val_targets, 0, batch_idx).to(device)\n",
    "                combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "\n",
    "                outputs = model(combined_inputs)\n",
    "\n",
    "\n",
    "\n",
    "                loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        num_batches_v = (val_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_val_loss = total_val_loss / num_batches_v\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss and epoch > 20:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Save the best model parameters after all epochs\n",
    "    if best_model_params is not None:\n",
    "        model_path = os.path.join(model_dir, f\"best_model_stage_Q_{stage_number}_{sample_size}_W_estimator_{params['f_model']}.pt\")\n",
    "        torch.save(best_model_params, model_path)\n",
    "\n",
    "\n",
    "    return train_losses, val_losses, epoch_num_model\n",
    "\n",
    "\n",
    "\n",
    "def valFn_estimate(Qhat1_H1d1, Qhat2_H2d2, Qhat1_H1A1, Qhat2_H2A2, A1_tensor, A2_tensor, A1, A2, Y1_tensor, Y2_tensor , P_A1_given_H1_tensor, P_A2_given_H2_tensor):\n",
    "\n",
    "    # # IPW estimator\n",
    "    # indicator1 = ((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # indicator2 = ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # term = (Y1_tensor + Y2_tensor) * indicator1 * indicator2\n",
    "    # return torch.mean(term).item()\n",
    "\n",
    "    # # term I got\n",
    "    # term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1)) *((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # term_2 = (Y2_tensor - Qhat2_H2A2.squeeze(1) ) * ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # return torch.mean(Qhat1_H1d1.squeeze(1)  + term_1 + term_2 + Qhat2_H2d2.squeeze(1)).item()\n",
    "\n",
    "    # # 1st term on board (incorrect)\n",
    "    # term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1) + Qhat2_H2d2.squeeze(1) ) *((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # term_2 = (Y2_tensor- Qhat2_H2A2.squeeze(1) ) * ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # return torch.mean(Qhat1_H1d1.squeeze(1)  + term_1 + term_2).item()\n",
    "\n",
    "    # corrected term in email\n",
    "    indicator1 = ((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    indicator2 = ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1) + Qhat2_H2d2.squeeze(1) ) * indicator1\n",
    "    term_2 = (Y2_tensor - Qhat2_H2A2.squeeze(1) ) * indicator1 * indicator2\n",
    "    return torch.mean(Qhat1_H1d1.squeeze(1) ).item() + torch.mean(term_1 + term_2).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_and_train_stage(stage, input_tensor, action_tensor, outcome_tensor, val_input_tensor, val_action_tensor, val_outcome_tensor, params):\n",
    "\n",
    "    sample_size = params['sample_size']\n",
    "\n",
    "    \"\"\"Initialize, train and validate a model for a given stage.\"\"\"\n",
    "    model, optimizer, scheduler = initialize_model_and_optimizer(params, stage)\n",
    "    losses, val_losses, epoch_num = train_and_validate_W_estimator(\n",
    "        model, optimizer, scheduler, input_tensor, action_tensor, outcome_tensor, val_input_tensor, val_action_tensor, val_outcome_tensor,\n",
    "        params['batch_size'], params['device'], params['n_epoch'], stage, sample_size, params\n",
    "    )\n",
    "\n",
    "    # Define the directory and file name for the model\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{stage}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # Check if the model file exists before attempting to load\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.error(f\"No model file found at {model_path}. Please check the file path and model directory.\")\n",
    "        return None  # or handle the error as needed\n",
    "\n",
    "    # Load the model's state dictionary from the file\n",
    "    model.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def calculate_policy_values_W_estimator(train_tens, params, A1, A2, P_A1_given_H1_tensor, P_A2_given_H2_tensor):\n",
    "\n",
    "\n",
    "    train_size = int(params['training_validation_prop'] * params['sample_size'])\n",
    "    train_test_tensors = [tensor[:train_size] for tensor in train_tens ]\n",
    "    val_test_tensors = [tensor[train_size:] for tensor in train_tens]\n",
    "\n",
    "    test_input_stage1, test_input_stage2,  train_Y1, train_Y2, train_A1, train_A2 = train_test_tensors\n",
    "    val_input_stage1, val_input_stage2, val_Y1, val_Y2, val_A1, val_A2 = val_test_tensors\n",
    "\n",
    "\n",
    "    A1_tr, A2_tr = [tensor[:train_size] for tensor in [A1, A2] ] # actions from chosen policy\n",
    "    A1_val, A2_val = [tensor[train_size:] for tensor in [A1, A2]] # actions from chosen policy\n",
    "\n",
    "\n",
    "\n",
    "    # Duplicate the params dictionary\n",
    "    param_W = params.copy()\n",
    "\n",
    "    # Update specific values in param_W\n",
    "    param_W.update({\n",
    "          'num_networks': 1,\n",
    "          'input_dim_stage1': 6,\n",
    "          'output_dim_stage1': 1,\n",
    "          'input_dim_stage2': 8,\n",
    "          'output_dim_stage2': 1,\n",
    "      })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage2, optimizer_2, scheduler_2 = initialize_model_and_optimizer(param_W, 2)\n",
    "    train_losses_stage2, val_losses_stage2, epoch_num_model_2 = train_and_validate_W_estimator(nn_stage2, optimizer_2, scheduler_2, test_input_stage2, train_A2, train_Y2, val_input_stage2, val_A2, val_Y2, params['batch_size'], device, params['n_epoch'], 2, params['sample_size'], params)\n",
    "\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{2}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    nn_stage2.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    nn_stage2.eval()\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2_tr.unsqueeze(-1)), dim=1)\n",
    "    test_tr_outputs_stage2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    train_Y1_hat = test_tr_outputs_stage2.squeeze(1) + train_Y1 # pseudo outcome\n",
    "\n",
    "\n",
    "    combined_inputs2val = torch.cat((val_input_stage2, A2_val.unsqueeze(-1)), dim=1)\n",
    "    test_val_outputs_stage2 = nn_stage2(combined_inputs2val)[0]  #compute_test_outputs(nn_stage2, val_input_stage2, A2_val, device, params, is_stage1=False)\n",
    "    val_Y1_hat = test_val_outputs_stage2.squeeze() + val_Y1 # pseudo outcome\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage1, optimizer_1, scheduler_1 = initialize_model_and_optimizer(param_W, 1)\n",
    "    train_losses_stage1, val_losses_stage1, epoch_num_model_1 = train_and_validate_W_estimator(nn_stage1, optimizer_1, scheduler_1, test_input_stage1, train_A1, train_Y1_hat, val_input_stage1, val_A1, val_Y1_hat, params['batch_size'], device, params['n_epoch'], 1, params['sample_size'], params)\n",
    "\n",
    "\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{1}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    nn_stage1.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage1.eval()\n",
    "\n",
    "\n",
    "\n",
    "    [test_input_stage1, test_input_stage2, Y1_tensor, Y2_tensor, A1_tensor, A2_tensor] =   train_tens\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2.unsqueeze(-1)), dim=1)\n",
    "    Qhat2_H2d2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    combined_inputs1 = torch.cat((test_input_stage1, A1.unsqueeze(-1)), dim=1)\n",
    "    Qhat1_H1d1 = nn_stage1(combined_inputs1)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2_tensor.unsqueeze(-1)), dim=1)\n",
    "    Qhat2_H2A2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    combined_inputs1 = torch.cat((test_input_stage1, A1_tensor.unsqueeze(-1)), dim=1)\n",
    "    Qhat1_H1A1 = nn_stage1(combined_inputs1)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "\n",
    "    V_replications_M1_pred = valFn_estimate(Qhat1_H1d1, Qhat2_H2d2, Qhat1_H1A1, Qhat2_H2A2, A1_tensor, A2_tensor, A1, A2, Y1_tensor, Y2_tensor , P_A1_given_H1_tensor, P_A2_given_H2_tensor)\n",
    "\n",
    "\n",
    "    return V_replications_M1_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkRMVRENNO4J"
   },
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDPqJEGgNeSa"
   },
   "source": [
    "## Generate Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5AGXH8vfNfmG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Generate Data\n",
    "def generate_and_preprocess_data(params, replication_seed, run='train'):\n",
    "\n",
    "    # torch.manual_seed(replication_seed)\n",
    "    sample_size = params['sample_size']\n",
    "    device = params['device']\n",
    "\n",
    "    # Simulate baseline covariates\n",
    "    O1 = torch.randn(5, sample_size, device=device)\n",
    "    Z1 = torch.randn(sample_size, device=device)\n",
    "    Z2 = torch.randn(sample_size, device=device)\n",
    "\n",
    "    if params['noiseless']:\n",
    "        Z1.fill_(0)\n",
    "        Z2.fill_(0)\n",
    "\n",
    "    # Stage 1 data simulation\n",
    "    x1, x2, x3, x4, x5 = O1[0], O1[1], O1[2], O1[3], O1[4]\n",
    "    pi_10 = torch.ones(sample_size, device=device)\n",
    "    pi_11 = torch.exp(0.5 - 0.5 * x3)\n",
    "    pi_12 = torch.exp(0.5 * x4)\n",
    "    matrix_pi1 = torch.stack((pi_10, pi_11, pi_12), dim=0).t()\n",
    "\n",
    "    result1 = A_sim(matrix_pi1, stage=1)\n",
    "#     A1, probs1 = result1['A'], result1['probs']\n",
    "\n",
    "    A1, _ = result1['A'], result1['probs']\n",
    "    probs1 = M_propen(A1, O1[[2, 3]].t(), stage=1)  # multinomial logistic regression with X3, X4\n",
    "\n",
    "    A1 += 1\n",
    "\n",
    "    g1_opt = ((x1 > -1).float() * ((x2 > -0.5).float() + (x2 > 0.5).float())) + 1\n",
    "    Y1 = torch.exp(1.5 - torch.abs(1.5 * x1 + 2) * (A1 - g1_opt).pow(2)) + Z1\n",
    "\n",
    "    # Stage 2 data simulation\n",
    "    pi_20 = torch.ones(sample_size, device=device)\n",
    "    pi_21 = torch.exp(0.2 * Y1 - 1)\n",
    "    pi_22 = torch.exp(0.5 * x4)\n",
    "    matrix_pi2 = torch.stack((pi_20, pi_21, pi_22), dim=0).t()\n",
    "\n",
    "    result2 = A_sim(matrix_pi2, stage=2)\n",
    "#     A2, probs2 = result2['A'], result2['probs']\n",
    "\n",
    "    A2, _ = result2['A'], result2['probs']\n",
    "    probs2 = M_propen(A2, O1[[0, 4]].t(), stage=2)  # multinomial logistic regression with X1, X5\n",
    "\n",
    "    A2 += 1\n",
    "\n",
    "    Y1_opt = torch.exp(torch.tensor(1.5, device=device)) + Z1\n",
    "    g2_opt = (x3 > -1).float() * ((Y1_opt > 0.5).float() + (Y1_opt > 3).float()) + 1\n",
    "\n",
    "    Y2 = torch.exp(1.26 - torch.abs(1.5 * x3 - 2) * (A2 - g2_opt).pow(2)) + Z2\n",
    "\n",
    "    if run != 'test':\n",
    "      # transform Y for direct search\n",
    "      Y1, Y2 = transform_Y(Y1, Y2)\n",
    "\n",
    "    # Propensity score stack\n",
    "    pi_tensor_stack = torch.stack([probs1['pi_10'], probs1['pi_11'], probs1['pi_12'], probs2['pi_20'], probs2['pi_21'], probs2['pi_22']])\n",
    "\n",
    "    # Adjusting A1 and A2 indices\n",
    "    A1_indices = (A1 - 1).long().unsqueeze(0)  # A1 actions, Subtract 1 to match index values (0, 1, 2)\n",
    "    A2_indices = (A2 - 1 + 3).long().unsqueeze(0)   # A2 actions, Add +3 to match index values (3, 4, 5) for A2, with added dimension\n",
    "\n",
    "    # Gathering probabilities based on actions\n",
    "    P_A1_given_H1_tensor = torch.gather(pi_tensor_stack, dim=0, index=A1_indices).squeeze(0)  # Remove the added dimension after gathering\n",
    "    P_A2_given_H2_tensor = torch.gather(pi_tensor_stack, dim=0, index=A2_indices).squeeze(0)  # Remove the added dimension after gathering\n",
    "\n",
    "    # Calculate Ci tensor\n",
    "    Ci = (Y1 + Y2) / (P_A1_given_H1_tensor * P_A2_given_H2_tensor)\n",
    "\n",
    "    # Input preparation\n",
    "    input_stage1 = O1.t()\n",
    "    input_stage2 = torch.cat([O1.t(), A1.unsqueeze(1), Y1.unsqueeze(1)], dim=1)\n",
    "\n",
    "    if run == 'test':\n",
    "        return input_stage1, input_stage2, Ci, Y1, Y2, A1, A2, P_A1_given_H1_tensor, P_A2_given_H2_tensor, g1_opt, g2_opt, Z1, Z2\n",
    "\n",
    "    # Splitting data into training and validation sets\n",
    "    train_size = int(params['training_validation_prop'] * sample_size)\n",
    "    train_tensors = [tensor[:train_size] for tensor in [input_stage1, input_stage2, Ci, Y1, Y2, A1, A2]]\n",
    "    val_tensors = [tensor[train_size:] for tensor in [input_stage1, input_stage2, Ci, Y1, Y2, A1, A2]]\n",
    "\n",
    "    return tuple(train_tensors), tuple(val_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TxsHyCXuNkC4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVg1IOCmNjS2"
   },
   "source": [
    "## surrogate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "69HE80wwNnx1"
   },
   "outputs": [],
   "source": [
    "def surr_opt(tuple_train, tuple_val, params):\n",
    "\n",
    "    sample_size = params['sample_size']\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss, best_model_stage1_params, best_model_stage2_params, epoch_num_model = float('inf'), None, None, 0\n",
    "\n",
    "    nn_stage1 = initialize_and_prepare_model(1, params, sample_size)\n",
    "    nn_stage2 = initialize_and_prepare_model(2, params, sample_size)\n",
    "\n",
    "    optimizer, scheduler = initialize_optimizer_and_scheduler(nn_stage1, nn_stage2, params)\n",
    "\n",
    "    #  Training and Validation data\n",
    "    train_data = {'input1': tuple_train[0], 'input2': tuple_train[1], 'Ci': tuple_train[2], 'A1': tuple_train[5], 'A2': tuple_train[6]}\n",
    "    val_data = {'input1': tuple_val[0], 'input2': tuple_val[1], 'Ci': tuple_val[2], 'A1': tuple_val[5], 'A2': tuple_val[6]}\n",
    "\n",
    "\n",
    "    # Training and Validation loop for both stages\n",
    "    for epoch in range(params['n_epoch']):\n",
    "\n",
    "        train_loss = process_batches(nn_stage1, nn_stage2, train_data, params, optimizer, is_train=True)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = process_batches(nn_stage1, nn_stage2, val_data, params, optimizer, is_train=False)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = val_loss\n",
    "            best_model_stage1_params = nn_stage1.state_dict()\n",
    "            best_model_stage2_params = nn_stage2.state_dict()\n",
    "\n",
    "        # Update the scheduler with the current epoch's validation loss\n",
    "        update_scheduler(scheduler, params, val_loss)\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_path_stage1 = os.path.join(model_dir, f'best_model_stage_surr_1_{sample_size}.pt')\n",
    "    model_path_stage2 = os.path.join(model_dir, f'best_model_stage_surr_2_{sample_size}.pt')\n",
    "\n",
    "    # Save the models\n",
    "    torch.save(best_model_stage1_params, model_path_stage1)\n",
    "    torch.save(best_model_stage2_params, model_path_stage2)\n",
    "\n",
    "    return (nn_stage1, nn_stage2, (train_losses, val_losses), epoch_num_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "36KmGLjvNrln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH_L_V5oNsWI"
   },
   "source": [
    "## DQL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9DFOx69PNrp2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DQlearning(tuple_train, tuple_val, params):\n",
    "    train_input_stage1, train_input_stage2, _, train_Y1, train_Y2, train_A1, train_A2 = tuple_train\n",
    "    val_input_stage1, val_input_stage2, _, val_Y1, val_Y2, val_A1, val_A2 = tuple_val\n",
    "\n",
    "\n",
    "    nn_stage1, optimizer_1, scheduler_1 = initialize_model_and_optimizer(params, 1)\n",
    "    nn_stage2, optimizer_2, scheduler_2 = initialize_model_and_optimizer(params, 2)\n",
    "\n",
    "    train_losses_stage2, val_losses_stage2, epoch_num_model_2 = train_and_validate(nn_stage2, optimizer_2, scheduler_2, train_input_stage2, train_A2, train_Y2,\n",
    "                                                                                   val_input_stage2, val_A2, val_Y2, params, 2)\n",
    "    # params['batch_size'], device, params['n_epoch'], 2, params['sample_size'], params)\n",
    "\n",
    "    train_Y1_hat = evaluate_model_on_actions(nn_stage2, train_input_stage2, train_A2) + train_Y1\n",
    "    val_Y1_hat = evaluate_model_on_actions(nn_stage2, val_input_stage2, val_A2) + val_Y1\n",
    "\n",
    "    train_losses_stage1, val_losses_stage1, epoch_num_model_1 = train_and_validate(nn_stage1, optimizer_1, scheduler_1, train_input_stage1, train_A1, train_Y1_hat,\n",
    "                                                                                   val_input_stage1, val_A1, val_Y1_hat, params, 1)\n",
    "\n",
    "    return (nn_stage1, nn_stage2, (train_losses_stage1, train_losses_stage2, val_losses_stage1, val_losses_stage2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "67Iadt7cNrsq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioq4ivMDNw3E"
   },
   "source": [
    "## Evaluation DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5g24tFFdNruR"
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_DTR(V_replications, num_replications, nn_stage1, nn_stage2, df, params):\n",
    "\n",
    "    # Generate and preprocess data for evaluation\n",
    "    processed_result = generate_and_preprocess_data(params, replication_seed=num_replications, run='test')\n",
    "    test_input_stage1, test_input_stage2, Ci_tensor, Y1_tensor, Y2_tensor, A1_tensor_test, A2_tensor_test, P_A1_g_H1, P_A2_g_H2, d1_star, d2_star, Z1, Z2  = processed_result\n",
    "\n",
    "    nn_stage1 = initialize_and_load_model(1, params['sample_size'] , params)\n",
    "    nn_stage2 = initialize_and_load_model(2, params['sample_size'] , params)\n",
    "\n",
    "    # Calculate test outputs for all networks in stage 1\n",
    "    A1, test_outputs_stage1 = compute_test_outputs(nn = nn_stage1, test_input = test_input_stage1, A_tensor = A1_tensor_test, params=params, is_stage1=True)\n",
    "    test_input_stage2, Y1_pred = prepare_stage2_test_input(O1_tensor_test = test_input_stage1 , A1 = A1,\n",
    "                                                           g1_opt_conditions = d1_star, Z1_tensor_test = Z1)\n",
    "\n",
    "    # Calculate test outputs for all networks in stage 2\n",
    "    A2, test_outputs_stage2 = compute_test_outputs(nn = nn_stage2, test_input = test_input_stage2, A_tensor = A2_tensor_test, params=params, is_stage1=False)\n",
    "    Y2_pred =  prepare_Y2_pred(O1_tensor_test = test_input_stage1, A1 = A1, A2 = A2, g2_opt_conditions = d2_star,\n",
    "                               Z1_tensor_test = Z1, Z2_tensor_test = Z2)\n",
    "\n",
    "\n",
    "    # Append to DataFrame\n",
    "    new_row = {\n",
    "        'Behavioral_A1': A1_tensor_test.cpu().numpy().tolist(),\n",
    "        'Behavioral_A2': A2_tensor_test.cpu().numpy().tolist(),\n",
    "        'Predicted_A1': A1.cpu().numpy().tolist(),\n",
    "        'Predicted_A2':  A2.cpu().numpy().tolist(),\n",
    "        'Optimal_A1': d1_star.cpu().numpy().tolist(),\n",
    "        'Optimal_A2': d2_star.cpu().numpy().tolist()\n",
    "        }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "    message = f'\\nY1_pred mean: {torch.mean(Y1_pred)}, Y2_pred mean:  {torch.mean(Y2_pred)}, Y1_pred+Y2_pred mean: {torch.mean(Y1_pred + Y2_pred)} \\n'\n",
    "    print(message)\n",
    "\n",
    "    V_replications = calculate_policy_values(Y1_tensor=Y1_tensor, Y2_tensor=Y2_tensor,\n",
    "                                             d1_star=d1_star, d2_star=d2_star,\n",
    "                                             Y1_pred=Y1_pred, Y2_pred=Y2_pred,\n",
    "                                             V_replications=V_replications,\n",
    "                                             Z1_tensor_test=Z1, Z2_tensor_test=Z2)\n",
    "\n",
    "    # Calculate policy values using the W estimator for DQL\n",
    "    train_tensors = [test_input_stage1, test_input_stage2, Y1_tensor, Y2_tensor, A1_tensor_test, A2_tensor_test]\n",
    "\n",
    "    V_replications_estimator = calculate_policy_values_W_estimator(train_tensors, params, A1, A2, P_A1_g_H1, P_A2_g_H2)\n",
    "\n",
    "    print(\"Estimated value fn.: \", V_replications_estimator)\n",
    "\n",
    "    V_replications[\"V_replications_estimator\"].append(V_replications_estimator)\n",
    "\n",
    "    return V_replications, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FojOCzJN20Z"
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "q1YeA669Nn0s"
   },
   "outputs": [],
   "source": [
    "\n",
    "def simulations( V_replications, params):\n",
    "    columns = ['Behavioral_A1', 'Behavioral_A2', 'Predicted_A1', 'Predicted_A2', 'Optimal_A1', 'Optimal_A2']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    losses_dict = {}\n",
    "    epoch_num_model_lst = []\n",
    "\n",
    "    for replication in tqdm(range(params['num_replications']), desc=\"Replications_M1\"):\n",
    "        print(f\"Replication # -------------->>>>>  {replication+1}\")\n",
    "\n",
    "        # Generate and preprocess data for training\n",
    "        tuple_train, tuple_val = generate_and_preprocess_data(params, replication_seed=replication, run='train')\n",
    "\n",
    "        # Estimate treatment regime : model --> surr_opt\n",
    "        print(\"Training started!\")\n",
    "        if params['f_model'] == 'DQlearning':\n",
    "            nn_stage1, nn_stage2, trn_val_loss_tpl = DQlearning(tuple_train, tuple_val, params)\n",
    "        else:\n",
    "            nn_stage1, nn_stage2, trn_val_loss_tpl, epoch_num_model = surr_opt(tuple_train, tuple_val, params)\n",
    "            epoch_num_model_lst.append(epoch_num_model)\n",
    "\n",
    "        losses_dict[replication] = trn_val_loss_tpl\n",
    "\n",
    "        # eval_DTR\n",
    "        print(\"Evaluation started\")\n",
    "        V_replications, df = eval_DTR(V_replications, replication, nn_stage1, nn_stage2, df, params)\n",
    "\n",
    "    return V_replications, df, losses_dict, epoch_num_model_lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MVSOOddJOBWW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTmbj9n_OF2l"
   },
   "source": [
    "# Change input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d391c23f4ca94548b4096e524e45007c",
      "70b096ad51dc490fa5b8e618e7d8694c",
      "793bf2a6285d43178a6f96762a9f9c42",
      "07ae5da6304040b3b623bccab6987fbb",
      "98ffd24a57774ceda9f2e49c356a48a4",
      "30bd93bc900a453f977c7b45e54a64e8",
      "35c0860a48fd47148273906eaf920dd4",
      "efafddbf1d724b539fffd04270ee828a",
      "f9169dc77b4c43fc8c55da01d38dd2a1",
      "e0b74f94741b460782b03302a3628d3f",
      "869dc90565954dfe85024370feaf437c"
     ]
    },
    "id": "9XBaDKo6O15S",
    "outputId": "e21e963e-ff7e-4e53-b415-e112d7efb643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: %s DQlearning\n",
      "Training size: %d 21000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391c23f4ca94548b4096e524e45007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Replications_M1:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication # -------------->>>>>  1\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.186362266540527, Y2_pred mean:  3.3947455883026123, Y1_pred+Y2_pred mean: 7.581108570098877 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.500905990600586\n",
      "Replication # -------------->>>>>  2\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.135711193084717, Y2_pred mean:  3.342452049255371, Y1_pred+Y2_pred mean: 7.478164196014404 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.480799198150635\n",
      "Replication # -------------->>>>>  3\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.153692722320557, Y2_pred mean:  3.372300863265991, Y1_pred+Y2_pred mean: 7.525993347167969 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.495543956756592\n",
      "Replication # -------------->>>>>  4\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.181252479553223, Y2_pred mean:  3.3827593326568604, Y1_pred+Y2_pred mean: 7.564012050628662 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.5309648513793945\n",
      "Replication # -------------->>>>>  5\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.170168876647949, Y2_pred mean:  3.3605494499206543, Y1_pred+Y2_pred mean: 7.5307183265686035 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.518710494041443\n",
      "Replication # -------------->>>>>  6\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.1459455490112305, Y2_pred mean:  3.3032026290893555, Y1_pred+Y2_pred mean: 7.449147701263428 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.392635107040405\n",
      "Replication # -------------->>>>>  7\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.173537731170654, Y2_pred mean:  3.288161039352417, Y1_pred+Y2_pred mean: 7.461698055267334 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.4424355030059814\n",
      "Replication # -------------->>>>>  8\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.101849555969238, Y2_pred mean:  3.3445677757263184, Y1_pred+Y2_pred mean: 7.446417331695557 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.45654559135437\n",
      "Replication # -------------->>>>>  9\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.123665809631348, Y2_pred mean:  3.3805267810821533, Y1_pred+Y2_pred mean: 7.50419282913208 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.423767685890198\n",
      "Replication # -------------->>>>>  10\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.15866756439209, Y2_pred mean:  3.3413941860198975, Y1_pred+Y2_pred mean: 7.500062942504883 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.479176878929138\n",
      "Replication # -------------->>>>>  11\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.1536431312561035, Y2_pred mean:  3.3733582496643066, Y1_pred+Y2_pred mean: 7.527001857757568 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.51748526096344\n",
      "Replication # -------------->>>>>  12\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.172242641448975, Y2_pred mean:  3.338691473007202, Y1_pred+Y2_pred mean: 7.510933876037598 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.483167052268982\n",
      "Replication # -------------->>>>>  13\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.158085346221924, Y2_pred mean:  3.33998441696167, Y1_pred+Y2_pred mean: 7.498070240020752 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.4770989418029785\n",
      "Replication # -------------->>>>>  14\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.158217430114746, Y2_pred mean:  3.39768385887146, Y1_pred+Y2_pred mean: 7.555901527404785 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.544078230857849\n",
      "Replication # -------------->>>>>  15\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.170735836029053, Y2_pred mean:  3.381584644317627, Y1_pred+Y2_pred mean: 7.55232048034668 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.498168587684631\n",
      "Replication # -------------->>>>>  16\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.143442630767822, Y2_pred mean:  3.356200933456421, Y1_pred+Y2_pred mean: 7.499643802642822 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.453324675559998\n",
      "Replication # -------------->>>>>  17\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.187196731567383, Y2_pred mean:  3.3643102645874023, Y1_pred+Y2_pred mean: 7.551506042480469 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.48749566078186\n",
      "Replication # -------------->>>>>  18\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.133761882781982, Y2_pred mean:  3.4027369022369385, Y1_pred+Y2_pred mean: 7.5364990234375 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.513056039810181\n",
      "Replication # -------------->>>>>  19\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.161636829376221, Y2_pred mean:  3.396273612976074, Y1_pred+Y2_pred mean: 7.557910919189453 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.556613445281982\n",
      "Replication # -------------->>>>>  20\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.129863739013672, Y2_pred mean:  3.3724184036254883, Y1_pred+Y2_pred mean: 7.502281188964844 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.537987112998962\n",
      "Replication # -------------->>>>>  21\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.160529136657715, Y2_pred mean:  3.3687756061553955, Y1_pred+Y2_pred mean: 7.529304027557373 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.5093674659729\n",
      "Replication # -------------->>>>>  22\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.168691635131836, Y2_pred mean:  3.3687753677368164, Y1_pred+Y2_pred mean: 7.537467002868652 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.501312613487244\n",
      "Replication # -------------->>>>>  23\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.078057765960693, Y2_pred mean:  3.3829948902130127, Y1_pred+Y2_pred mean: 7.461052417755127 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.4257320165634155\n",
      "Replication # -------------->>>>>  24\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.137468338012695, Y2_pred mean:  3.306493043899536, Y1_pred+Y2_pred mean: 7.443962097167969 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.412825703620911\n",
      "Replication # -------------->>>>>  25\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.163376331329346, Y2_pred mean:  3.3805270195007324, Y1_pred+Y2_pred mean: 7.543903827667236 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.547562837600708\n",
      "Replication # -------------->>>>>  26\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.190920352935791, Y2_pred mean:  3.397566318511963, Y1_pred+Y2_pred mean: 7.588486671447754 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.539770007133484\n",
      "Replication # -------------->>>>>  27\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.165080547332764, Y2_pred mean:  3.340806722640991, Y1_pred+Y2_pred mean: 7.505887508392334 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.499462127685547\n",
      "Replication # -------------->>>>>  28\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.159284591674805, Y2_pred mean:  3.3210644721984863, Y1_pred+Y2_pred mean: 7.480349063873291 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.443457007408142\n",
      "Replication # -------------->>>>>  29\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.123684883117676, Y2_pred mean:  3.3767664432525635, Y1_pred+Y2_pred mean: 7.500451564788818 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.468150019645691\n",
      "Replication # -------------->>>>>  30\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.176850318908691, Y2_pred mean:  3.375826358795166, Y1_pred+Y2_pred mean: 7.552676200866699 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.510013103485107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup_logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration and set up the device\n",
    "#config = load_config()\n",
    "\n",
    "config = {\"f_model\": \"DQlearning\", # DQlearning, surr_opt\n",
    "          \"setting\": \"tao\",\n",
    "          \"surrogate_num\": 1,\n",
    "          \"option_sur\": 4,\n",
    "          \"device\": None,\n",
    "          \"noiseless\": True,\n",
    "          \"sample_size\": 30000,\n",
    "          \"num_replications\": 30,\n",
    "          \"job_id\": \"tao\",\n",
    "          \"training_validation_prop\": 0.7,\n",
    "          \"n_epoch\": 150,\n",
    "          \"batch_size\": 3000,\n",
    "          \"num_networks\": 2,\n",
    "          \"activation_function\": \"elu\",\n",
    "          \"input_dim_stage1\": 5,\n",
    "          \"output_dim_stage1\": 1,\n",
    "          \"input_dim_stage2\": 7,\n",
    "          \"output_dim_stage2\": 1,\n",
    "          \"hidden_dim_stage1\": 20,\n",
    "          \"hidden_dim_stage2\": 20,\n",
    "          \"dropout_rate\": 0.4,\n",
    "          \"num_layers\": 1,\n",
    "          \"optimizer_type\": \"adam\",\n",
    "          \"optimizer_lr\": 0.07,\n",
    "          \"optimizer_weight_decay\": 0.001,\n",
    "          \"use_scheduler\": True,\n",
    "          \"scheduler_type\": \"reducelronplateau\",\n",
    "          \"scheduler_step_size\": 30,\n",
    "          \"scheduler_gamma\": 0.8,\n",
    "          \"initializer\": \"he\"\n",
    "          }\n",
    "\n",
    "\n",
    "print(\"Model used: %s\", config['f_model'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config['device'] = device\n",
    "\n",
    "# Get the SLURM_JOB_ID from environment variables\n",
    "job_id = os.getenv('SLURM_JOB_ID')\n",
    "\n",
    "# If job_id is None, set it to the current date and time formatted as a string\n",
    "if job_id is None:\n",
    "    job_id = datetime.now().strftime('%Y%m%d%H%M%S')  # Format: YYYYMMDDHHMMSS\n",
    "\n",
    "config['job_id'] = job_id\n",
    "\n",
    "training_validation_prop = config['training_validation_prop']\n",
    "train_size = int(training_validation_prop * config['sample_size'])\n",
    "print(\"Training size: %d\", train_size)\n",
    "\n",
    "if config['f_model'] != 'surr_opt':\n",
    "    config['input_dim_stage1'] = 6\n",
    "    config['input_dim_stage2'] = 8\n",
    "    config['num_networks'] = 1\n",
    "\n",
    "V_replications = {\n",
    "    \"V_replications_M1_pred\": [],\n",
    "    \"V_replications_M1_behavioral\": [],\n",
    "    \"V_replications_M1_optimal\": [],\n",
    "    \"V_replications_estimator\": []\n",
    "    }\n",
    "\n",
    "V_replications, df, losses_dict, epoch_num_model_lst = simulations( V_replications, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "11EFbOC1b8V0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrrQksdhkZ-k"
   },
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze_TrBppYztl",
    "outputId": "a3f058fd-2692-4442-fdd1-114f46deee8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.500905990600586,\n",
      " 7.480799198150635,\n",
      " 7.495543956756592,\n",
      " 7.5309648513793945,\n",
      " 7.518710494041443,\n",
      " 7.392635107040405,\n",
      " 7.4424355030059814,\n",
      " 7.45654559135437,\n",
      " 7.423767685890198,\n",
      " 7.479176878929138,\n",
      " 7.51748526096344,\n",
      " 7.483167052268982,\n",
      " 7.4770989418029785,\n",
      " 7.544078230857849,\n",
      " 7.498168587684631,\n",
      " 7.453324675559998,\n",
      " 7.48749566078186,\n",
      " 7.513056039810181,\n",
      " 7.556613445281982,\n",
      " 7.537987112998962,\n",
      " 7.5093674659729,\n",
      " 7.501312613487244,\n",
      " 7.4257320165634155,\n",
      " 7.412825703620911,\n",
      " 7.547562837600708,\n",
      " 7.539770007133484,\n",
      " 7.499462127685547,\n",
      " 7.443457007408142,\n",
      " 7.468150019645691,\n",
      " 7.510013103485107]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(V_replications[\"V_replications_estimator\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GBmljhZ-jNWB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "3fAYECnwaLly",
    "outputId": "48ae69aa-19bb-4884-ab2c-49ca97deb2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bias for the estimator: 0.031125597159067788\n",
      "Standard Deviation for the estimator: 0.02091825727331583\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAHHCAYAAADkj8/RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADFAUlEQVR4nOydeXhTZfr+75OkSZrue8vWskMpUNlBEBSwVWRxYRMFkdFxQVEUFUdFvvwcxBHcYEBUHFyQRUfci4gy4lBl2ARkR6AsXehC9yZt8v7+SN+TpE3bnORkafJ8rquXkpycvNnOec6z3LfAGGMgCIIgCIIgfAqFtxdAEARBEARBNIaCNIIgCIIgCB+EgjSCIAiCIAgfhII0giAIgiAIH4SCNIIgCIIgCB+EgjSCIAiCIAgfhII0giAIgiAIH4SCNIIgCIIgCB+EgjSCIAiCIAgfpFUHaSkpKbjlllta3G7nzp0QBAE7d+50/6LcxIsvvghBELy9jCbJz8/HHXfcgZiYGAiCgNdff93bSyLcSEpKCu655x7x3978jTVciy9y880347777vPoc7pyzPjXv/4FQRBw7tw5eRfl55w7dw6CIOBf//qXx5/b188RgcyaNWvQoUMH6PV6yY/1SpA2YcIE6HQ6lJeXN7nNjBkzoFarUVRU5MGVEc7y+OOPY9u2bVi4cCE+/PBDZGZmuv35+vXrh+joaOh0OvTs2RMvvvgiKioqGm2r1+vx9NNPo02bNggODsbgwYOxffv2ZvfPgw5H/uTg6NGjePHFFx0+KfIDMv8LCgpCSkoKHn30UVy9elWWNfkSu3fvxosvvtgqX9t///tffP/993j66acBmINKR75X3jjR+wq//PILbrrpJrRt2xZarRYdOnTA+PHjsWHDBm8vzeNUVFRg0aJFSEtLQ0hICGJiYpCeno558+bh8uXL3l5eI6qqqrBq1SrceOONSEpKQlhYGK655hqsXr0aRqOx0fYvvfQSJkyYgISEBAiCgBdffLHJfV+6dAlTpkxBZGQkwsPDMXHiRPz55592t33vvffQs2dPaLVadO3aFW+99ZbL+7TH7t27MXz4cOh0OiQmJuLRRx9tdB665557YDAY8Pbbbzu8XxHmBTZu3MgAsPXr19u9v7KykoWEhLDx48c3u5/k5GQ2bty4Fp/PaDSy6upqZjQanVqvL7Bo0SLmpY/LIRISEtiMGTM89nzXXnste/TRR9mbb77J1q5dyx588EGm0WjYtdde2+hznjZtGlOpVOzJJ59kb7/9Nhs6dChTqVRs165dTe4/Ly+PffjhhzZ/7dq1Yz169Gh0uxxs2bKFAWA//fSTQ9vz78Pq1avZhx9+yNasWcMmT57MALBrr71WljU1R3JyMps1a5b4b3f/xv7xj38wAOzs2bON7qupqWEGg8EtzysHEydOZDfeeKP4788//9zm+zN9+nQGgL322ms2t585c8al562trWXV1dVOPbauro5VV1czk8nk0hqcYfPmzUwQBHbNNdewZcuWsbVr17KFCxeya6+9lo0aNcrj65HC2bNnGQD2/vvvy7I/g8HArrnmGhYcHMweeOABtmbNGvbqq6+y2bNns9jYWJvjhSuft5wcPnyYCYLAxowZw1555RW2Zs0aduuttzIAbObMmY22B8ASExNZRkYGA8AWLVpkd7/l5eWsa9euLD4+ni1btoytWLGCtW/fnrVr144VFhbabLtmzRoGgN1+++1s7dq17O6772YA2Msvv+z0Pu1x4MABptVq2TXXXMNWr17N/va3vzGNRsMyMzMbbfvUU0+x5ORkyb8pr5z1q6qqWFhYGMvIyLB7/4YNGxgAtnHjxmb342iQ5g/4epAmCAJ7+OGHZdufMyf8V199lQFg2dnZ4m2//fYbA8D+8Y9/2Oy7c+fObOjQoZL236tXLzZy5EhJj3EUZ4O0K1eu2Nw+depUBoD99ttvblilhYZBmrtpLkjzZfLz85lKpWLvvvtuk9s4+toqKipkXp1vkpqaynr16sX0en2j+/Lz872wIseRO0jbvHkzA8A+/vjjRvdVV1ez0tJSWZ5HTq5cucKOHDnS6PbZs2czAOzUqVM2t/Pv/ZUrV5oN0pYtW8YAsD179oi3HTt2jCmVSrZw4ULxtqqqKhYTE9MoNpgxYwYLCQlhxcXFkvfZFDfddBNLSkqy+RzeeecdBoBt27bNZtu9e/cyAGzHjh0t7tcar5Q7g4ODcdttt2HHjh0oKChodP+GDRsQFhaGCRMmOLS/77//Hunp6dBqtUhNTcW///1vm/vt9cvs2rULkydPRocOHaDRaNC+fXs8/vjjqK6utnlsXl4eZs+ejXbt2kGj0SApKQkTJ05stiz16quvQhAEnD9/vtF9CxcuhFqtRklJiaR1NKS53gd7KeNLly7h3nvvRUJCAjQaDXr16oV169Y1euxbb72FXr16QafTISoqCgMGDGi2xMB7VxhjWLVqVaMS4J9//onJkyeLZckhQ4bgm2++sdkH/3w2btyI5557Dm3btoVOp0NZWVmz70FDUlJSAMCmJPbpp59CqVTi/vvvF2/TarWYM2cOsrOzceHCBUnP0ZCrV6/iscceQ/v27aHRaNClSxcsW7YMJpPJZruNGzeif//+CAsLQ3h4OHr37o033ngDgPk9nDx5MgDg+uuvF99DZ/q7RowYAQA4c+aMze2//fYbMjMzERERAZ1Oh5EjR+K///2vzTa8hHr8+HFMmTIF4eHhiImJwbx581BTU9Ps8zbVk/bbb7/h5ptvRlRUFEJCQtCnTx/xdQPAoUOHcM8996BTp07QarVITEzEvffea9Pm8OKLL2LBggUAgI4dO4rvD/8N2utJk/K927x5M1566SW0a9cOWq0Wo0ePxunTp222PXXqFG6//XYkJiZCq9WiXbt2mDZtGkpLS5t9X7755hvU1dVhzJgxzW7XkHvuuQehoaE4c+YMbr75ZoSFhWHGjBkAHD9m2OtREgQBc+fOxdatW5GWliYeC7Kysmy2s9eTxnuAf/nlFwwaNAharRadOnXCBx980Gj9hw4dwsiRIxEcHIx27drh//2//4f333/foT63M2fOYODAgVCr1Y3ui4+Pt/n3q6++imHDhiEmJgbBwcHo378/Pv3000aP4697y5YtSE1NRXBwMIYOHYrDhw8DAN5++2106dIFWq0Wo0aNarTGUaNGIS0tDfv27cOwYcMQHByMjh07Ys2aNc2+Fs7x48dxxx13IDo6GlqtFgMGDMCXX37Z4uP47/jaa69tdJ9Wq0V4eLj474af9z333NNkKd36/KDX67Fo0SJ06dJF/D499dRTjfqnCgsLcfz4cVRVVTW75tjYWPTq1avR7bfeeisA4NixYza38+N2S3z66acYOHAgBg4cKN7Wo0cPjB49Gps3bxZv++mnn1BUVISHHnrI5vEPP/wwKisrbY4Dju7THmVlZdi+fTvuuusum89h5syZCA0NbfT4/v37Izo6Gl988YVDr5ejkrS1jMyYMQPr16/H5s2bMXfuXPH24uJibNu2DdOnT0dwcHCL+zl16hSmTp2KBx54ALNmzcL777+PyZMnIysrC2PHjm3ycVu2bEFVVRUefPBBxMTEYM+ePXjrrbdw8eJFbNmyRdzu9ttvxx9//IFHHnkEKSkpKCgowPbt25GTk9Pkl2vKlCl46qmnsHnzZvHkwtm8eTNuvPFGREVFSVqHK+Tn52PIkCHigSouLg7fffcd5syZg7KyMjz22GMAgHfeeQePPvoo7rjjDvHEfOjQIfz222+488477e77uuuuw4cffoi7774bY8eOxcyZM22ed9iwYaiqqsKjjz6KmJgYrF+/HhMmTMCnn34q/mg5S5YsgVqtxpNPPgm9Xm/3IG1NXV0drl69CoPBgCNHjuC5555DWFgYBg0aJG5z4MABdOvWzeZHBEDc5uDBg2jfvr3D76U1VVVVGDlyJC5duoS//vWv6NChA3bv3o2FCxciNzdXHJ7Yvn07pk+fjtGjR2PZsmUAzAeq//73v5g3bx6uu+46PProo3jzzTfx7LPPomfPngAg/lcK/OTCv18A8OOPP+Kmm25C//79sWjRIigUCrz//vu44YYbsGvXLpv3CzB/f1NSUrB06VL8+uuvePPNN1FSUmL3ZNwc27dvxy233IKkpCTMmzcPiYmJOHbsGL7++mvMmzdP3ObPP//E7NmzkZiYiD/++ANr167FH3/8gV9//RWCIOC2227DyZMn8cknn+C1115DbGwsACAuLs7u80r93r388stQKBR48sknUVpaildeeQUzZszAb7/9BgAwGAzIyMiAXq/HI488gsTERFy6dAlff/01rl69ioiIiCbfg927dyMmJgbJycmS3jvA/P3OyMjA8OHD8eqrr0Kn0wFw/Zjxyy+/4N///jceeughhIWF4c0338Ttt9+OnJwcxMTENPvY06dP44477sCcOXMwa9YsrFu3Dvfccw/69+8vnpgvXbokXmwsXLgQISEhePfdd6HRaBx63cnJydixYwcuXryIdu3aNbvtG2+8gQkTJmDGjBkwGAzYuHEjJk+ejK+//hrjxo2z2XbXrl348ssv8fDDDwMAli5diltuuQVPPfUU/vnPf+Khhx5CSUkJXnnlFdx777348ccfbR5fUlKCm2++GVOmTMH06dOxefNmPPjgg1Cr1bj33nubXOMff/yBa6+9Fm3btsUzzzyDkJAQbN68GZMmTcJnn33W6PvY8L0AgA8++ADPPfecpB7Yv/71r40uDrKysvDxxx+Lwa7JZMKECRPwyy+/4P7770fPnj1x+PBhvPbaazh58iS2bt0qPnblypVYvHgxfvrpJ4waNcrhdXDy8vIAQPz9SsFkMuHQoUN23+dBgwbh+++/R3l5OcLCwnDgwAEAwIABA2y269+/PxQKBQ4cOIC77rpL0j7tcfjwYdTV1TV6HrVajfT0dHEd1vTr16/RxXGLSMq7yUhdXR1LSkpqVHLiteSGqUJ7JCcnMwDss88+E28rLS1lSUlJ7JprrhFv++mnnxqVkqqqqhrtb+nSpUwQBHb+/HnGGGMlJSWNSmWOMnToUNa/f3+b2/bs2cMAsA8++EDSOhhrXO5sLq2OBinjOXPmsKSkpEY19mnTprGIiAhxDRMnTmS9evWS9Dqtn7NhufOxxx5jAGx6v8rLy1nHjh1ZSkqKWM7kn0+nTp3svh9NkZ2dzQCIf927d29ULuzVqxe74YYbGj32jz/+YADYmjVrHH6+huXOJUuWsJCQEHby5Emb7Z555hmmVCpZTk4OY4yxefPmsfDwcFZXV9fkvp0td544cYJduXKFnTt3jq1bt44FBwezuLg4VllZyRhjzGQysa5du7KMjAybXoiqqirWsWNHNnbs2Eb7nDBhgs1zPfTQQwwA+/3338XbGpY7G/7G6urqWMeOHVlycjIrKSmx2V/DdTTkk08+YQDYzz//LN7WXEmw4Vqkfu969uxpU1p74403GAB2+PBhxpi57wQA27JlS6Pnbonhw4c3Og40xN5rmzVrFgPAnnnmmUbbO3vMYMz8O1Wr1ez06dPibb///jsDwN566y3xtvfff7/Rmvjx1vpzKSgoYBqNhj3xxBPibY888ggTBIEdOHBAvK2oqIhFR0c7VNZ97733xHVef/317Pnnn2e7du2y2/7Q8L0wGAwsLS2t0W8eANNoNDbP/fbbb4v9UGVlZeLtCxcubLTOkSNHMgBs+fLl4m16vZ6lp6ez+Ph4sSfS3nF59OjRrHfv3qympka8zWQysWHDhrGuXbs2+15UVVWx7t27MwAsOTmZ3XPPPey9996zW/ZtqSXm1KlTLCIigo0dO1Y8Fn344YdMoVA06s/l5+H//ve/jfbv6DHKGr1ez1JTU1nHjh1ZbW2t3W2aK3fy+/7v//6v0X2rVq1iANjx48cZY4w9/PDDTKlU2n2OuLg4Nm3aNMn7tAc/Zlv/HjiTJ09miYmJjW6///77WXBwcJP7tIfXJDiUSiWmTZuG7Oxsm9Tyhg0bkJCQgNGjRzu0nzZt2thciYSHh2PmzJk4cOCAGLnbwzpLV1lZicLCQgwbNgyMMTECDg4Ohlqtxs6dO8XypKNMnToV+/btsyk7bdq0CRqNBhMnTpS0DldgjOGzzz7D+PHjwRhDYWGh+JeRkYHS0lLs378fABAZGYmLFy/if//7n8vPCwDffvstBg0ahOHDh4u3hYaG4v7778e5c+dw9OhRm+1nzZrlUPaUk5qaiu3bt2Pr1q146qmnEBIS0miqprq62u4VvFarFe93li1btmDEiBGIioqyeV/HjBkDo9GIn3/+GYD5fa2srGxxotQZunfvjri4OKSkpODee+9Fly5d8N1334lZl4MHD+LUqVO48847UVRUJK6xsrISo0ePxs8//9yoNMszDZxHHnkEgPnzdJQDBw7g7NmzeOyxxxAZGWlzn3U2wPrzrqmpQWFhIYYMGQIA4vdSKlK/d7Nnz7bJ2vKSMZ/w4pmybdu2tVjqaUhRUZFNVlMqDz74YKPbXD1mjBkzBp07dxb/3adPH4SHhzs00Zaamiq+P4A5m9m9e3ebx2ZlZWHo0KFIT08Xb4uOjhbLtS1x7733IisrC6NGjcIvv/yCJUuWYMSIEejatSt2795ts631e1FSUoLS0lKMGDHC7ndn9OjRNtWPwYMHAzBXS6yzJfz2hu+HSqXCX//6V/HfarUaf/3rX1FQUIB9+/bZfS3FxcX48ccfMWXKFJSXl4u/v6KiImRkZODUqVO4dOlSk+9FcHAwfvvtN7Ei869//Qtz5sxBUlISHnnkEYclHSorK3HrrbciKioKn3zyCZRKJQDzMaxnz57o0aOHzTHshhtuAGAuHXJefPFFMMacyqLNnTsXR48excqVK6FSSS/g8eO0I8fy6urqJqswWq3WZjtH9+nMmuw9NioqCtXV1ZKOI17VSeM/Wt7zdPHiRezatQvTpk0Tv0Qt0aVLl0Yp4G7dugFAs70POTk5uOeeexAdHY3Q0FDExcVh5MiRACD2mWg0GixbtgzfffcdEhIScN111+GVV15pNvjjTJ48GQqFAps2bQJgDpa2bNmCm266yab05sg6XOHKlSu4evUq1q5di7i4OJu/2bNnA4DYF/j0008jNDQUgwYNQteuXfHwww9LT81acf78eXTv3r3R7byM17Bnr2PHjpL2Hx4ejjFjxmDixIlYtmwZnnjiCUycOBG///67uE1wcLDdAxnvsZISFDbk1KlTyMrKavS+8hIDf18feughdOvWDTfddBPatWsnnoTk4LPPPsP27duxYcMGDBkyBAUFBTav6dSpUwDMAXDDdb777rvQ6/WNvmddu3a1+Xfnzp2hUCgkaWbxi5O0tLRmtysuLsa8efOQkJCA4OBgxMXFid8DZ7//Ur93HTp0sPk3D6r4hVnHjh0xf/58vPvuu4iNjUVGRgZWrVrl8PoYY5JfA2AOCuyV+1w9ZjR8vYD5NTtyIerIY8+fP48uXbo02s7ebU2RkZGBbdu24erVq/j555/x8MMP4/z587jlllts+pi//vprDBkyBFqtFtHR0YiLi8Pq1avtvg8N186D74btDvz2hu9HmzZtEBISYnNbS+ea06dPgzGG559/vtHvb9GiRQBgty+74XpeeeUVnDt3DufOncN7772H7t27Y+XKlViyZEmzj+Xcd999OHPmDD7//HObkvapU6fwxx9/NFobf10trc0R/vGPf+Cdd97BkiVLcPPNNzu1D35Mc+RYHhwcDIPBYHc/NTU1Nts5uk9n1mTvsfxYIKVs7bWeNMBcI+7Rowc++eQTPPvss/jkk0/AGHP4istZjEYjxo4di+LiYjz99NPo0aMHQkJCcOnSJdxzzz02mYXHHnsM48ePx9atW7Ft2zY8//zzWLp0KX788Udcc801TT5HmzZtMGLECGzevBnPPvssfv31V+Tk5Ig9SVLX0ZCmPuSGOjR8H3fddRdmzZpl9zF9+vQBYD6JnThxAl9//TWysrLw2Wef4Z///CdeeOEFLF68uMm1yIUrARMA3Hbbbbj77ruxceNG9O3bFwCQlJRk90o1NzcXgPlzchaTyYSxY8fiqaeesns/P9DFx8fj4MGD2LZtG7777jt89913eP/99zFz5kysX7/e6ecHzD2BvMdj/Pjx6N27N2bMmIF9+/ZBoVCIn/8//vEPm8yGNaGhoc0+hzsFMqdMmYLdu3djwYIFSE9PR2hoKEwmEzIzM5v9/stJUxeE1sHV8uXLcc899+CLL77A999/j0cffVTs2WuubyomJkZyFp6j0WigUNheR7tyzOA48nrd8Vhn0Ol0GDFiBEaMGIHY2FgsXrwY3333HWbNmoVdu3ZhwoQJuO666/DPf/4TSUlJCAoKwvvvv2932KmptbvzNfHP48knn0RGRobdbaQEr8nJybj33ntx6623olOnTvj444/x//7f/2v2MW+88QY++eQTfPTRR42OASaTCb1798aKFSvsPtbZfl3Ov/71Lzz99NN44IEH8Nxzzzm9n+joaGg0GvG4bU3DY3lSUhKMRiMKCgpsBk0MBgOKiorE7aTs0x5JSUk22zZ8vL3HlpSUQKfTSTrXeTVIA8zZtOeffx6HDh3Chg0b0LVrV5tJi5bgVyrWJ5KTJ08CaHpq5PDhwzh58iTWr19v0+jeVDmqc+fOeOKJJ/DEE0/g1KlTSE9Px/Lly/HRRx81u7apU6fioYcewokTJ7Bp0ybodDqMHz/e6XVYw6/2G4p7NswSxMXFISwsDEaj0aEJs5CQEEydOhVTp06FwWDAbbfdhpdeegkLFy4UU8COkpycjBMnTjS6/fjx4+L9cqLX62EymWyuotPT0/HTTz+hrKzMJoPJm8KbClwcoXPnzqioqHDofVWr1Rg/fjzGjx8Pk8mEhx56CG+//Taef/55u9lgZwgNDcWiRYswe/ZsbN68GdOmTRPLWjzr6AinTp2yyWqePn0aJpPJ4SksAOLzHjlypMnnLSkpwY4dO7B48WK88MILNs/fECnvj7u+d71790bv3r3x3HPPYffu3bj22muxZs2aZk+SPXr0wGeffebU89nDlWOGp0hOTm40HQvA7m1S4A3a/KT42WefQavVYtu2bTYlp/fff9+l52mKy5cvo7Ky0iab1tK5plOnTgCAoKAgyRO+zREVFYXOnTvjyJEjzW63a9cuPPnkk3jsscfsJj86d+6M33//HaNHj5b9YuyLL77AX/7yF9x2221YtWqVS/tSKBTo3bs39u7d2+i+3377DZ06dRJL1vyYvnfvXpvM3d69e2EymcT7pezTHmlpaVCpVNi7dy+mTJki3m4wGHDw4EGb2zhnz56VPBDmdVso/sV54YUXcPDgQclZtMuXL+Pzzz8X/11WVoYPPvgA6enpSExMtPsYfuVkfaXEGLORBgDM03sNpQc6d+6MsLAwh3oBbr/9diiVSnzyySfYsmULbrnlFpsfuKPrsEd4eDhiY2PFvifOP//5T5t/K5VK3H777fjss8/s/qCvXLki/n9Ddwe1Wo3U1FQwxlBbW9vimhpy8803Y8+ePcjOzhZvq6ysxNq1a5GSkoLU1FTJ+wTMgam99bz77rsAbKd67rjjDhiNRqxdu1a8Ta/X4/3338fgwYNdulKcMmUKsrOzsW3bNrtrrKurA9D4fVUoFGL2kn+P+PfCVUX9GTNmoF27dmLGtn///ujcuTNeffVVu24M1p8/p+EBlSt133TTTQ6vo1+/fujYsSNef/31Rq+Jf9/tff8B2LUUk/L+yP29KysrEz9LTu/evaFQKFo8DgwdOhQlJSWSFMybw5VjhqfIyMhAdnY2Dh48KN5WXFyMjz/+2KHH79ixw+7tvCeSl7KVSiUEQbCpHpw7d85mIlFO6urqbBTjuYJ8XFwc+vfvb/cx8fHxGDVqFN5++227GRd7vz9rfv/9dxQWFja6/fz58zh69Kjdsj4nNzcXU6ZMwfDhw/GPf/zD7jZTpkzBpUuX8M477zS6r7q6GpWVleK/HZXgAICff/4Z06ZNw3XXXYePP/64UUbYGe644w7873//swmqTpw4gR9//FGUMAKAG264AdHR0Vi9erXN41evXg2dTmcz9evoPgHzRV5OTo7474iICIwZMwYfffSRjXvShx9+iIqKikaPB8x9tsOGDZP0ur2eSevYsSOGDRsmaodIDdK6deuGOXPm4H//+x8SEhKwbt065OfnN3s11aNHD3Tu3BlPPvkkLl26hPDwcHz22WeNyhInT57E6NGjMWXKFKSmpkKlUuHzzz9Hfn4+pk2b1uLa4uPjcf3112PFihUoLy/H1KlTnVpHU/zlL3/Byy+/jL/85S8YMGAAfv75Z/HKzpqXX34ZP/30EwYPHoz77rsPqampKC4uxv79+/HDDz+guLgYAHDjjTciMTER1157LRISEnDs2DGsXLkS48aNa/aKoimeeeYZfPLJJ7jpppvw6KOPIjo6GuvXr8fZs2fx2WefOf3D3blzpygV0rVrVxgMBuzatQv//ve/MWDAANx1113itoMHD8bkyZOxcOFCFBQUoEuXLli/fr3Y2+EKCxYswJdffolbbrlFlCGorKzE4cOH8emnn+LcuXOIjY3FX/7yFxQXF+OGG25Au3btcP78ebz11ltIT08Xr6rS09OhVCqxbNkylJaWQqPR4IYbbmikC9USQUFBmDdvHhYsWICsrCxkZmbi3XffxU033YRevXph9uzZaNu2LS5duoSffvoJ4eHh+Oqrr2z2cfbsWUyYMAGZmZnIzs7GRx99hDvvvFMsITuCQqHA6tWrMX78eKSnp2P27NlISkrC8ePH8ccff2Dbtm0IDw8X+zxra2vRtm1bfP/99zh79myj/fGT4N/+9jdMmzYNQUFBGD9+fKMeIUD+792PP/6IuXPnYvLkyejWrRvq6urw4YcfihdAzTFu3DioVCr88MMPNlp9zuLqMcMTPPXUU/joo48wduxYPPLII6IER4cOHVBcXNxixmbixIno2LEjxo8fj86dO6OyshI//PADvvrqKwwcOFCsRowbNw4rVqxAZmYm7rzzThQUFGDVqlXo0qULDh06JPvratOmDZYtW4Zz586hW7du2LRpEw4ePIi1a9ciKCioycetWrUKw4cPR+/evXHfffehU6dOyM/PR3Z2Ni5evGjTQ9uQ7du3Y9GiRZgwYQKGDBmC0NBQ/Pnnn1i3bh30en2zFkqPPvoorly5gqeeegobN260ua9Pnz7o06cP7r77bmzevBkPPPAAfvrpJ1x77bUwGo04fvw4Nm/ejG3btokXvY5KcJw/fx4TJkyAIAi44447GsnC8OfmfPjhhzh//rwY/P38889idvruu+8WM98PPfQQ3nnnHYwbNw5PPvkkgoKCsGLFCiQkJOCJJ54Q9xccHIwlS5bg4YcfxuTJk5GRkYFdu3bho48+wksvvYTo6GhxW0f3CZjbgUaOHGmjBfnSSy9h2LBhGDlyJO6//35cvHgRy5cvx4033tjIGnHfvn0oLi62GRx0CEmzoG6Cj7sOGjRI0uO448C2bdtYnz59mEajYT169Gg0Km9PguPo0aNszJgxLDQ0lMXGxrL77rtPHEXn49OFhYXs4YcfZj169GAhISEsIiKCDR48mG3evNnhNXL14bCwMLuWHY6sgzH749VVVVVszpw5LCIigoWFhbEpU6awgoICu2PM+fn57OGHH2bt27dnQUFBLDExkY0ePZqtXbtW3Obtt99m1113HYuJiWEajYZ17tyZLViwwCFVa9iR4GCMsTNnzrA77riDRUZGMq1WywYNGsS+/vprm2345+OoxMHp06fZzJkzWadOnVhwcDDTarWsV69ebNGiRXZV2aurq9mTTz7JEhMTmUajYQMHDmRZWVkOPZc19hwHysvL2cKFC1mXLl2YWq1msbGxbNiwYezVV18Vx/I//fRTduONN7L4+HimVqtZhw4d2F//+leWm5trs6933nmHderUiSmVyhZH3ZtyHGDMLEMTERFhs9YDBw6w2267Tfxsk5OT2ZQpU2zUr/k+jx49yu644w4WFhbGoqKi2Ny5cxt9d1uS4OD88ssvbOzYsSwsLIyFhISwPn362Eg9XLx4kd16660sMjKSRUREsMmTJ7PLly/b/Q4vWbKEtW3blikUChuJBHvuB6587xrKKPz555/s3nvvZZ07d2ZarZZFR0ez66+/nv3www+N3nt7TJgwgY0ePbrJ+5uS4AgJCbG7vSvHjKZ+pw3fw6YkOOw5vIwcObLR7+LAgQNsxIgRTKPRsHbt2rGlS5eyN998kwFgeXl5Tb4XjJklWKZNm8Y6d+4s/r5TU1PZ3/72NxupDMbMch1du3YVj/3vv/++w6+bf84NJZbsfS9GjhzJevXqxfbu3cuGDh3KtFotS05OZitXrrS7z4bSSGfOnGEzZ85kiYmJLCgoiLVt25bdcsst7NNPP232vfjzzz/ZCy+8wIYMGcLi4+OZSqVicXFxbNy4cezHH3+02bbh6+ayIfb+rH9bBoOBLVu2jPXq1YtpNBoWFRXF+vfvzxYvXmxz7HdUgoO/f448d0vrbPhcFy5cYHfccQcLDw9noaGh7JZbbmnkYMBZu3Yt6969O1Or1axz587stddes2vJ5Og+Adh1nNm1axcbNmwY02q1LC4ujj388MONvqeMMfb000+zDh06SLaFEuqfnCCIAOfFF1/E4sWLceXKFacEJwn77Nq1C6NGjcLx48cbTc4GEo899hjefvttVFRUODy97yuMGjUKhYWFLfaAEYQ99Ho9UlJS8Mwzz4hC3o7i9Z40giAIf2bEiBG48cYb8corr3h7KR6joUZUUVERPvzwQwwfPrzVBWgE4Srvv/8+goKC8MADD0h+rNd70giCIPyd7777zttL8ChDhw7FqFGj0LNnT+Tn5+O9995DWVkZnn/+eW8vjSA8zgMPPOBUgAZQkEYQBEHIzM0334xPP/0Ua9euhSAI6NevH9577z1cd9113l4aQbQqqCeNIAiCIAjCB6GeNIIgCIIgCB+EgjSCIAiCIAgfhHrS7GAymXD58mWEhYW51beQIAiCIAj5YIyhvLwcbdq0kcXpwNtQkGaHy5cvu2wsSxAEQRCEd7hw4QLatWvn7WW4DAVpduAWSBcuXLAx5SYIgiAIwncpKytD+/btnbIy9EUoSLMDL3GGh4dTkEYQBEEQrQx/aVVq/QVbgiAIgiAIP4SCNIIgCIIgCB+EgjSCIAiCIAgfhII0giAIgiAIH4SCNIIgCIIgCB+EgjSCIAiCIAgfhII0giAIgiAIH4SCNIIgCIIgCB+EgjSCIAiCIAgfhBwHCMJNGE0Me84Wo6C8BvFhWgzqGA2lwj9UsAmCIAj3Q0GaB6GTduCQdSQXi786itzSGvG2pAgtFo1PRWZakhdXRhAEQbQWvF7uXLVqFVJSUqDVajF48GDs2bOn2e23bNmCHj16QKvVonfv3vj2229t7q+oqMDcuXPRrl07BAcHIzU1FWvWrHHnS3CIrCO5GL7sR0x/51fM23gQ09/5FcOX/YisI7neXhohM1lHcvHgR/ttAjQAyCutwYMf7afPnCAIgnAIrwZpmzZtwvz587Fo0SLs378fffv2RUZGBgoKCuxuv3v3bkyfPh1z5szBgQMHMGnSJEyaNAlHjhwRt5k/fz6ysrLw0Ucf4dixY3jssccwd+5cfPnll556WY2gk3bgYDQxLP7qKJid+/hti786CqPJ3hYEQRAEYcGrQdqKFStw3333Yfbs2WLGS6fTYd26dXa3f+ONN5CZmYkFCxagZ8+eWLJkCfr164eVK1eK2+zevRuzZs3CqFGjkJKSgvvvvx99+/ZtMUPnLuikHVjsOVvcKBi3hgHILa3BnrPFnlsUQRAE0SrxWpBmMBiwb98+jBkzxrIYhQJjxoxBdna23cdkZ2fbbA8AGRkZNtsPGzYMX375JS5dugTGGH766SecPHkSN954o3teSAvQSTuwKChv+rN2ZjuCIAgicPHa4EBhYSGMRiMSEhJsbk9ISMDx48ftPiYvL8/u9nl5eeK/33rrLdx///1o164dVCoVFAoF3nnnHVx33XVNrkWv10Ov14v/Lisrc+Yl2YVO2oFFfJhW1u0IgiCIwMXrgwNy89Zbb+HXX3/Fl19+iX379mH58uV4+OGH8cMPPzT5mKVLlyIiIkL8a9++vWzroZN2YDGoYzSSIrRoamZXgHnKc1DHaE8uiyAIgmiFeC1Ii42NhVKpRH5+vs3t+fn5SExMtPuYxMTEZrevrq7Gs88+ixUrVmD8+PHo06cP5s6di6lTp+LVV19tci0LFy5EaWmp+HfhwgUXX50FOmkHFkqFgEXjU+3ex78Di8ankvQKQRAE0SJeC9LUajX69++PHTt2iLeZTCbs2LEDQ4cOtfuYoUOH2mwPANu3bxe3r62tRW1tLRQK25elVCphMpmaXItGo0F4eLjNn1zQSTvwyExLwuq7+iFSF2Rze2KEFqvv6kc6aQRBEIRDeFXMdv78+Zg1axYGDBiAQYMG4fXXX0dlZSVmz54NAJg5cybatm2LpUuXAgDmzZuHkSNHYvny5Rg3bhw2btyIvXv3Yu3atQCA8PBwjBw5EgsWLEBwcDCSk5Pxn//8Bx988AFWrFjhtdfJT9rPfn4ExZUG8fZEEjf1WzLTklBaXYunPzsMAHjkhi54bEw3CsYJgiAIh/FqkDZ16lRcuXIFL7zwAvLy8pCeno6srCxxOCAnJ8cmKzZs2DBs2LABzz33HJ599ll07doVW7duRVpamrjNxo0bsXDhQsyYMQPFxcVITk7GSy+9hAceeMDjr8+azLQkJIRrces/dyMyOAir7+pPjgN+TrXBKP5/QriWPmuCIAhCEgJjjAS6GlBWVoaIiAiUlpbKWvo8XVCBMSv+g4jgIPy+yDuSIITnWPnjKbz6/UkAwFOZ3fHQqC5eXhFBEIR/467zt7fwu+lOXyZEowQAVBnqvLwSwhNU6C2ZtLJq+swJgiAIaVCQ5kF0anN1udbIYKhrepCB8A8q9ZbArLym1osrIQiCIFojFKR5EJ1aKf4/ZdP8nwqrIK2shj5vgiAIQhoUpHmQIKUCapX5La+0aion/BObIK2aMmkEQRCENChI8zAh9dm0Kj1lVvydSptMGgVpBEEQhDQoSPMwvC+NMmn+T4VNTxoF5QRBEIQ0KEjzMOKEJ2XS/B4qdxIEQRCuQEGah+GZtAoK0vweKncSBEEQrkBBmoexaKVRudPfqbAqcdbUmkh2hSAIgpAEBWkextKTRpk0f8ZkYo36DkkrjSAIgpACBWkeJlRjDtKq9JRJ82eqai2fr1pp/pmRVhpBEAQhBQrSPAwXtKVMmn/DS51KhYDYUDUAGh4gCIIgpEFBmocJ4Zk06knza/hgSKhGhfDgIAA0PEAQBEFIg4I0DyNm0mi606+ptA7StOYgjbTSCIIgCClQkOZhQtSUSQsEeCYtRKNEeLD5M6dyJ0EQBCEFCtI8jE5DmbRAwLrcGaalcidBEAQhHQrSPAxl0gKDSjGTpkK4lmfSKDAnCIIgHIeCNA9D052Bgb3BAdJJIwiCIKRAQZqHCSGdtICgws7gAOmkEQRBEFKgIM3D8EwaeXf6N9blzjAtDQ4QBEEQ0qEgzcNYdNIoSPNnuJgt6aQRBEEQzkJBmoex9KRRudOfqagvZ4dqSSeNIAiCcA4K0jwM9+401JlQazR5eTWEu7CZ7iSdNIIgCMIJKEjzMLp6CQ6AZDj8GcvggNJKJ40yaQRBEITjUJDmYdQqBYKUAgDqS/NnLEFakKiTVqGvg9HEvLksgiAIohVBQZoX4Nm0SpLh8FsqrWyheCYNsAwUEARBEERLUJDmBULqhwcok+a/WOukqVUKBAeZP3Oa8CQIgiAchYI0L6DTUCbN37EO0gCIWmmlNDxAEARBOAgFaV6AMmn+DWNMLHfyII200giCIAipUJDmBcSeNJru9Euqa43g8wFcvJgPD5BWGkEQBOEoFKR5gRBNfSaNrKH8El7qFASLeLGYSaNyJ0EQBOEgFKR5AZ5JI/9O/4T3GoaqVRAEs9wKaaURBEEQUvGJIG3VqlVISUmBVqvF4MGDsWfPnma337JlC3r06AGtVovevXvj22+/tblfEAS7f//4xz/c+TIcRsykUbnTL+EyG7zUCVjKnZRJIwiCIBzF60Hapk2bMH/+fCxatAj79+9H3759kZGRgYKCArvb7969G9OnT8ecOXNw4MABTJo0CZMmTcKRI0fEbXJzc23+1q1bB0EQcPvtt3vqZTWLpSeNsir+iDjZqbUK0oLJv5MgCIKQhteDtBUrVuC+++7D7NmzkZqaijVr1kCn02HdunV2t3/jjTeQmZmJBQsWoGfPnliyZAn69euHlStXitskJiba/H3xxRe4/vrr0alTJ0+9rGbhGZYqkuDwS6x9OznhWpruJAiCIKTh1SDNYDBg3759GDNmjHibQqHAmDFjkJ2dbfcx2dnZNtsDQEZGRpPb5+fn45tvvsGcOXOaXIder0dZWZnNnzvhEhyUSfNPrH07OWFU7iQIgiAk4tUgrbCwEEajEQkJCTa3JyQkIC8vz+5j8vLyJG2/fv16hIWF4bbbbmtyHUuXLkVERIT41759e4mvRBo6yqT5NQ2FbAHSSSMIgiCk4/Vyp7tZt24dZsyYAa1W2+Q2CxcuRGlpqfh34cIFt66JMmn+jf1yJ+mkEQRBENJQtbyJ+4iNjYVSqUR+fr7N7fn5+UhMTLT7mMTERIe337VrF06cOIFNmzY1uw6NRgONRiNx9c7DBwdoutM/oUwaQRAEIQdezaSp1Wr0798fO3bsEG8zmUzYsWMHhg4davcxQ4cOtdkeALZv3253+/feew/9+/dH37595V24i3AJjkrSSfNL7AZpYk8afeYEQRCEY3g1kwYA8+fPx6xZszBgwAAMGjQIr7/+OiorKzF79mwAwMyZM9G2bVssXboUADBv3jyMHDkSy5cvx7hx47Bx40bs3bsXa9eutdlvWVkZtmzZguXLl3v8NbUEZdL8m+amO8trasEYE0VuCYIgCKIpvB6kTZ06FVeuXMELL7yAvLw8pKenIysrSxwOyMnJgUJhSfgNGzYMGzZswHPPPYdnn30WXbt2xdatW5GWlmaz340bN4IxhunTp3v09TiCRcyWsir+SHPlThMze7Za30cQBEEQ9vCJM8XcuXMxd+5cu/ft3Lmz0W2TJ0/G5MmTm93n/fffj/vvv1+O5clOCBezpelOv6SC20JZBWIalQJqpQIGowll1bUUpBEEQRAt4vfTnb4IN92urjXCaGJeXg0hN/bKnYIgWLTSaHiAIAiCcAAK0ryA9cmbSp7+B/fubJgtEyc8aXiAIAiCcAAK0ryARqWAor5vnIYH/A973p2AtVYaZdIIgiCIlqEgzQsIgiBm00iGw//gIsXWtlAAaaURBEEQ0qAgzUuEkAyHX8IYE8udIQ3KnWGklUYQBEFIgII0L6EjQVu/RF9nQl39MEijnjQt70mjTBpBEATRMhSkeQnKpPkn1kE3/4w5vNxZToE5QRAE4QAUpHkJHZms+yV8aECnVkKhsHUVsFhDUSaNIAiCaBkK0rwE71eqIkFbv8Ke2wAnTEuDAwRBEITjUJDmJSiT5p9U2nEb4IQH0+AAQRAE4TgUpHkJ6knzTyr05ixZw8lOwNZknSAIgiBagoI0L0HTnf6JPd9OjkUnjT5zgiAIomUoSPMSFpN1OmH7E/Z8OzlhNDhAEARBSICCNC8hZtKo3OlXWHw7lY3uC7caHGCMeXRdBEEQROuj8eU+4RF4OYwM1v2Lpnw7AUu5s9bIoK8zQRvUOJAjWi9GE8Oes8UoKK9BfJgWgzpGQ9lAhoUgCEIKFKR5CZ1Y7qRMmj/RXLkzRK2EQgBMzFzypCDNf8g6kovFXx1FbmmNeFtShBaLxqciMy3JiysjCKI1Q+VOLxFSL8FBmTT/QsykqRsHaYIgkFaaH5J1JBcPfrTfJkADgLzSGjz40X5kHcn10soIgmjtUJDmJXQayqT5I82VOwErrTSa8PQLjCaGxV8dhb0OQ37b4q+OwmiiHkSCIKRDQZqXoEyaf9JcuRMgk3V/Y8/Z4kYZNGsYgNzSGuw5W+y5RREE4TdQkOYlxJ40mu70K5qzhQKsZDgok+YXFJQ3HaA5sx1BEIQ1FKR5iZB6iYYq0knzK5oTswUok+ZvxIdpZd2OIAjCGgrSvATPpFXVGmGifhW/ocVyZzC3hqLg3B8Y1DEaSRFaNCW0IcA85TmoY7Qnl0UQhJ9AQZqX4Jk0xoCaOip5+gstlTvDabrTr1AqBCwan2r3Ph64LRqfSnppBEE4BQVpXkKrUkKoP25XUMnTb2hpupOsofyPzLQkrL6rH9Qq28NpYoQWq+/qRzppBEE4DYnZegmFQoAuSIlKgxFVeiMQ5u0VEa5iqDPBUGcCYF8nDSCTdX8lo1citCqF+PmHaJT45ekbKINGEIRLUCbNi4haaSTD4RdUWmVEQ+x4dwJAeH0mrZzKnX5FTnEVymrqxOx4pd4IE/mzEgThIhSkeRGLfyf1pPkDvNSpDVJApbT/0xIzaVTu9Ct+v1gKAOjTNkLMnhVVGLy5JIIg/AAK0ryIrl7QtpJ60vwCnhFtamgAIJ00f+XQhasAgL7tIxETogYAFFbovbgigiD8AQrSvEiImjJp/kRFTfPyGwDppPkrh3gmrV0kYkM1AIArFKQRBOEiFKR5EZ2GMmn+REvyGwAQQTppfofRxHDksjlI69suArFh5iCtsJyCNIIgXIOCNC9CmTT/orLebcCRTFp1rVGcBCRaN6cLKlBlMCJErUSnuFDEhprLnZRJIwjCVbwepK1atQopKSnQarUYPHgw9uzZ0+z2W7ZsQY8ePaDVatG7d298++23jbY5duwYJkyYgIiICISEhGDgwIHIyclx10twGrEnjaY7/YIKvbmE2VwmzVo/jSY8/YPfL14FAKTVDw3EiZk0GhwgCMI1vBqkbdq0CfPnz8eiRYuwf/9+9O3bFxkZGSgoKLC7/e7duzF9+nTMmTMHBw4cwKRJkzBp0iQcOXJE3ObMmTMYPnw4evTogZ07d+LQoUN4/vnnodX6nncez7hU6SmT5g+05NsJmBXq+f00POAfHKoP0vq2jwQAxNX3pNHgAEEQruLVIG3FihW47777MHv2bKSmpmLNmjXQ6XRYt26d3e3feOMNZGZmYsGCBejZsyeWLFmCfv36YeXKleI2f/vb33DzzTfjlVdewTXXXIPOnTtjwoQJiI+P99TLchjKpPkXLfl2ckgrzb+wDA1EAIA4OEBBGkEQruK1IM1gMGDfvn0YM2aMZTEKBcaMGYPs7Gy7j8nOzrbZHgAyMjLE7U0mE7755ht069YNGRkZiI+Px+DBg7F161a3vQ5XoEyaf2EZHLAvZMuxaKVRcN7a0dcZcSy3DADQt10kAArSCIKQD68FaYWFhTAajUhISLC5PSEhAXl5eXYfk5eX1+z2BQUFqKiowMsvv4zMzEx8//33uPXWW3HbbbfhP//5T5Nr0ev1KCsrs/nzBDyTVkGZNL/AEqQFNbudRSuNMmmtneO55ag1MkTpgtAuKhgAEBvGddKoJ40gCNfwK+9Ok8k8LTdx4kQ8/vjjAID09HTs3r0ba9aswciRI+0+bunSpVi8eLHH1skRpztJgsMvsJQ7W8ikkVaa38D70fq0i4RQ7wnFM2klVQbUGU1Nuk8QBEG0hNeOHrGxsVAqlcjPz7e5PT8/H4mJiXYfk5iY2Oz2sbGxUKlUSE1NtdmmZ8+ezU53Lly4EKWlpeLfhQsXnHlJkhF10kiCwy/gYrbNDQ4AlnInaaW1frgdVN/6fjQAiNKpoRAAxoDiSsqmEQThPF4L0tRqNfr3748dO3aIt5lMJuzYsQNDhw61+5ihQ4fabA8A27dvF7dXq9UYOHAgTpw4YbPNyZMnkZyc3ORaNBoNwsPDbf48gdiTRuVOv0Asd2odGxygcmfrxzqTxlEqBESHkOsAQRCu49Vy5/z58zFr1iwMGDAAgwYNwuuvv47KykrMnj0bADBz5ky0bdsWS5cuBQDMmzcPI0eOxPLlyzFu3Dhs3LgRe/fuxdq1a8V9LliwAFOnTsV1112H66+/HllZWfjqq6+wc+dOb7zEZrGUOymT5g/wKd2WpjvDqNzpF1Tq63C6oAIA0Kd9hM19saFqFFbocYVcBwiCcAGvBmlTp07FlStX8MILLyAvLw/p6enIysoShwNycnKgUFiSfcOGDcOGDRvw3HPP4dlnn0XXrl2xdetWpKWlidvceuutWLNmDZYuXYpHH30U3bt3x2effYbhw4d7/PW1BElw+BeOlztJJ80fOHKpFCYGJEVoER9mq8MYF6bB8bxyGh4gCMIlvD44MHfuXMydO9fuffayX5MnT8bkyZOb3ee9996Le++9V47luRWS4PAvHBGzBSyDA6ST1rppqI9mDQnaEgQhBzR25EVCrDJpjDEvr4ZwlUoHDNYB0knzF36304/GIZN1giDkgII0L6KrP5mbGKAns+1WTZ3RhOralg3WAdJJ8xcOiZOdkY3u4ybrlEkjCMIVKEjzIsFBFj2tStJKa9VYy6iQTpr/U1JpQE5xFQCgt51yp8V1gHrSCIJwHq/3pAUySoWA4CAlqmuNqDIYEePtBfkgRhPDnrPFKCivQXyYFoM6RkOpELy9rEbwIFutVECjcswWinTSWi+HLpmzaB1jQxAR3NhhgqyhCIKQAwrSvEyIxhyk0YRnY7KO5GLxV0eRW1oj3pYUocWi8anITEvy4soaU+Gg2wBgZbCur4PRxHwy6CSa59CFqwDsDw0AFKQRBCEPVO70Mrp6rTQqd9qSdSQXD3603yZAA4C80ho8+NF+ZB3J9dLK7OOokC1g0UkDLLIdROvid3GyM9Lu/dy/s7jSAKOJhoIIgnAOCtK8jKiVRjIcIkYTw+KvjsLeqY3ftviroz518hN9O9UtB2lqlQLaIPNPj4YHWifcaaBvE5m0aJ0agmAeCiqqpGwaQRDOQUGalyFrqMbsOVvcKINmDQOQW1qDPWeLPbeoFnBUyJYjDg9QkNbqyCutQUG5HkqFgF5t7AdpKqUCMSH1E57lNDxAEIRzOB2knT59Gtu2bUN1dTUAkM6Xk/AgjTJpFgrKmw7QnNnOE0gpdwKkldaa4fpoXeNDEaxuugeR+tIIgnAVyUFaUVERxowZg27duuHmm29Gbq65N2jOnDl44oknZF+gv8MFbSmTZqGhxY6r23kCsdzpYCaNtNJaL5ZSZ2Sz21GQRhCEq0gO0h5//HGoVCrk5ORAp9OJt0+dOhVZWVmyLi4QEAcHDJRJ4wzqGI2kCC2amnkUYJ7yHNQx2pPLahYxk+ZATxpAWmmtGdEOqr39UieHBG0JgnAVyUHa999/j2XLlqFdu3Y2t3ft2hXnz5+XbWGBApdsqKLpThGlQsCi8akA0ChQ4/9eND7Vp6QrRN9OieVO0kprXTDGmnUasIYEbQmCcBXJQVplZaVNBo1TXFwMjUYjy6ICCcqk2SczLQmr7+qH+HDb71RihBar7+rnczppUsud4VTubJWcL6pCaXUt1CoFuieGNbst+XcSBOEqkoO0ESNG4IMPPhD/LQgCTCYTXnnlFVx//fWyLi4QoJ60pslMS8JHcwaL/04I1+CXp2/wuQANsCp3OiBmC1i00mhwQF6MJobsM0X44uAlZJ8pkl2mhQ8NpCaFI0jZ/OGTZ9KuULmTIAgnkew48Morr2D06NHYu3cvDAYDnnrqKfzxxx8oLi7Gf//7X3es0a/R0XRns5Ra9WyV19TBhyqcNliCtMYWQfYID6ZMmtx4wqHCUupsvh8NsO5Jo3InQRDOITmTlpaWhpMnT2L48OGYOHEiKisrcdttt+HAgQPo3LmzO9bo11AmrXmKKi0nuCqDUQyGfI1KCbZQgGVwoJyCNFnwlEMFn+xsymnAGpruJAjCVZzy7oyIiMDf/vY3udcSkFAmrXmKK22zEAXlehtbJV/BkkkjnTRP05JDhQCzQ8XY1ESXhk3qjCYcuVQGAOjbwmQnAMTX96QVVejJo5UgCKeQHKT9/PPPzd5/3XXXOb2YQIRn0shg3T6NgrQyPTrHhXppNU0jNUgjnTT5kOJQMbRzjNPPc/pKBaprjQjVqNAptuXvYHSIxRqqpMogZtYIgiAcRXKQNmrUqEa3CYLlCtFopIyQFMhgvXmKKhpm0nzHZcAa6dOdZAslF55yqDh0wdyPltY2HAoHsmIqpQJROjWKKw0orNBTkEYQhGQk96SVlJTY/BUUFCArKwsDBw7E999/7441+jWiThpJcNiluIE59RUflTOQ6t0ZUT84QDppruMph4rfHXQasEYcHiD/ToIgnEByJi0ionEvxtixY6FWqzF//nzs27dPloUFChbvTjpZ24MPDkTpglBSVYsCHwzSTCYm6tw5LGZr5TjAGLPJRhPS4A4VeaU1dvvSBJj19Vx1qBCdBiQFaRqczK+g4QGCIJzCaYP1hiQkJODEiRNy7S5gCKkvd1YZjGRSbwfek9YzKRwAkF/me+XOqlpLFtTxnjRzkGZiJGTsKs05VHBcdajQ1xlxPM88NNDHAfkNDk14EgThCpIzaYcOHbL5N2MMubm5ePnll5Geni7XugIGXX25s87EYDCaoFE5JuEQKFgHabvPFKGgzPdOdrzUqVQI0Kgcu+7RBikQpBRQa2Qoq651OLgj7MMdKp7f+kcj8di5N3RxWSftWG45ao0M0SFqtIsKdvhxJGhLEIQrSD4zpKenQxCERlmfIUOGYN26dbItLFDQBVmCsiq9kYI0Kxhj4uBAj3oLHl8cHLCe7HS0bCkIAsK1QSiqNFBfmkxkpiUhSqfG1LW/IiZEjcEdo/HtkTzsPVfi8r4t+mgRkkrTsWHUk0YQhPNIDtLOnj1r82+FQoG4uDhota415QYqKqUCGpUC+joTKg11iApRe3tJPkOFvg4GowmApdzpiz1plRLlNzjhweYgjSY85aOkyvxedojR4fnxqdh+LB/ZfxbhQE4JrukQ5fR+f78gvR8NoHInQRCuIbknLTk52eavffv2FKC5CB8eoAlPW3ipUxukQIcYHQDzNGRNrW+9TxUS3QY4olZaNQVpclFUPw0cE6JBUkQwJqa3BQCs+c8Zl/Z7SJzsdLwfDQDi6gVtfXUqmSAI38ahS/8333zT4R0++uijTi8mUNGplSiupAnPhvDJzpgQDcI0KmiDFKipNaGgTC8Gbb6AVCFbDmmlyQ8vj3PpiwdGdsKn+y7i+6P5OF1QgS7x0oWQK/R1OH2lAoD0TFocZdIIgnABh84qr732mkM7EwSBgjQnsJ7wJCwU159wzcrtAhLCtThfVIX88hqfCtKkCtlywkkrTXaK6oOhmPogrUt8GG5MTcD3R/Ox9uczeOWOvpL3eeRSKRgD2kRoxcyYo/ByZ1GlASYTc0gElyAIguPQWaVhHxohL3zCkzJptvByZ3R9n158mAbni6p8bsLT5UwalTtlo9Aq+8p5YFRnfH80H58fuITHx3ZDUoTj05mANFP1hvBg0WhiuFpdK36XCYIgHEE2nTTCeXgmjfw7bbGUO3mQZu599LUJT2eDNIt/J33ucsEzabFWGa9+HaIwuGM0ao0M7+2SfsH5OxexdcBUvSFBSgUideZgnEqeBEFIxSlxposXL+LLL79ETk4ODAbb0fIVK1bIsrBAQsdN1vVU7rSGW0Lx7AMvNfnahKfT5U7KpMlOIe9Ja5CxenBUZ/x2thif7MnB3Bu6IFLneEbrkBN2UNbEhmpwtaoWheV6dEsIc2ofBEEEJpKDtB07dmDChAno1KkTjh8/jrS0NJw7dw6MMfTr188da/R7QsXpTsqoWMMzadH1JaP48PogzdfKnRJ9OznhweYgjXrS5MPSk2bbOzayWxx6JoXjWG4ZPsw+j0dGd3Vof8WVBlworgYApLWVnkkDzEMMpwtI0JYgCOlILncuXLgQTz75JA4fPgytVovPPvsMFy5cwMiRIzF58mSnFrFq1SqkpKRAq9Vi8ODB2LNnT7Pbb9myBT169IBWq0Xv3r3x7bff2tx/zz33QBAEm7/MzEyn1uYJLD1plEmzprjVlDul+XZy+OAATXfKQ53RJOqk8V4wjiAIeGBkJwDA+7vPodrBIR2eResUG4KI+qBaKhatNBK0JQhCGpKDtGPHjmHmzJkAAJVKherqaoSGhuL//u//sGzZMskL2LRpE+bPn49FixZh//796Nu3LzIyMlBQUGB3+927d2P69OmYM2cODhw4gEmTJmHSpEk4cuSIzXaZmZnIzc0V/z755BPJa/MUlulOyqhYYxkcMJ/kEnw0k+ZsuTNMQ+VOOSmuMn9fBAGIslPOHNc7Ce2jg1FcacCWfRcc2qfFVN25LBpAgrYEQTiP5CAtJCRE7ENLSkrCmTMWkcjCwkLJC1ixYgXuu+8+zJ49G6mpqVizZg10Ol2TFlNvvPEGMjMzsWDBAvTs2RNLlixBv379sHLlSpvtNBoNEhMTxb+oKOfVxt2NThwcoEyaNVzzimdFfDeTxsud0sRsebmTBgfkgX9fonVqu2bqKqUC91/XGQDw9n/+RG29m0VzuDLZySFBW4IgnEVykDZkyBD88ssvAICbb74ZTzzxBF566SXce++9GDJkiKR9GQwG7Nu3D2PGjLEsSKHAmDFjkJ2dbfcx2dnZNtsDQEZGRqPtd+7cifj4eHTv3h0PPvggioqKmlyHXq9HWVmZzZ8n4Ur1VSTBYUPjcqf5ZFdSVQtDXcsnWE9hCdKklcMsOmmUSZODhkG9PSb3b4fYUDUuXa3GN4dym90fY0yc7OzrxGQnhwRtCYJwFoeDtOLiYgDmzNfgwYMBAIsXL8bo0aOxadMmpKSk4L333pP05IWFhTAajUhISLC5PSEhAXl5eXYfk5eX1+L2mZmZ+OCDD7Bjxw4sW7YM//nPf3DTTTfBaLSfqVq6dCkiIiLEv/bt20t6Ha5CmbTGVBuMqK63f+LTnZG6IKiV5q+sLzVhVzppC2WZ7qwDY0z2dQUa3BIqNrRpwVltkBKzr+0IwGwV1dz7nldWgyvleigVAlKTXCh3cpN1H/rOEgTROnC4iaZNmzaYNGkS5syZg7FjxwIwlz7XrFnjtsU5y7Rp08T/7927N/r06YPOnTtj586dGD16dKPtFy5ciPnz54v/Lisr82igJmbSqCdNhJ9w1UqFODUpCALiwjS4dLUaBWU1aBspTZTUXbiqk2YwmqCvM0EbJC3II2zh5cSGk50NuWtIMlbvPIPjeeXYeeIKru8Rb3c7bqreLSEMwWrnPxuxJ62cBgcIC0YTw56zxSgor0F8mBaDOkbbLdMTgY3DmbR33nkHV65cQWZmJlJSUvDiiy/i3LlzLj15bGwslEol8vPzbW7Pz89HYmKi3cckJiZK2h4AOnXqhNjYWJw+fdru/RqNBuHh4TZ/nkTMpNF0p4i124AgWA5cvqiV5myQFqJWgR+TaXjAdRqKHzdFRHAQ7hzcAQCwemfTxuvOmqo3xGINpaeMKQEAyDqSi+HLfsT0d37FvI0HMf2dXzF82Y/IOtJ8CZ4IPBwO0u6++27s2LEDp0+fxqxZs7B+/Xp06dIFY8eOxaZNmxqJ2jqCWq1G//79sWPHDvE2k8mEHTt2YOjQoXYfM3ToUJvtAWD79u1Nbg+YxXeLioqQlJQkeY2eIERNmbSGFDWwhOJYJjx9Y3iAMSaWO6UGaQqFgDAtDQ/Iheg20ExPGmfO8I5QKxXYc64Y+84X293GMtkZ6dK6eI9crZGhlILxgCfrSC4e/Gg/ckttj2F5pTV48KP9FKgRNkgeHOjYsSMWL16Ms2fPIisrC/Hx8bj33nuRlJTklLn6/Pnz8c4772D9+vU4duwYHnzwQVRWVmL27NkAgJkzZ2LhwoXi9vPmzUNWVhaWL1+O48eP48UXX8TevXsxd+5cAEBFRQUWLFiAX3/9FefOncOOHTswceJEdOnSBRkZGZLX5wl0GsqkNaSpJnDLhKdvZNKqa40w1SdHpEpwAKSVJieW70zLJugJ4Vrc1q8tAGD1zj8b3c8Ys5rsdC2TplEpEV5f2qa+tMDGaGJY/NVR2Mun8tsWf3UURhNlXAkzLnl3jhkzBh9//DE++OADAGZRWqlMnToVr776Kl544QWkp6fj4MGDyMrKEocDcnJykJtrubIYNmwYNmzYgLVr16Jv37749NNPsXXrVqSlpQEAlEolDh06hAkTJqBbt26YM2cO+vfvj127dkGjafng7Q14Jo28Oy00tITi8AlPX9FK46VOQbDYe0mBtNLko9DBcifn/us6QRCAH47l42R+uc1954qqUFZTB41Kge6Jrls5xYoyHNSXFsjsOVvcKINmDQOQW1qDPWftZ3eJwMMp704AOH/+PN5//32sX78eFy5cwPXXX485c+Y4ta+5c+eKmbCG7Ny5s9FtkydPbtLdIDg4GNu2bXNqHd6CZ9KqKJMm0lS5U7SG8hGtNJ79DFWrbHrnHMWSSaMA3VWasoRqik5xocjslYjvjuRhzX/OYMWUdPE+nkVLbROOIKVL17IAzH1pf16ppExagOPocctXjm+E95F09NHr9diwYQPGjBmDzp074/3338fMmTNx+vRpbN++3WaqknCcULVlys+X9L+8SXGF/ayIr5U7uW+nM6VOwCLDQVpprsPLnXEOBmkA8MBIs7jtlwcv49LVavF2PtnprKl6Q0jQlgAsxy+5tiP8H4eDtIceeghJSUm49957ERMTg2+//Rbnzp3D4sWLkZKS4sYl+j/W4/2Oegr6Ow0toTi+Nt0pTnZK9O3kiK4D1ZRJc4VKfZ2oq9ecmG1D+raPxLDOMagzMby7y9KbJlc/GocEbQkAGNQxGkkRWjSVcxcAJEWY5TgIApAQpP3yyy9YtGgRLl26hE2bNuHGG290qrxDNEatUogirdSXZqbp6U7zFWZhhR51Dtj6uBtnfTs5XCuNBgdcg2fRtEEKyb2BD44yZ9M27rmAkkoD6owmHLksz2Qnh0+cUpAW2CgVAhaNT7V7Hz+bLhqfSnpphIjDQdqhQ4cwb948xMTEuHM9AYuOBG1tEC2hGmRFYkLMvoyMWQI5b+KsbyfH4jpAQZorFNYPmsSEaCRfPA7vEou0tuGorjViffY5nCqoQE2tCWEaFTrFhsiyPovJuve/s4R3yUxLwuq7+jWSikmM0GL1Xf2QmeabUlGEd3C9I5aQhRAStLWhuIlMmkIhiAc3X5jwdFbIlsPLneU0OOASPJPmiEZaQwRBEHvT3v/vWWzckwMAaB+tsyuV4AyxVO4krMhMS8Jb064R/50UocUvT99AARrRCArSfAQdyXCI6OuMYvBjT07BMjzg/QkoV8ud4VTulAWpk50NuSktCXGhapRW12F99nkAwNHcMtlU4LkER6GP9FIS3ueqVfa8ymCkEidhFwrSfASS4bDAs2gqhSCWA62J96HhAVczaWFU7pQFXvp2JpMGANuP5uGKnVKkXCrwlp40A1lDEQBs2zVKq2tpsp+wCwVpPgIJ2lrgpauoEDUUdq4uRa00vyh3mh9H5U7XcNRc3R5cBd4ecqnA83KnwWgiTTwCgOVitKl/EwTgRJCWlZWFX375Rfz3qlWrkJ6ejjvvvBMlJSWyLi6Q4CbrVSTBYRkaaEI5Pq6+3JnvF+VO7t1JmTRXcNRc3R6eUIHXBikRpiFrKMJCw6CMvheEPSQHaQsWLEBZWRkA4PDhw3jiiSdw88034+zZs5g/f77sCwwUQuqnA/lJP5BpamiAk+BHmbQI0kmTBYu5uvRMmqdU4GNJ0JawomGQ5gvT6oTvIfnMcvbsWaSmmnVePvvsM9xyyy34+9//jv379+Pmm2+WfYGBgo6mO0Wa0kjj8MGBKz6QSavgtlAu6qRV1xpRazTJYkEUiFjM1aVn0jylAh8XqsHZQrKGIsw0CtLoe0HYQfIZQa1Wo6qqCgDwww8/4MYbbwQAREdHixk2Qjq8J4100izm6k2VrnxpcMDVcqd1cEd9ac5TZKWTJhVPqcDHhtUPD/jA95bwPvxiNEpnzqYXkYYeYQfJQdrw4cMxf/58LFmyBHv27MG4ceMAACdPnkS7du1kX2CgwE/yNDjQtCUUhw8OXCnXw+RCM7cccO9OZzNpKqVCfCxNeDqH0cTE74wz053WKvANAzU5VeBJ0Jawhl+Mdk0IA2ARZCYIayQHaStXroRKpcKnn36K1atXo23btgCA7777DpmZmbIvMFDgPWkkwWG5ooxu4oQbG6qBIAB1JoaSKu+e8Fz17gRIK81VrlYZwGP1pkrkLcFV4BMjbEuacqrAk6AtwWGMoaTS/HvvlhAKACgsp+CdaIzkM0uHDh3w9ddfN7r9tddek2VBgYrYk0aZtBYn9YKUCkTr1CiqNCC/TO+0gKkc8M/LWVsooF4rrbSGhgechGemonRBULnQ05eZloSxqYnYc7YYBeU1iA8zlzjlEhmlII3gVOjrYKj3Hu5Wn0krokwaYQfnL/8B1NTUwGCwjf7Dw8NdWlCgImbSSIKjxelOAIgP16Ko0oCC8hqkwjvfOcaYWO50ticNsNZKo0yaM7jqNmCNUiFgaGf3+BPzUqw90VwisODHuOAgJdpFBQOgnjTCPpIvOysrKzF37lzEx8cjJCQEUVFRNn+Ec1imOymbIp50mwvSfGB4QF9nQl19nc3ZnjSAtNJcpdAFjTRPQtZQBMd6gp0Pu9B0J2EPyUHaU089hR9//BGrV6+GRqPBu+++i8WLF6NNmzb44IMP3LHGgCCExGwBALVWiuzNZtJ8QHPKOqDmn58zhJNWmku4opHmSeKsyp1kDRXYFFtJxnDZmMJKsgwjGiP5zPLVV1/hgw8+wKhRozB79myMGDECXbp0QXJyMj7++GPMmDHDHev0e3QasoUCgJL6K0xBACJ1zZU7uaCt97TS+NCATq20a1/lKGE0OOASrmikeRIeROrrTCjX19n1pSUCg+Kqxpk0Q50JFfo60c+XIAAnMmnFxcXo1KkTAHP/WXGx2Spl+PDh+Pnnn+VdXQAhZtICfLrToh2kbrZhmwuLerPc6arbAIefrEknzTlc0UjzJMFqpfhdoZJnYCP23erUCFYrRZ3MQJBnMZoYss8U4YuDl5B9psglT9xAQPLZpVOnTjh79iw6dOiAHj16YPPmzRg0aBC++uorREZGumGJgYGODNYBODY0AFjKnflezKRVuug2wOGDA6ST5hz8xMbFYn2Z2FA1KvR1KKwwoFOct1dDeIuGx7mYUA0qi6tQVKFHx9gQby7NrWQdycXir47aeOUmRWixaHyqLDI3/ojkTNrs2bPx+++/AwCeeeYZrFq1ClqtFo8//jgWLFgg+wIDBT4dWFNrQl39aHYg4qhRdny4L2TSzEGVK5OdAA0OuEphRevIpAEkw0GYaagFySd//TmTlnUkFw9+tN8mQAOAvNIaPPjRfmQdyfXSynwbyWeXxx9/XPz/MWPG4Pjx49i3bx+6dOmCPn36yLq4QIJn0gCgqtaI8AD1cCwW5RQcy6QVlJubsAVBHi0rKbjq28nhPSg0OOAc/ITnjNuAp6EgjQAaW99x+Rh/1UozmhgWf3UU9gqbDGZnj8VfHcXY1ETZdAn9BdfOLgCSk5ORnJwsx1oCGo1KAaVCgNHEUKU3BmxTsaPlzrgwS7NtWXUdInSef79c9e3kiOVOyqQ5hZw6ae6G/DsJACiuMv/WufUdv8DwV620PWeLG2XQrGEAcktrsOdssdt0ClsrDp1d3nzzTdx///3QarV48803m9320UcflWVhgYYgCAhRK1FWUxfQfWlFLfh2crRBSkQEB6G0uhYF5TVeCdIsvp3Ouw0ANDjgCtUGIyrrZWt8fboTsGTSSNA2sOGZtOgQ82/f37XSCsod6x12dLtAwqEg7bXXXsOMGTOg1WqbtX8SBIGCNBcI0ahQVlMX0BOexRKESePDNPVBml40KfYkcvh2AtY6aZRJkwovD6mVCoS5mNH0BFTuJACLThq/GI3x8540Po0v13aBhENHtbNnz9r9f0JeaMLTVom7JeLDNThVUOG1CU+5yp1cJ61cXwejiVFPhgSsNdK80ZcoFQrSiJpaS/Y3ukFPmr9+LwZ1jEZShBZ5pTV2+9IEAIkRZq9cwhaXutMZY6SQLCP8ZF8VwEGalExagpe10sRMmgtuA4AlSLPeJ+EYPJPm624DnLj6njRvOmUQ3oUf44KUAsLrf/tiT1qlf2bSlAoBi8an2r2PX1otGp9KF6h2cCpIe++995CWlgatVgutVou0tDS8++67cq8t4BAzaVTuFEfTmyNOdB3wcpDmYrlTo1JCG2T+KVLJUxqF5a3DbYATF2q+sCBrqMCl2Eqwm2d/+UWGv/akAUBmWhKWTEprdHtihBar7+pHOmlNIPns8sILL2DFihV45JFHMHToUABAdnY2Hn/8ceTk5OD//u//ZF9koGDx7wzMbIrRxFBSJaHcKWbSWne5EzDLcNTU6mnCUyKFrcRtgMOnO2tqTag0GF2WbyFaH/Ym2HnloKSqFnVGE1R+KsFUWn8R2qtNOO6/rhPiw8wlTsqgNY3kI8Tq1avxzjvvYPr06eJtEyZMQJ8+ffDII49QkOYCuvoDdqBm0kqqDODJhahmfDs51lpp3kAuWygACNeqcKVcT1ppEmlNGmkAoFOroFMrUWUworBcT0FaAGIvSIvUqaEQABMz+3r6YwM9YwxfHLwEAJg5NBkT09t6eUWtA8nhem1tLQYMGNDo9v79+6OuzrkTzKpVq5CSkgKtVovBgwdjz549zW6/ZcsW9OjRA1qtFr1798a3337b5LYPPPAABEHA66+/7tTaPAn3bwvUTBo/eEUEByHIgStJHqR5q79HLjFbwDLhWU6ZNEkUOSh+7EvQ8EBgY284SqkQxH/zEr6/cTyvHCfzK6BWKqi0KQHJQdrdd9+N1atXN7p97dq1mDFjhuQFbNq0CfPnz8eiRYuwf/9+9O3bFxkZGSgoKLC7/e7duzF9+nTMmTMHBw4cwKRJkzBp0iQcOXKk0baff/45fv31V7Rp00byuryBrr7cySd/Ag1xUs+BUidgsYZq7dOdgLU1VGAG6M5isRFrHeVOwNoCiIK0QKSh2wBH1ErzU9eBLw5eBgBc3yMOEcGBKdbuDA6dXebPny/+vyAIePfdd/H9999jyJAhAIDffvsNOTk5mDlzpuQFrFixAvfddx9mz54NAFizZg2++eYbrFu3Ds8880yj7d944w1kZmaKPqFLlizB9u3bsXLlSqxZs0bc7tKlS3jkkUewbds2jBs3TvK6vEGIhg8OBOaJ2lG3AQ7PpFUZjKjQ13m8dCRnuZNPeNLggDQs5uqtKUgjQdtAprjS1m2AExumxol8/3QdMJkYvqwvdU6iMqckHDq7HDhwwObf/fv3BwCcOXMGABAbG4vY2Fj88ccfkp7cYDBg3759WLhwoXibQqHAmDFjkJ2dbfcx2dnZNkEjAGRkZGDr1q3iv00mE+6++24sWLAAvXr1krQmbyJm0gK0J82iwu1YkBaiUSFUo0KFvg4FZTUIjQt15/IaIdd0J2AlaEvlTkmI5U4HvzO+AA8oyRoqMBGPc6H2M2n+mGHde74El0trEKZR4foe8d5eTqvCobPLTz/95JYnLywshNFoREJCgs3tCQkJOH78uN3H5OXl2d0+Ly9P/PeyZcugUqkcdj/Q6/XQ6y0/jLKyMkdfgqzwTFqg9qSJpSsJ/UXxYRpzkFauRycPBmmGOhMMdSYAruukAWQN5QwmExO/M61FJw2gnrRAR6wYNBiOivFjrbSt9Vm0zLREaINcs9ELNPxuznffvn1444038K9//cthBfKlS5ciIiJC/Gvfvr2bV2mfkADvSSt2or8ozksTntYl6RAXvTsBK5N1Knc6TGl1LYwm8ziwo9lXXyAulARtA5mmXFX8VSvNUGfCt4dzAYAmOp3Aq0FabGwslEol8vPzbW7Pz89HYmKi3cckJiY2u/2uXbtQUFCADh06QKVSQaVS4fz583jiiSeQkpJid58LFy5EaWmp+HfhwgXXX5wTiJm0AO1Jk2IJxeHDAwUeHh7gpU5tkEIWTaMwLZU7pcIbrMO1KqhVred6k19YUCYtMCluomLAS/b+5t/588kruFpVi7gwDYZ2jvH2clodXj2yqdVq9O/fHzt27BBvM5lM2LFjhyiU25ChQ4fabA8A27dvF7e/++67cejQIRw8eFD8a9OmDRYsWIBt27bZ3adGo0F4eLjNnzcI9OnO4grnyp2AFzJpBvmGBgCI9jCkk+Y44tBAKyp1AtblTv86GRMtU2c0iYKuDS9GY/w0k/bF7+apzvF92pBorRN4XUlx/vz5mDVrFgYMGIBBgwbh9ddfR2VlpTjtOXPmTLRt2xZLly4FAMybNw8jR47E8uXLMW7cOGzcuBF79+7F2rVrAQAxMTGIibGN1oOCgpCYmIju3bt79sVJJNB70qROdwJAgmgN5eFMWo188huAlU6anjJpjlLkRFDvC1BPWuBytboWjAGCAEQ2kKGwSLP4T/Beoa/D9qPmfvFJ17QOKSxfw+tB2tSpU3HlyhW88MILyMvLQ3p6OrKyssThgJycHCgUloTfsGHDsGHDBjz33HN49tln0bVrV2zduhVpaY09wVobgT7d6VS500sm63LKbwBWOmmUSXOY1mauzom1ko6pMtSJv3vC/7EW7G7YJiH2pFWafV0d7an2ZbYfzUNNrQkdY0PQu22Et5fTKpHt6JCbm4va2lp06NBB8mPnzp2LuXPn2r1v586djW6bPHkyJk+e7PD+z507J3lN3iCQvTtNVr6dUgYHvFburA+kZcuk8XIn9aQ5DJewaG2ZtBC1EtogBWpqTSgsN6BDDAVpgQLP/tq7EOXf45paE6oMRtmOLd5k6wFzqXNiehu/CDq9gWw9aTfccAM6duwo1+4CEp1Y7jTCVD+1FiiU1Vgm9aJCHFejjvdWubO+LClbJi3YIsHBWGB99s5S2ArdBgCzILhF0JZKnoGEZYK9cZCmU6sQXC9P4Q+CtoUVevxyuhAATXW6gmxB2gcffIAff/xRrt0FJCFWZY/q2sAqefJSZ5hGBY3KcUmLuPpyZ1lNHWo8+J7J6dsJWMqdRhNDVYAOjkiFN1i3FnN1a6gvLTBpSbCbZ9P8IXj/5lAujCaGvu0i0DE2xNvLabXIlk8dOHCgXLsKWLRBCggCwJh5etAf0t2OIg4NSDzhhmtV0KgU0NeZUFCmR4cYnTuW1wg5fTsB82cfpBRQa2Qoq6kNqM/eWSyDA60rkwZQkBaoNGUJxYkJ1eBiSbXbJzyNJoY9Z4tRUF6D+DAtBnWMln3y8ot6AdsJlEVzCafPBAaDAQUFBTCZTDa3O9OTRpgRBAEharPNUaXeCIR5e0Weo7lejeYQBAHx4RpcKK5GQXmNx4I0y+CAPOrZgiAgTBuE4koDyqrrkEQ9ti1S1EzpyNeJCyNB20DEkkmz39IR5wHXgawjuVj81VHkllpaRJIitFg0PhWZaUmyPEdOURX251yFQgDG95Fnn4GK5HLnqVOnMGLECAQHByM5ORkdO3ZEx44dkZKSQj1pMqBTB6bJenO9Gi2R4IUJT0uQ5nj/XEvQ8IA0eBaqNWbS4iiTFpBYJtibyKSFuFcrLetILh78aL9NgAYAeaU1ePCj/cg6kivL83z5uzmLNqxzrCg4TjiH5EzaPffcA5VKha+//hpJSUk0sSEzoRoVCsr1AdeXxA9Kztj7eGN4wFLulM+HzjI8QEFaS+jrjKLPaVwrDNIsJuutv0HcVTxRevMVWroYjXGjVprRxLD4q6OwN5bEAAgAFn91FGNTE116/xlj2HrQPNU5IZ200VxFcpB28OBB7Nu3Dz169HDHegIePuFZGWAyHC1dYTaHN7TSuJitXIMDAGmlSYGXx1UKQfQ9bU1QT5oZT5TefImWBLtF1wE3lDv3nC1ulEGzhgHILa3BnrPFLtk3Hc0tw+mCCqhVCmSm2bd3JBxHcrkzNTUVhYWF7lgLAYugbVWACdq6Uu70hsm6WO7UyhcghFG502Gs3QZaYzbf14I0o4kh+0wRvjh4CdlnikQ5HHfiqdKbL9FSkCa6DrjhWFZQ7lilwdHtmuLL+iza6B7x4oUn4TySzzDLli3DU089hb///e/o3bs3goJsPwRv+V76CyHqwMykOWMJxeGCtvmeLHca5J3uBKwzaRSktURhfQN2a9NI4/iSBZA3sllylt5aS7mUMYtgd5OZtBCL64Dc8IqDXNvZw2Ri+PJ3LmBLU51yIPkMM2bMGADA6NGjbW7nNhZGY2BlgORGp+GZtMAK0sRJPSc0r3hjqicn5dxS7qwv2/FeK6JpWqtvJ4f3pFXozfp+2iD5ehulwLNZDYMlns1afVc/twRqjpfeijC0c2yT27WmcmlZTR1qjeZ3uslMWv3UrzvEbAd1jEZShBZ5pTV2g2MASAzXYFDHaKefY8858+caplVhVPc4p/dDWJB8hvnpp5/csQ6iHksmLbCC3WIXMiOiybpHy53yitkCVpk0Kne2iEXItnVm0sI0KqhVChjqTLhSrkf7aM9Ix1jjqUZyezhaUpuzfi+GdIpB/+Qo9E+OQt92kQiuP0Z6K8B0Fl4tMNuC2Q/K+fGvuMoAo4nJ+r4rFQIWjU/Fgx/tb3KbhHAtXHlGro12c1qS1y48/A2HzjC33XYb/vWvfyE8PBznz5/H1KlTodG0zoOjr6MLQP9OxpjTYraAJT1fXGmAoc4EtUo2I40mqZTZYB2w6kmjwYEWac0aaYBZFy8uVINLV6tRWOGdIM1TjeT2cLSkVmUw4sfjBfjxeAEA86BIaptwXNMhEl8cvOyVANNZRI20Zo5xUbogUdC8pMog+0VIZloSVt/VD3/7/IjNcEJsqBpXq2rx+8VSrPrpNB4Z3VXyvvV1Rnx7OA+A2auTkAeHzmZff/01KisrAQCzZ89GaWmpWxcVyHBJh8oAGhwo11vKAM6cdKN0QQhSmg/EnmjErjOaRNsuWXvSgimT5ij8c+Zlw9aIt/vSPNVIbg9eemsqfBJgLlv++8FheOGWVIzrnYSEcA3qTAyHLpZi/e7zuFrV9O/EOsD0FVpyGwAAlVKBKJ37Sp6AOVD72809AQBd4kPwyX1D8NuzY/DSrWkAgBU/nMSPx/Ml7/c/J66gtLoWCeEaDO4kb1AfyDh0hunRowcWLlyI66+/HowxbN68uckBgZkzZ8q6wEAjEDNpxfUHI10zZYDm4FmJy6U1KCjXo01ksNxLtMG6FC2rTppY7gycz95ZeGDTWjNpgGUq2VuuA55oJG+K5kpvPHBbND4V/ZKj0C85CvcO7wjGGC6X1mDvuWJ8uu8idp1qWWXAHQGms4iZNF3zE48xIWoUVxpQWKFHdzfZzuTWD1n1bRclZkmnDuyAw5dK8dGvOZi38SC+nDtckufmF/UDA+P7tPGZ7KU/4FCQtmbNGsyfPx/ffPMNBEHAc889Z3fsXRAECtJcJBB70opcmOzkxIVrcbm0xiMTnrzUqVYqJJnBt4QoZkvTnS3S2nvSAO/LcLTUSC4ASIzQutRI3hyZaUl4Y1o6Ht140Ob2xCYa/wVBQNvIYLRNb4v4MK1DQZo7AkxncVQLMiZUjVMF7v1eXLpaDQBoG2V7QfvCLb1wLLcc+86X4P4P9uLzh691qKWjvKYWPxw1Z98mXUNTnXLiUJA2bNgw/PrrrwAAhUKBkydPIj4+3q0LC1T4dGcg2UK5opHGifegVlqFG9wGANJJk0Jrn+4EvB+kOZrNcmdWJDHCHCREBgdh8YReiA93TELD2wGmMxQ7+J0VBW3dWAa/VGIO0to1qDqoVQqsntEPt7z1C04VVGDBlt/xzxn9WtQi/P6PfOjrTOgUF4JebUiGS04kd1ifPXsWcXE0WusuQgJQzNZiOuz8CZdPeF7xQCbNHUK2gFVPGg0ONAtjTNSRao2+nRxLT5r3BG15IznP4HNiwzQemY7cd74EADC0cwwmXtMWQzvHOBQU8gATgN2+Ngbg+XHuDTCl4qgWZFyo+7TSODyTZq81JD5ci9V39UeQUsB3R/Lwz51nWtwfL3VOSm/bKsWlfRnJQVpycjJ9CG4kJABtoVyxhOJ40hpK9O1Uyxyk1Qd9BqMJNbWBE6RLxVpvqjX3pPmKf2dmWhJGNtC0mj+2q0fkK3iQ1j85SvJjeYCZGGG/pLnnXDEYc79zgqMUtyBky+HfaXdl0hhjYiatYbmT0z85Cv830TxI8Or3J7DzREGT+7tSrscvp64AACb0palOuWl9pnd+Dp8W9CWDdXcrejtaBmgOj5Y73SBkC5iDPoUAmJi55Ek6Q/bh/WihGlWrfo+8Xe60pqDMvIaUGB3OFVVh//mrmD4o2a3PyRjDgRxzkNbPiSANMAdqY1MTbY5PheV6PLLxAP61+xzaRQXjLyM6yblspxEzaTrHyp3umvq9WlUrTqcnNRHgAsD0QR1w6GIpPtmTg0c/OYCvHhmO5JjGgwTfHLoMEwPS20ciRcKgAeEYFKT5GDo+OOAjPWmeUPR2xRKKEy8K2rbecqdCISBUo0JZTR3KqusQ757BrlYPz7zGtuJ+NMASpF3xgSAtr75N4JY+bbDyp9PYW5/hcifni6pQVGmAWqVwqY9JqRAa6bjlldXgpW+P4f99cwxJEcEY18f7orY8M9aSFmSMm8vgvNQZF6Zp8SLnxQmpOJ5XhgM5V3H/B/vw74eGNZId2nqQ20BRFs0duF/1k5CE2JPmA5k0TxkgyzHdycud+WUeLHfKnEkDSCvNEbj5dGvuRwMsvUflNXVeLW+bTEycir6pdyIA4GxhpdszfLzU2btthKxT0gDwlxEdMWuoORP4+OaD2HvO+3ppjg5I8YsPd/WkXSxpuh+tIRqVEmvu6o+4MA1O5Jfjqc8O2ZSQzxdV4uCFq1AI5gCfkB+ngrS6ujr88MMPePvtt1FeXg4AuHz5MioqKmRdXCCis+pJ82Y/RUuWMYBZ0dtocn2Nck53FlXoZVlTc4iZNJl70gCLVhr5dzZNYSt3G+CEB6ugVpoPwdbq756muMqAWiODIABd48PQLSEUALD3nHuzaftynO9HawlBEPDC+F4Y0zMBhjoT/vLBXvx5xXvnp2qDUSwxttyT5t7pTp5JazjZ2RQJ4VqsntEPQUoB3xzKxds//wmjiSH7TBGWfXccADCsc4yo+0fIi+Qg7fz58+jduzcmTpyIhx9+GFeumBsGly1bhieffFL2BQYaPJPGGFBTa/LaOqRYxrgK7zFyJZMWE6oR+7mK3JwBEH07ZS53AhaT9TLSSmsS/vm29kyaIAhi1sRbgraAOTMOmIMDtUqBASlm2Yp9592bfdpfn0nr10H+IA0wl0Hfmn4N+raPxNWqWtzz/v+81v/HhwbUSkWLvax8oKTKYHSLqHlLQwP2GJASjUXjewEAln13HAP/3w+Y/s6v+PaI2Qbq8KUy2SorhC2Sg7R58+ZhwIABKCkpQXCw5UO+9dZbsWPHDlkXF4gEW/UIeHPC01OWMWY5BZ4Zcf6kq1QIYo+Pu4cH3FnuDCOT9RbhGYbW3pMGWE94ei9I46XOxAjzWgbUZ7bc2ZdWXlOLE/nmKky/5Ei3PU+wWon3Zg1A++hg5BRXYc76vaj2QisJH46KCglqUR0hRK2Ept5/2B3ZtMtcyFaiM8uMwR1wbecYMFiCTk5Zda2sLTCEBclB2q5du/Dcc89BrbY9QKakpODSpUuyLSxQUSgEcXjAm1ppUS1Yl3BcVfSuMhihrzNnDF0VJvXU8IBY7pRZzBawsoYirbQmETXSWnm5E/CNCU+eMU8MN/+WB9Zn0o5cKnVbr9zBC1fBGNAhWud2V4DYUA3+NXsQInVB+P3CVTy68YDbWyIaUiRqQbZ8IWrOsHKtNPmDtEtOBmkmBpxpomQsdwsMYUFykGYymWA0Nv7hXrx4EWFhNI4mB9y/01uZtNMF5Xi5vtegKbgBsquK3rwfTaNSiMGps4haaW4eHrAEaY4FslLg5c5yyqQ1CZcmaM3m6hxfELS1ZNLMv592UcGID9Og1sjw+4WrbnnOfWKpM9It+29I57hQvDNzANQqBbYfzcf/ffWHR3t+pfbdihOebsiwNidk2xx7zhYjr5ljqy+a2vsDkoO0G2+8Ea+//rr4b0EQUFFRgUWLFuHmm2+Wc20BCxe09bTJOmMMH/56Hre89QuO5paLKuQNk/NyWsYUWR28XBVJ5sMD7p7wrHSTLRRgbbJOQVpTiD1pLpTHfYVYN2tiOUJeg0yaIAhiNs1dJU9XRGydZWBKNF6bkg4AWJ99Hu/9clZsgP/i4CVknylyWxZIqsyQKGgr84RnlaFOXIuUnjTAcy0whC2Sm2qWL1+OjIwMpKamoqamBnfeeSdOnTqF2NhYfPLJJ+5YY8DBM2kVHix3Flbo8fSnh7DjuFlZekTXWCyf3Bf7c0oa6aQlhGvx4gR5dNJESygZ+ossgraeKne6oyeNDw5QubMpCv2pJ80HtNK4RlpCuKXs2D85Ct8cznWLdIXJxHAw5yoA50VsnWVcnyRcvtpT1FBb+dNpXK2yXBDJrQHJkRykuSl4v3zV/FmHaVSICJZWCXC0LO1Lpvb+gOSzTLt27fD7779j48aNOHToECoqKjBnzhzMmDHDZpCAcJ4QsSfNMyfqn04UYMGW31FYYYBaqcDTN/XA7GEpUCgEG0Xv+z/ci/KaOqy88xpxAsxVRIFHGbIi8eGesYZyZ5BGOmnNY6gzobR+8rW1T3cCvjE4IGbSrNTnB6SYg6d950tgMjEoZHQYOVVQgXJ9HULUSnRP8HyLzF9GdMR/Txdi58krNgEaYNGAlNu3VGqQFusmk3WxH01iFg1onab2/oBTZxmVSoW77rpL7rUQ9fCpwUoZp5DsWTvVGk1Y+u0xrM8+DwDonhCG16elo2eSrfo3V/RObx+JXacKcbqgQrYgTQ6NNI6nrKHcKmZLOmnNUlI/VaYQgEiJmQBfxBd60ngmzdoiKDUpHDq1EmU1dThVUIHuifIFU7zUmd4hEiql5/XUTQw4nldu9z4Gc7Cx+KujGJuaKJv9nVTBbncJ2l6SIGTbEG5q/+BH+yEANoGanC0whC2SzzIffPBBs/fPnDnT6cUQZuTuSbNn7RQbqkaQQoHc+gP07GtT8HRmj2ZtQrolhGHXqUJxdF4O5LCE4vBM2pUyN5c73eTdCZBOWksUVlim5OTM7niLOC/3pFUZ6sQLAutyp0qpQHr7SOw+U4T/nSt2S5DmLn20ljA3wDumAdnQbspZnB0ckD+TVgVA+mQnh5vaNzyfJLqpTEw4EaTNmzfP5t+1tbWoqqqCWq2GTqejIE0GxOlOGXrSuLVTw/Q0PymEaVV4a/o1GNU9vsV98QP1iSauQp1BDksoDs+kXanQy16i4ZhMTMxwukXMlgYHmsWfNNIAiCrtpdW10NcZZbdHagle6gxRK0WNPs6AlGjsPlOEfedLcNcQ+czW97toqu4q3miAlz444B5pFt6T5ky5k2PP1H5Qx2jKoLkJybnmkpISm7+KigqcOHECw4cPd3pwYNWqVUhJSYFWq8XgwYOxZ8+eZrffsmULevToAa1Wi969e+Pbb7+1uf/FF19Ejx49EBISgqioKIwZMwa//fabU2vzBmJPmouZtOasnTg6tRIjusY5tL8e9UHaSTdk0uQod/I+jlojE8ticlNlpRvllkwa6aQ1Cy//xPpBPxoARAQHIUhpPrm5ywaoOXiQlhDRuNnbImor3/BAUYUeZwsrAQD92nsnSPNGA7x4nHPw4sJisi5zJq3EOY20hvAWmInpbTG0cwwFaG5EloaArl274uWXX26UZXOETZs2Yf78+Vi0aBH279+Pvn37IiMjAwUFBXa33717N6ZPn445c+bgwIEDmDRpEiZNmoQjR46I23Tr1g0rV67E4cOH8csvvyAlJQU33nijaGHl6+g08mTSWrJ2AsxyFY7q2nSND4MgmA8ccl3hyZlJU6sU4n7c1ZfGS51KhSCqgssJL3dW1xpRa/SeLZivUlgu7WTn6wiC4LasiSPY60fjXNMhEgoBuFBcLWqpucqB+qnOrvGhiHBQMFtueAN8U2GFXBqQnFqjZdglSidtcKC40lwVkAtnNdII7yHbWUalUuHy5cuSH7dixQrcd999mD17NlJTU7FmzRrodDqsW7fO7vZvvPEGMjMzsWDBAvTs2RNLlixBv379sHLlSnGbO++8E2PGjEGnTp3Qq1cvrFixAmVlZTh06JDTr8+TyJVJkzutH6xWIjlaBwA4KVPJk0twyHXSdffwgPVkp6u6bvawzs7R8EBjCiv9RyONExvmveEBe/IbnDBtEHokmoeI5DJb56bq3upHAywN8IB7NSA5PKsvCECkg0Eav9g0MeCqTP2pdUaT+Hm3c6HcSXgWyfWaL7/80ubfjDHk5uZi5cqVuPbaayXty2AwYN++fVi4cKF4m0KhwJgxY5CdnW33MdnZ2Zg/f77NbRkZGdi6dWuTz7F27VpERESgb9++drfR6/XQ6y0HyLKyMkmvQ24sjgOuZdLckdbvlhCGc0VVOJ5XjmFdYp1dmkixjBIcgHl44HheOQrcNDxQ6Ub5DcDcsB2iVqLSYERZda0sGUZ/gpcE/SWTBlgJ2pZ7vtyZ30DItiEDU6JwNLcM/ztXjHF9XG8K94aIrT082QDPS51ROrXDgV+QUoFIXRCuVtWiqEIvy3Egr6wGRhODWqkQB1YI30fymWbSpEk2/xYEAXFxcbjhhhuwfPlySfsqLCyE0WhEQkKCze0JCQk4fty+LVFeXp7d7fPy8mxu+/rrrzFt2jRUVVUhKSkJ27dvR2ys/aBi6dKlWLx4saS1uxNxutNFnTR36Nr0SAzD90fzZRkeqKk1ioGoXMGIpzJp7nAb4IQHB5mDNBoeaAR3G/CXwQHAu4K2eQ0soRrSPyUa67PPi8GVK9QaTaLNlLeGBqzhDfCfH7iIJ7ccgjZIgV1PXS+7LIjlQlTadzYmRI2rVbUorDCga0LL27cEHxpIitT6xWR0oOCUd6f1n9FoRF5eHjZs2ICkJN8Zv73++utx8OBB7N69G5mZmZgyZUqTfW4LFy5EaWmp+HfhwgUPr9YWubw7rdP6DXE2rd+NT3jKMDzArzCDlALCZZqUFCc8PVDudBekldY0Fhsx/8kEeNNkvaElVEP48MDR3DIxi+wsRy+XQV9nQqQuCJ1iQ1zal1woFQJu6dMGAFBTa0KZG35zxVVOBmkyfy+4/EabCCp1tiY8ryRoRWxsLJRKJfLz821uz8/PR2Jiot3HJCYmOrR9SEgIunTpgiFDhuC9996DSqXCe++9Z3efGo0G4eHhNn/exKKT5roER2ZaEv45o1+j2xMjtE6paltPeLra0MpLV1E61307ORb/TveWO90hZMshrbSm8c9yp3sm+RyhpUxam8hgtI0MhtHEcNBFs/X9Vv1ovpTJ0QYpxSA1p7hK9v2L8hsO9qNxREFbuYK0EufdBgjv4dCZpmEPWHOsWLHC4W3VajX69++PHTt2iGVUk8mEHTt2YO7cuXYfM3ToUOzYsQOPPfaYeNv27dsxdOjQZp/LZDLZ9J35MhbvTnmu6qzdAZZP7oM2kTqndW2SY0KgVipQZTDi0tVqtK8fJHCGInFoQL6siLutoTyRSQsjrTS7MMbErIK/SHAAFq00T1tD1RlNYsa5qUwaYO4fu3S1Gv87V4xrXehDtYjYRjq9D3fRIVqHvLIa5BRXIb19pKz7Fq3vJF5Y8Gwxzx67imgJRZOdrQqHzjQHDhxwaGfOZEPmz5+PWbNmYcCAARg0aBBef/11VFZWYvbs2QDMDgZt27bF0qVLAZjFdEeOHInly5dj3Lhx2LhxI/bu3Yu1a9cCACorK/HSSy9hwoQJSEpKQmFhIVatWoVLly5h8uTJktfnDULqg7QqmQzW+dVhmwgtbu/f3qV9BSkV6BwfimO5ZTieV+5SkCanRhrH3Sbrnil3mvdN5U5bKvR10NeZZUn8KZMW56WetMIKA0zMXPJr7kJpYEoUvvz9sst9afvPe1fEtjnaR+uw51wxLrgxkyb1OBcrsxvFJRmEbAnP49CZ5qeffnLbAqZOnYorV67ghRdeQF5eHtLT05GVlSUOB+Tk5EChsFRlhw0bhg0bNuC5557Ds88+i65du2Lr1q1IS0sDACiVShw/fhzr169HYWEhYmJiMHDgQOzatQu9evVy2+uQE17udLUnjXOxxHzgcSWgsqZHYhiO5ZbhZH45xqY639EqpyUUh0sJFJTpwRiTXSbDM+VOLmjrvUyaPa9XbwtW8oyETq0Us83+gGiy7uEgLbfUnFlJCNM0+9n2TzZn4vefL0Gd0eRUY/3lq9W4XFoDpUJA33aRTq3XnXSoPzbmFLmx3Cm5J03ucqf5tbWjTFqrwieOdHPnzm2yvLlz585Gt02ePLnJrJhWq8W///1vOZfncXgAUGUwyhJo8AOPXEFatwRzX1pTJsWOIqeQLYeXjvR15ibgCJlNuN3p28mxWEN5J5Nmz+s1yQe8+Ypk1tTzFXjG5GpVLWqNJgR5yHSc923acxuwpntiGMI0KpTr63A8rxxpbSMkPxfvR+uZFObWCxxn6RBjDlzc2pMmOZPGTdZdz6QxxkjItpXi1K9l79692Lx5M3JycmAw2H6BWnuA5Avo6sVsjSYGfZ2pWdNzR+AHng4yZtIA1wVt+Wi6nOVObZAS4VoVymrqcKW8Rv4gTe8+305OmNZ7gwNNeb3mldbgwY/2OzVsIheFFf432QkAkcFBUCoEGE0MRRWGJpv45aalyU6OUiHgmuQo/HzyCvadL3EuSDt/FQDQ34sits0hZtJ8KEiTc7qzuNKAmlpzq0BSpGe+X4Q8SL5k27hxI4YNG4Zjx47h888/R21tLf744w/8+OOPiIiQ/uMlGmNdypFjwvNCibxBGpfhOHOlAoY6562LxEyazJkRPjyQXyZ/+cij5U4PZ9Ka83rlty3+6iiMMtrUSMHfzNU5CoUgXqh4suSZV//7sOc20JCB9X1k/zvnnI/nPi+bqrcErzLklla7dEyzh7MVA/6dkMPTlWfR4sM00Kjcp/FIyI/kIO3vf/87XnvtNXz11VdQq9V44403cPz4cUyZMgUdOnRwxxoDDqVCgDbI/NG4qk0EmL33APnKnW0itAjTqFBnYvizsMLp/YiWUDKr6rtzeMAyOOBGMVsvTXe25PXKAOSW1jjs9So3vDfH3zJpgHcEbfPqe9Icydz1T6k3Wz9XAsakBek1tUb8cakUgHftoJojLlQDbZACJmYJaOTAZGKiLZTU7y3PpFXo61BT69rF+uWrJL/RWpEcpJ05cwbjxo0DYJbQqKyshCAIePzxx8UJS8J1xAlPFzNphjoTLpfyIE2eH6ggCBZRWxdKnpYygLwnXTFIc0MmzRKkuc8c2ls6aXJ7vcoNz0hwr0t/ItYLMhzNmas3JL19JFQKAXllNZKDmEMXS1FnYogP0/isZ6QgCG4peZbV1IqZ56gQaceMcK0K6vr+RFf70i6WUD9aa0VykBYVFYXycvOJuW3btjhy5AgA4OrVq6iqkr+eH6joZJrwvHS1GowB2iB5/dq6yxCkuWNwALCa8HTDCa/SA7ZQYV5yHHCH16ucXPHrTJrnBW3zJZQ7dWoVerUxi3xLleKw9uuUe9paTjpEm10Q5AzS+DEuTKOSXGYUBEG2CU8eWNNkZ+tDcpB23XXXYfv27QDMU5bz5s3Dfffdh+nTp2P06NGyLzBQkUsr7YLV0ICcB8juCRbnAWcw1JnEIETucmecG/07PamT5ulyJ/d6bepbIsCcdZHi9SonYrnTz3rSAItWmqd60hhjDg8OcLgUx95z0oI0PtnpbVP1luCZNDm10kpc7Lu1BGmuBe/kNtB6cThI4xmzlStXYtq0aQCAv/3tb5g/fz7y8/Nx++23N2m7REiHT3i6mknjV4Xto+TpR+PwTJqzMhy8T0OpEGSfwBRdB9xgDeWRIK3+/ajQ17lsvSUF7vXa3DNK9XqVE8vggP9l0uLc7DnbkLLqOlTX9zk5Ok06MEX68ABjTBSxvcZH+9E4HerbQeTUSuOZtCiJllAcnjV2tVeRt7yQ20Drw+EzTZ8+fTBw4ED85S9/EYM0hUKBZ555xm2LC2QsWmmuBWn8qlCuoQEOz6RdLKlGhb5OctBi8e0Mkt3HL95NmTTGmFjudK8tlKr++YByvfxab82RmZaE265pi38fuNTovonpbbysk+Z/vp0cT5us8360SF2QwxI/fHjgRH45ympqxQGX5jhfVIWiSgPUSgXS2nrXE7klOsTI35PmqquK3Jk06klrfTicSfvPf/6DXr164YknnkBSUhJmzZqFXbt2uXNtAQ3PpFW4Wu6UWX6DExWiFoMhZ0qe7nAb4FgGB+TNpFXXGsETW+6U4NColNCozD9Nb2ilGYxmCYKpA9vjjWnpePj6zgCAHccLxPKNp6kzmpyekmsNeCtIc7TUCZh7EZNjdGDMYvHUErwfrXe7CJ+XfrAud0qdYG0KV49z/HvhSk9alaEOJVXm4wiVO1sfDgdpI0aMwLp165Cbm4u33noL586dw8iRI9GtWzcsW7YMeXl57lxnwGHpSZOp3ClzkAa4NjzA1ePdEqTVn3gqDUZZJEw4vNQpCJYg2l3wkqc3/DsP18sljOudhInpbfHE2O7omRSO8po6/HPnaY+vBwBKqmrBmPm9d8d3xtvwiVVPDQ7k1/ejOTI0YA3vK3N0eGBfK+lHA4B29S0h5fo6XK2S5+LIWXN1jhyuAzyLFqZVOZT9JHwLyYMDISEhmD17Nv7zn//g5MmTmDx5MlatWoUOHTpgwoQJ7lhjQMIzNZUuSnDw/gq5M2mApeTpTJBmKQPInxUJ1agQUh9EyVnyrORuA2qV26fUvDU8UFpdi/P135ne9cryCoWApzO7AwDW7z4vesF6EjGo16m97iHqDnjGpKTKgDqjvGKq9siVODTAGZhiHh5wtC9NNFXvECnpebyBNkiJhHDz53BeppKnJfvrWk+aKxlWPtlJ/WitE5dM4rp06YJnn30Wzz33HMLCwvDNN9/Ita6Ah0twuJJJK62qFVXr5dJIs8aVTFqxm/uL3DE8wH07PeE96C2TdS462i4qGFFWJ5aR3eIwtFMMDEYTXtt+yqNrAoDCcv/tRwPMjeUKwdyHWOyBkrJY7pRoQTWgPiN28MJV1LYQTJbX1OJEfSuEr4rYNkRurTSXBwdk6EmjIK1143SQ9vPPP+Oee+5BYmIiFixYgNtuuw3//e9/5VxbQMPLna5k0ng/WmyoxsZqSi54kOZMTxov67irdOUOGQ5xstONvp2cMC+ZrB+qD9L6tLO1eBMEAc/c1AMA8O8DF3E8r8yj6xLN1f2wHw0wT9ZGyzTJ5wj5TgZpneNCEakLQk2tCX9cbv47cPDCVTBmvkCMl5ix8xZcK00uGQ7RVcXpcqcMmTSS32jVSArSLl++jL///e/o1q0bRo0ahdOnT+PNN9/E5cuX8c4772DIkCHuWmfAwXueXJnutPSjuefH2TU+DIJgvlqUKh3gLksoDh8eyJcxk+YJ304OL3eWe7jcyfvR7Jlo920fiXG9k8AY8ErWCY+uSzRX99NMGuBZQVupGmkchUIQTdL3tlDyFEVsW0kWDbDKpMkkw1EsXow6d3HBv+/FlQan5Xgok9a6cThIu+mmm5CcnIy33noLt956K44dO4ZffvkFs2fPRkhIiDvXGJCIPWkuTHfmFLuvHw0AgtVKJNfvW2o2zV2WUByuii+n7pQnfDs5lnKnZzNpR+qDtN52gjQAeDKjO5QKAT8eL8CvfxZ5bF18us0fNdI4cR60huLlTqmDA4BFiqOl4QFrp4HWQoeYeq00GTJpjDGLbIyTF6O80lBnYk73p1ImrXXjcJAWFBSETz/9FBcvXsSyZcvQvXt3d64r4JEjk3bBzUEa4LyorbssoTjx4W4sd3okk+Z5k/XSqsZDAw3pGBuC6YPaAwBe/u64bFIFLcF7ctyVefUFPGWyrq8zihdJjvh2NsQyPNC02brJxHAw5yoA3xextUbOnrTqWiP0dea+PWePcxqVUtRNdDbDepkyaa0ah4O0L7/8EhMnToRS6dtaN/6CHD1p7nIbsEa0h5IYpLl7cCBBDNJaZ7mTH5g9OThw5LI5i9Y+OhiRzTQ6Pzq6K4KDlDh44Sq2/eEZ6R3ek8aNyP0R/lv47c8iZJ8pEo255aag3rNTrVIgUiddkqF32wiolQoUVuibDGZOFVSgXF8HnVqJHvUXcq0BLlWUW1oNQ51rU7b8wkKtUrgk2RPnglZardEkZk0pSGuduDTdSbgPOaY73eU2YE33RLOK+HEJ5c46o0nUIXJbJi2MT3e20kyaF3TSDrdQ6uTEh2lx34iOAMy9aZ6QjCj080xa1pFcbPrfBQDATyeuYPo7v2L4sh+RdSRX9ueyFrJ1RkpGG6RE7/rBkv814ePJS53p7SOhUrae00xcqAbaIAVMzJKBchZrtwFXJHtiXNBKyyutgYkBaqXCr1sF/JnW8+sJMEQxWyczaUYTExtGud2JO+DlzlP55Q43tnL1a0FwfjS9JdxhDeXZcqfnddIOX+RBWmSL2953XSdEh6jxZ2ElNu+96OaVWabbYvzwRJN1JBcPfrS/UUCeV1qDBz/aL3ug5qxGmjUDRFFb+8MDrbEfDTBPMctV8pTLVcUVrTR+DmgTqZXdfo/wDBSk+SghGtcM1vPKalBrZAhSCi4djFsiJUYHtUqBKoMRF0scu/LkB6/I4CC3CZPyTFppdS1qal0TBOZ4dLoz2PM9aY5m0gCzRMgjN3QBALz+w0mXPWZbwmKu7l+ZNKOJYfFXR+2a2vPbFn91VNbSJ3cbkCq/Yc0Aq740e+yvdxro18qCNMDSl+aqoK1cfbcxLkz9iv1oNDTQaqEgzUfhumbO2hrxEfK2kcFuVWhXKRXoEhcKAA5rZ7nTEooTHqyCut7/Uq4JT69k0jw03Xm1yiBmDhw1wr5zcAe0jw5GQbke7//3nNvWVmWoQ3V9oO1vmbQ9Z4vFzJY9GMyZrz1nHVP4dwRnhWyt4Rmy0wUVjfxciysNOFtYCQDo1771BWntrTw8XaHExclOTowLPWmisXoEBWmtFQrSfBSerak1MqcaWLmQrTv70ThSRW3daQnFEQTBquQpz/AAN7v35HSnp3TSjlwyB9gdonXNDg1Yo1Ep8eSN5invNTvPuM18nWfRNCqFaPflLzj63ZRzAMYV+Q1OdIganePM0ksNpTi4FVSX+FBEODGY4G2SZdJKE90GXAzSYl1wHbhEmbRWDwVpPor1NJAzpSRPyG9wpMpwyNWr0RJikCbT8IB3yp11HpG5kFLqtGZ8nzZITQpHub4Oq35yj/l6oZVGmrs9Uz0NL8vLtZ0jOCtk25AByeaS594GQZpoqt6KpDes4T28rvekySPYzRv+eQVCCiRk2/qhIM1HCVIqxHKdMzIcOR6Y7OSIMhwOZtL4FWG0m/uLeKZAruEB7t3pyUya0cScHh6RwuFLVwFAnNpzFIVCwNP1dlEfZLvHfN1f+9EAYFDHaCRFaNFU6CnArGU2qGO0bM+ZJ0NPGmAtamtbim2tQwOcDlblTlcukOQS7OZBHmXSAhMK0nwYXtpxRobDG5m0P69UOlSaLZapV6Ml5C93es67UxukgKq+l9ATwwPOZtIA4LqusRjW2Wy+vmL7SbmXZvHt9LN+NMDs2blofCoANArU+L8XjU+Vra/UZGLi78HVII2L2v5+sRT6OvOFRK3RhEMXrwJonUMDANCuXleyXF8nSgU5g3yDA86JHDPGSMjWD6AgzYfRuSBom1NcL7/hgSAtKUKLMK0KdSaGPwsrWtzeY0FafSYtX65yp8FztlCCIHhMK+1qlQEX6r8vaW2kB2mCIODpTHM27fMDl3AsV17zdX/XSMtMS8Lqu/o1CpoSI7RYfVc/ZKYlyfZcxVUG1BoZBMFyEeMsKTE6xISoYagziXZix3LLUFNrQkRwEDrFtk67QG2QUhTDdqXkWSKTYDfPIJfX1InBsCMUVRpQU2uCIABJNDjQaqEgzYcJcVLQtspQJ/bxuNNtgCMIgljyPOFAX5o43enmzEicjFppjDGx3OmJnjTAesLTvZk0nkVLjtE53ejdt30kxvUxm68v++4Yss8U4YuDl2RRzvdnjTROZloSfnn6BrxYn1WLCQnCL0/fIGuABlhKnTEhGgS5KDIrCAIG1Jc8uRQHL3X26xDZqnW55NBKEwcHXNSCDNcGiVn1YgnDOXyyMz5MI7bOEK0P+uR8GGczaTwrEq5VeWy6SsrwgMfLnWWulzv1dSbU1QcbnuhJAyzWUN8fzXOrTRAP0tKcKHVa8+SN3aEQgJ0nCzH9nV8xb+NBWZTz/bknzRqlQsCt17QDABRV1rpFe44Hac54dtpDHB5oEKS11n40TnsXgzRDnUnMgLt6nFMoBLFkKqUvjYYG/AMK0nwYMZMm8WAt9qO50WmgIaIMh4Qgzf3TneYTkRw6adZ6ddwNwp1kHcnFiTxz6Xjtz2fdahN0xIV+NGtO5JXBXhzpqnK+pSfNv4M0AIjQBYkXF6cLWm4dkIoc8hvWDLAaHmCMifIbrbUfjdPBRRmOkirzMU6pEBAR7PqFMp/wlOI6cFl0G6AgrTVDQZoPYxG0lZZJ84SxekN4ubOlTJrJxDyWSeN9JUWVBtS66C/JhwZ0aqXbyzjcJsjQYM3usgk6VG8H1ceFII0r59vDVeX8IrEnzX/LndZ0TTCLQ59yQ5CWLwrZyvNe9moTAY1KgZKqWvz3dBEul9ZAqRDQt12kLPv3FskuynDw72yULkiW40WME1pp3AGGJjtbNxSk+TDidKfETFqOByc7OTyTdulqdbMCrFera8Vsi6sijy0RpVOLvRzO+N5Z4ym3AU/bBJVUGsSDeS8XgjR3KucXiuXOAAnS4s2/JXdk0uTw7bRGrVIgvX0kAODtn88AAHokhnmsb9NduNqTxjNpclULnMmk8XJnO8qktWp8IkhbtWoVUlJSoNVqMXjwYOzZs6fZ7bds2YIePXpAq9Wid+/e+Pbbb8X7amtr8fTTT6N3794ICQlBmzZtMHPmTFy+fNndL0N2dPUHugqJgwMXPeg2wInUqcXM1cn8pk8uXOAxXKtyuXG5JRQKQRwecHXCs9JDbgOetgmyGRpwoSzjLuV8o4mJ3xl/70njiJk0B3UHpWDJpMl34uYlz12nCgGYe6Dc1T/pKfixM7e02inHF7mGBjiiVpoTgwOUSWvdeD1I27RpE+bPn49FixZh//796Nu3LzIyMlBQUGB3+927d2P69OmYM2cODhw4gEmTJmHSpEk4cuQIAKCqqgr79+/H888/j/379+Pf//43Tpw4gQkTJnjyZcmCJZPmXLnTk5k0AOjmgKitWLryUFZEruGBCr05O+juDIGnbYJc0Uezxl3K+VerDB7LvPoKPJPW3MWOs8jlNtAc3x/Nd1v/pKeIC9VAG6SAiVl6u6RQXCFvH2WMMz1ppdST5g94PUhbsWIF7rvvPsyePRupqalYs2YNdDod1q1bZ3f7N954A5mZmViwYAF69uyJJUuWoF+/fli5ciUAICIiAtu3b8eUKVPQvXt3DBkyBCtXrsS+ffuQk5PjyZfmMjwgkGKyzhgTpzs9mUkDzGUOoHkZDk8NDXDiwuRxHfCUb6enbYLkGhpwl3I+zxxE6oLcnnn1FbrGmzNpl65WS/rtO0KezD1pWUdy8c+fzjR+Hjf1T3oKQRBcKnnKfZyT2pNWaSXES9OdrRuvHvUMBgP27duHMWPGiLcpFAqMGTMG2dnZdh+TnZ1tsz0AZGRkNLk9AJSWlkIQBERGRsqybk/BpwilZNIKKwyorjVCEDz/4+zmgFaaXCrcjhIbZn6eXacKXZKx8JRvp6dtgvjQgFQ7qIY0p5zPcUY5X9RIC5AsGmDOGPIepDNX5MumVerrRFkIOaY7Pd0/6WlcCdKKZLKE4sRJ9O/k/WjhWhXCtK3P5J6w4NUgrbCwEEajEQkJCTa3JyQkIC8vz+5j8vLyJG1fU1ODp59+GtOnT0d4eLjdbfR6PcrKymz+fAFdvQSHlKtpfkBpExHscQHDHonm9/dEfnmTnneemuwEzFf5X/9uvpLf9keeSzIWFt9O97oNeNImqKTSIB7MXdVIA5pWzlcIwJvTr3FKmNXT5XFfgWfT5Cx58ixaiFopy4nb0/2Tnqa9lYenVPjggFzHOamZNEs/mmerKYT8+HX9oLa2FlOmTAFjDKtXr25yu6VLlyIiIkL8a9++vQdX2TTOZNL4AaWdF5pFuyaEQhDMgVhTPnOeKndyGYuGQxfOlmE86dvZVLATF6aR1SaI96OlxOhEQ3dX4cr5n9w3BCum9EVEcBBMDE4HlUUVgTU0wOkmynDINzyQL5OxOsfT/ZOehmfSzjuhlSZKcMgWpGnE/Tpi+n6RhGz9Bq8GabGxsVAqlcjPz7e5PT8/H4mJiXYfk5iY6ND2PEA7f/48tm/f3mQWDQAWLlyI0tJS8e/ChQtOviJ50dUPDlRKkODw1tAAYPa8S4kx+/WdzLOfAfBEudMdZRhPlTs51sEO16CbfW2KrDZB4tCAzJpWSoWAoZ1jcFu/drhrSAcAwCd7nOsH5d+XQJHf4HSp/8xPuyGTJleQ5un+SU8jR0+abJm0+v0YjCaUOeDlazFWb53vPWHBq0GaWq1G//79sWPHDvE2k8mEHTt2YOjQoXYfM3ToUJvtAWD79u022/MA7dSpU/jhhx8QExPT7Do0Gg3Cw8Nt/nwBHhBUSRCzveDFIA2wFrW1XzIu9oB6vDvKMGImzQNuAxwe7Nw1NBkAsO2P/BYeIY3DvB+trfu+79MGdoAgmHsCzxdVSn68pSctsII0sdwpYyaN/ybkchvwdP+kp+GCtheKqxzKXlkjd8VAG6QUh5aKHJjwJPkN/8Hr5c758+fjnXfewfr163Hs2DE8+OCDqKysxOzZswEAM2fOxMKFC8Xt582bh6ysLCxfvhzHjx/Hiy++iL1792Lu3LkAzAHaHXfcgb179+Ljjz+G0WhEXl4e8vLyYDA4rjHjC7iSSfP0ZCenW2LzMhy8DCBXQ6093FGG8WS5syEZqQkQBODghavILZUuB9AUcnl2Nkf7aB1GdI0DAGz8n/QMdaHYkxZo5U7z7+hiSbVsHp6iRppMQZon+ye9Qbv6fq5yq0lJRzCZmOw9aYBVX5oDWmkW307qSWvteD1Imzp1Kl599VW88MILSE9Px8GDB5GVlSUOB+Tk5CA319I/NGzYMGzYsAFr165F37598emnn2Lr1q1IS0sDAFy6dAlffvklLl68iPT0dCQlJYl/u3fv9sprdBYxk+ZET5q3grSWZDg8MTjgjjKMp8ud1sSHa9G/g1kwdNsR+wMyUimWeWigOe4cZO7x3LL3gmRh0EDtSYsOUSMmRA3GgD+vSM9A2kNuc3Wg6f7JxAitrP2T3kAbpBQFuqWUPEvd5KoSK/alUSYtkPAJ7465c+eKmbCG7Ny5s9FtkydPxuTJk+1un5KSIjk17auImTQHpzsNdSbk1l8te6vcaRG0rYDJxGx86xizusJ040mXl2HySmvs9qUJMJ9EpJRhPGUL1RSZaYnYe74EWX/k4Z5rO7q8P55F6xgbItvQQFOM7pmAuDANrpTr8cOxfNzc2/ETN88aBNp0JwB0iQ9F0dlinMwvlyWQzpfZXJ2TmZaEsamJ2HO2GAXlNYgPM/+2WmsGzZoO0Trkl+mRU1yFvvX2Vy3Bv7NhMruq8AvbwhYmPGuNJuTXVwnaUE9aq8frmTSiafh0p77OhDoHDMIvXa0GY0BwkNJrmYeUGB3UKgWqa424UGJ79VlWU4daozlscufggDs0uzwlZtsUGb3MgzF7zhY7dCXdEocvXgXg/iwaAAQpFZgyoB0AYMNv0gYILObqgZVJAywXPHIZrefKPN1pDe+fnJjeFkM7x/hFgAZYKhJSMmnuqhY46jqQV1oDxsy+qrEB1svpj1CQ5sPorDS5Kh0oeVr60YIhCN45SKqUCnSJMzc9Nyx58oNXqEYFjcq9emNya3Z5s9wJmE8WaW3DYWLA9qOuDxDwTFofDwRpgGWA4JfTjg8Q1NQaxQxmbFjgnWwsHp6uB2l1RpN4cnenJZS/0cEJrTQ+HCX3hWisg1ppF0ss8hsKPwmWAxkK0nwYtVIBVf2PzJHmYW9PdnKa6ktz18GrKaxlLF6b0hdROrNmlzPxq7fLnQBwU31g+Z0MfWlHLpmnbz2RSQOcGyDgZSO1UoEwL77v3qJLvHxaaVcq9DAxQKUQArJ07CzOyHDI7TbAsZisN59Ju0QaaX4FBWk+jCAIVv6dLWfSvD00wOleH6QdbzDhWVgh71i6I/AyzK392uHuIWYpC6klN8C7050cXvLcfaYQpdWOT5s1pKhCbzU04Dm5mTsHmTXTHB0gKCy3yLV4KzPsTXi5M6e4CjW1jg8P2YMPDcSHafymFOkJnBG0LXF7ubP5TBrXSKN+NP+AgjQfJ6R+eMCRTJpY7vSyFYgow9FEudNb/UVTBraHIAC7zxThbKHjE3OGOpMYVHhSJ60hXeJD0TU+FLVGhp+OFzi9H17q7BQb4lFfv9E94xEXpkFhhQE/HGu5ZFvkAU09XyYmRI0oXRAYc93DkwdpCW7oR/NnOtRrpeWWVjs8mcwzaXJOdgKOT3eKk50kv+EXUJDm4+gkZNK86TZgDS93/llYCX2dZd2esoRqinZROozqVl9yk6CAbz1dG+Jm786WyEwzZ9O+c8J/lHPEA/po9ghSKjB1gFmOw5FspqiRFqDNz4IgoGt8/fCAi31peTJrpAUKcaEaaIMUMDFLhqol3HUxGuugTppY7iT5Db+AgjQfR0omTexJi/FukJYYrkWYVgWjidloPIlCtl7MjNw52Fzy3LLvok0A2Ry81KkNUkAl40i9M/CS539OXnFa5PRQvdNAn3aeDdIAYGp9NtORAYKiABWytaarTB6ecltCBQqCIEjuS3PXxSgvd16tqkVtM9P+1JPmX1CQ5uPo6strLU13llbVip5u3jBXt0YQBLvDA6IllBflFK7vHofEcC2KKw343kGbJe744M2hAU6vNuFoHx2MmloT/nPiilP78FYmDTD3S15XP0DwyZ7mBwgsQraBmUkDLPZQrmbSRHN1yqRJRmqQ5q6L0cjgIPB2wuImsmkmE6Mgzc+gIM3H4eW1qhYEbfkBJDZUIwZ23oQ3PZ+wGh5w19STFFRKBaYMdLzkBgAVNd6V37BGEARk1mfTsv6QPuVZWKHH5foTdq823vGonV4/QPDpvuYHCCzm6oGcSZNHK40yac7TXqIMh7vKnQqFIB47m9JKK6o0wFBngiDQZ+0vUJDm4ziaSePCsR2ifePqyX4mzTeESacObA+FAGT/WYQ/HWjI9gX5DWu4xtuPxwocLtlyxKGBOM8ODVgzumc84usHCJrTfAtUc3VreLnzfFGlSxOeeTKbqwcSUjJpjDEU17uqROnkP861pJXGs2gJYVqoVXR69wfoU/RxpGbSvD00wBEzaXaCNG8NDnDaRgZjVPd4AI5pdvGhDV/IpAHANe0jkRCuQbm+DrtPF0l67JH6frTeXih1cswOBOZs5ifNDHAEqrm6NXGhGkQEm/X9pEwkW8MYEzNpcvp2BgpSgrRKg1HMDrvjeytOeDahlUaenf4HBWk+jqOZtBwf0Ujj9Eg0l9IuXa1GeU0tGGNW5U7vn3TvFEtuLQ8QVOjNmmS+kklTKARxgEDqlOehS94P0gDHBgioJ41PeJqzaSfznRseKKuuQ02tOXCgTJp0xCCtqKpFX+ji+gsLbZDCLW0nMS1m0sznAepH8x8oSPNxHJ3u9BUhW06ELkhsUj6ZX+72K0ypjLIaIMhqQcHf276d9uB9aduP5jvk68o54iNBWksDBCYTs5THfeD74k14X9ppJ/vSeBYtUhcEbZB3JWRaI/yYWq6vw9Wq5kWkRW0/N5Xo+X6vNNGTdvkqN1anIM1foCDNx+E6aRUtlDt9xRLKmm5iX1qFeIUZHKT0icEGlVKBqQNbLrkB3vfttMegjtGI0gWhpKoWe84VO/SYK+V65JbWQBCAXl4O0oDmBwjKampRZzJnLXwh8+pNXJ3wzC01l8BostM5tEFKJISbg6OWSp7ubuloKZN2kcqdfgcFaT6OmElrRszWaDV27SuZNMB6eKBMvML0pRMuHyD49c/iZhXdLYMDvpOFUCkVGJuaAAAtZgI5R6ycBnwhK9jcAAHvRwvTqqBR+c777g348MBJJ7XS8mmy02Uc7Utzd5BmGRxooiet/jzQjjJpfgMFaT6O6N3ZTLkzr6wGtUaGIKXgU1fL1jIcvli6ahMZjOv5AEEz2TRLkOadacim4O4D2/7Ig8nUfK8MYJns9Hapk9PcAAE/CcUFcD8ah7sOnC+qkjzNCwB5peb30peODa2N9j4SpPFyZ1OuA5fqp/wpk+Y/UJDm4/DSYFUzgwM59ea/7aJ0PmWebC3D4UtDA9bcOdgyQNCUxIGl3OlbGZ1ru8QiVKNCfpkeBy5cbXH7w14UsW0K6wGCc1bTi0U+GNR7i4Rwjejgca7QcaNvDu9Jo6EB5+ngoFaa2zNpYdy/s3GQVl5jETSnnjT/gYI0H4cHBpXN9KTxA4e3nQYa0iU+FAoBKKmqFaU4fC1IG9ktDkkRWpRU1WJbE+KwXMzWF0qE1mhUStzQw5wJbGrt1hwW7aAi3bksSVgPEFjLoZBGmgVXJzzzeE8alTudxtFyp7svRrnGZGGFvtGkKR8aiAgO8rljFeE8FKT5OA5l0nxwaAAwN9ymxIQAALLPmPW8vC1k2xDrAYKmHAjEcqfW9w58N1kZrjcnD3ClXI+8svqhAS85DTSFJZtpGSAgjTRbRKN1JyY888rqy50UpDmN1J40dx3n+O9BX2dqNExG8hv+CQVpPo4oZttMT5rFbcC3gjTA0pd2NLcMgHctoZqCDxD8drbYrswB7wf0pelOzsjucdAGKXChuFp8j+1hPTTga6/jhh6NBwh4T1oM9aQBsAwPnHZieEAcHKByp9PwY+vlq9XNmpu7u9ypU6ugqx8ma1jyJCFb/4SCNB8nhIvZNjPd6auZNADoXt+XxvG1TBoAJEUEi2VDe3IcvlruBMwH7ZHdzOXCbc1MeR7ywVInJ8iOHAo/AQWyb6c1ooenRBmOmlqjGDhQkOY8cWEaaIMUMDFLMGQPT7iqiDIcDVwHLpKxul9CQZqPw6+aqmuNMDYxwedrQrbW9GgQpPlaTxqHl9w+2994gMAXxWytyRRLnk0Hab44NGBNwwECd4uCtjZ4T9rZwspmTekbUlBf6lSrFIjU+dZ0cmtCEASHSp4eCdJEk3XbTBrvSaMgzb+gIM3HsS5NVduZPqwy1Ik/Vl8M0ro1CNIul1Y3GWx6k5Hd4tEmQourVbWNdMcqfcxgvSE39EhAkFLAqYKKJlXpD1+6CsB35Dca0i5KJ2YEN/7vAmXSGpAUoUWoRoU6E2vSRsse1p6dguA7k9+tkZaCNH2dUewTc+fFRVMm6yS/4Z9QkObjaFQKcFUNeybrF4rNKe6I4CBEBPvelfKJXNsemhe++APDl/2ILImek+5GqRAwdaA5m2Y9QFBnNInBsa/1cnEigoMwrHMsAPtTngXlNcgv0/vk0IA13IFg8/9ycLl+IvFCiW8G9Z5GEAR04c4DEoYHSH5DPtq3IMPBs2gqhYDwYPcdK0ST9QaCtpeo3OmXUJDm4wiCYOlLszPhaTFW970fZtaRXDy8YX+j2/NKa/DgR/t9LlCbMrAdFAKw51yx2KBt/Z77mk6aNbzkac99gA8NdI4L9dlAEwBG94hHuFaF4qpa0RD8yS2/+2RQ7w2ckeHIL6WhAbloKZPGg7SoELVbs5aWnjRLJs1QZ0JBuTloI400/4KCtFaArhmtNF/07ATMVlWLvzoKezkQftvir476VJbEPEBgtlra8JtZs4u/52qlwqfticamJkAhmHvPGl7pi0MDPlrq5PxwLF8U47TGV4N6T8MnpaVk0nJLyRJKLhwN0qJ17i3R2zNZzyutAWPmygu1CPgXFKS1AiwTno1PYDk+OjSw52yxeIKwB4P5BLLnrGPm4J5iRoMBggofdRtoSGyoBgNTogE0Lnke8fGhAcAS1NvDV4N6T9OFy3BImPDMp3KnbIhBWlGVXU1CTwwNANYm65Yg7aKVRhr1HvoXFKS1AniJyp6grTjZGeVbQVpBedMBmjPbeYrrusWhbWQwSqtr8d2RXJ8Wsm3ITU2UPEXPzna+G6S11qDek/By55+FFc1qdVljPThAuEa7+mNsub4OpdW1je7njfzRbs5kWXrSLOVO0kjzXyhIawVwGQ57Juu+qpEWH+bYScHR7TyFeYDA4kAg+naqfT9Iy6gP0vbllKCg/uRcUGYeGlAIQGqS7w4NtNag3pO0jQxGiFqJWiPD+SLHPDzzSimTJhfBaiXi670z7ZU83e02wLHXk0ZDA/4LBWmtADGT1kDQljHms24DgzpGm8f+m7hfgPnqflDHaE8uyyGmDGgPpULA/86V4EDOVQC+K79hTVJEMNLbR4Ix4Pt65f7DrWRooLUG9Z7EesLTEecBk4lZ3AYokyYL/DhrL0gurvJMuZNn0kqqDKirz6jyTBoNDfgfFKS1AprKpF2p0KOm1gSF4Hs/TqVCwKLxqQDQKFDj/140PhVKhe/1TyRGaEUHgnd3nQUA1JpMraIfquGUp1jq9OF+NKB1B/WepEu9h+dJB/rSiioNqDMxCALEDBDhGh1imh4eKK7wTJAWpVNDEADGgJIqc9mVS9ZQJs3/oCCtFfD/27v3qCjr/A/g75mRGS4CynVAEVC8IYiliZibW5Jg5ZGtLXRrQ/PoqbRjsmprpehu54y5a9HFle23W+0l09VNKy03l4ROiVgYv8JbRnagHzcvcRvkIvP9/TE8D4yADMbM88zwfp0zJ3jmGebLwxN++H6/n8/Hp5cm69J+tDB/L+iHqO9HmRoXhh0P3dztr3ijvyd2PHQzUuPCFBpZ38Z1bNKub7b+Evzf8jqXKAWROskapBV8dwm1Ta34+gf170cDXDuodybpvrQnw1OaRQsaaoCHTn2/H1zRqOvUSnNW4oBOq5EzSC92JA9wT5r7Uvz/3O3btyMqKgqenp5ITEzE8ePHr3v+nj17MGHCBHh6eiI+Ph4ffPCBzfPvvPMO5s6di8DAQGg0GhQXFztw9M7RWwkOqZCtGmukSVLjwvDpU3fg7WUz8NLCKXh72Qx8+tQdqg7QDpVU4k9HSrsdd4VSEFFBPphg9EW7ReDwqWqXmUkDXDuodxap0fo5O2qlVbFG2oC7XhkOqZWZM1rfBXbpOmCxCLaEcmOKblLZvXs3MjMzkZOTg8TERGRnZyMlJQVnz55FSEhIt/OPHj2KRYsWwWQy4Z577sHOnTuRlpaGEydOIC4uDgBgNpsxa9YsPPDAA1i2bJmzvyWH6G0mTa1JA9fSaTVIGhOo9DDs0ld9Nw2spSDujDWqdlYnNc6IM1UN2JFXipqGFmjQvdG9WqXGheHOWCOOn7+MmoZmhPhalzjVeq2dbWzHcud3F8y42m7BkOvMkFWy/MaAu16Q1pk44PilZet7NOKSuQUXG1vQ2m7d9sK9h+5H0Zm0F154AcuWLcOSJUsQGxuLnJwceHt74/XXX+/x/JdeegmpqalYu3YtJk6ciN///ve4+eab8eqrr8rn/PrXv8bGjRuRnJzsrG/D4XqbSStTafkNV+YOpSB8Pa3twb67aO3xKADMffETVc8AdiUF9QumjEDSmEAGaF2MGOYFLw8dWtst1230DXTpNuDP/WgDRQrSKmqv2JRBabcI1HaU5XDmTNrFxlY5szPUz5PL2m5IsZ9oa2srioqKbIIprVaL5ORkFBQU9PiagoKCbsFXSkpKr+fbq6WlBfX19TYPNelrT5q0mZV+OlcvBXGopBLPHeheFNYVlmqpb1qt/T08O2ukcQlsoAT7GmAYooVFWAM1SW1TK6T6tsO8Hd9DuWv/TpbfcG+KBWkXL15Ee3s7QkNDbY6Hhoaiqqp7/0EAqKqq6tf59jKZTPD395cfERERP+nrDbTesjvLVdptwJW5cikIV2zFRf0nFbXta18auw0MPI1G0+OSp7TU6e/l4ZTZrKAue9KYNODeODcKYP369airq5Mf5eXlSg/JhlTfqutyZ8vVdnnPCZc7B44rl4Jwh6Va6ttYO3t4VjJxwCF6CtIuOamQrSSwYybtYpeZNLWVYaKBoViQFhQUBJ1Oh+rqapvj1dXVMBqNPb7GaDT263x7GQwG+Pn52TzUpDNI61zurKi1NtT18tCxoe4AcuVSEK6+VEv26ZxJu36Qxj1pjiHXSrvUfSbNGfvRgM5g8KK5VV525XKne1IsSNPr9Zg6dSpyc3PlYxaLBbm5uUhKSurxNUlJSTbnA8Dhw4d7Pd9d+HQsdzZ1We7smtnJhroDy1VLQbjyUi3ZTyrDUXqhsdela3PLVTR0zLwbuSdtQF1vudNpQVqXPWk/cLnTrSlagiMzMxMZGRmYNm0apk+fjuzsbJjNZixZsgQA8PDDD2PEiBEwmUwAgFWrVmH27NnYtm0b7r77buzatQtffPEFXnvtNflrXr58GWVlZaioqAAAnD17FoB1Fu6nzrgpxbsjccDcJXGgjPvRHMoVS0FIS7VVdc097kvTwBpoqnGpluw3crg3PD20aG6zoPxyE6KCfLqdIyUNDDUMcYmWZq5EDUFa1z1pUrP3kZxJc0uK7klLT0/HH//4R2zcuBFTpkxBcXExDh06JCcHlJWVobKyMxtt5syZ2LlzJ1577TUkJCRg79692L9/v1wjDQDee+893HTTTbj77rsBAAsXLsRNN92EnJwc535zA8inowRHU5c9aZ1JA/wf01FcrRSEKy/Vkv10Wg3GBF8/w7OzsTqXOgeaHKRdaoLoSOl0fpBm/bleaWtHQ7P13wXuSXNPiv+JtXLlSqxcubLH5/Ly8rodu//++3H//ff3+vUWL16MxYsXD9Do1EGaSWtqa4fFIqDVajrLb3AmjbqQlmo3v3/KJonA6O+JrPmxql2qpf4ZGzIUJyvq8U11A+6MDe32vNxtgMVNB9zIjkSthparqLvShmHeejlxwFlBmrdeJ8+mAtayHz6cMXVL/Km6AGkmTQig+Wo7vPVDXKbbADmfKy7VUv9IGZ7f9jaTVi9ldnJ2ZaB56XUI8TWgpqEFZZebMMxbj8sdLaECnZTEpdFoEOhjYI20QYBBmgvwHKKDRmMN0swttkEa96RRT1ypFRf1n5zhWdNzrTSpRhozOx1jVIC3HKRNHjkMl81StwHnXe+goXoGaYMA66S5AK1WA2+PzgzPuqY2eR8Ca6QRDT5dZ9IsPWR4skaaY12bPCDNpAV4O68ckpThCTCz050xSHMR3l1qpUm/GIJ9DfDqKM9BRIPHqABv6IdY9yRJJRi6YrcBx4q4JnlAThxwYs3KgC7tp9raLewk4qYYpLmIrrXSOhur868nosHINsOz+5KnlDjAvp2OERnYOZPW0HIVbe3WAMlZHQcOlVTiw5Od7RD/eawMs57/mL153RCDNBfRtVZa+Y9MGiAa7KR9ad9c03mgrd2CC43W5bdQ7klziK7LnZcbrbNo1oxLx69sHCqpxGP/PGHTgQawBuaP/fMEAzU3wyDNRUgZnuaWq8zsJCKMC+15Ju1CQwuEAIZoNQhy4kb2wUT63VtRewU1DR370Zwwi9ZuEdj8/qkei1VLxza/f4pLn26EQZqL6NpkvZyZnUSDXkxIz2U4pPIbIb4GaFl2xSGCfQ0wDNHCIoCv/68OgHOCtOPnL9vUP7yWgDVp5Pj5yw4fCzkHgzQX4SMVtG1tZ/kNIpJ7eJ6rts3wrGYhW4fTaDTybFpxeS0A5wRpNQ29B2g3ch6pH4M0F+HdkTjQ0NyG/+vI5uJyJ9HgFRngDb1Oiytt7XK9LKBLIVsGaQ7VGaT9CMA5QVqIr30/U3vPI/VjkOYipOXO0gtmXLUI6HVaptcTDWJDdFqMDrY2V++65NnZt5O/HxxJWskov2wNkJ2R2Tk9OgBh/p7devNKNADC/K0dRsg9MEhzEdJM2unKegDW4oVs80M0uMX00HmgsyUUgzRHunYlwxndBnRaDbLmxwJAt0BN+jxrfiz/bXAjDNJcROdMmvUvZu5HI6JxHZ0HupbhYHN15+gepHn0cubASo0Lw46Hbu728zX6e2LHQzcjNS7MKeMg52DvThchzaRJRRNHBbBIJdFg19nDszNIq+ZMmlNIBW0lzuzbmRoXhjtjjTh+/jJqGpoR4mtd4uQMmvthkOYipOxOCXt2EpGU4fltdQOEsP4BV8mZNKcYOfzaIM15LaEA69Jn0phAp74nOR+XO12Et8G2kjUzO4koMtAHHjoNzK3tqKhrRt2VNrRctQBg4oCjeel1CO7Sq7PskplFZGnAMUhzEd1m0hikEQ16HjotooOsGZ7nqhvkpIFh3h5OaVE0mB0qqUTtlTb589X/+l/2z6QBxyDNRUh70iSjAhmkEREwtkvnATlpgLNoDiX1z5T2CEvYP5MGGoM0FyFldwKAv5cH/Dydk0lEROom7Uv7prqBmZ1OwP6Z5EwM0lxE16WLAB89fwEQEYDOmbRzNY2skeYE7J9JzsQgzQUcKqnEr/7nmPz5+Ytm7n0gIgBdMzwb5fIbTBpwHPbPJGdikKZy0t6HmoYWm+Pc+0BEABAV6IMhWg0aWq6iuLwOgLU1EDkG+2eSMzFIUzHufSCivuiHaBHVkeEptY0LZZDmMOyfSc7EIE3FuPeBiOwhdR6QcE+a47B/JjkTgzQV494HIrLH2I4enhIGaY7F/pnkLGwLpWLc+0BE9hjTsdwJAB5aDXw9+avd0dg/k5yBM2kqxr0PRNSXQyWV+P3BU/LnbRaBn209wqQiJ5D6Zy6YMgJJYwIZoNGAY5CmYtz7QETXI2V/X2xstTnO7G8i98AgTeW494GIesLsbyL3x40LLoB7H4joWv3J/k4aE+i8gRHRgGGQ5iKkvQ9ERACzv4kGA1Usd27fvh1RUVHw9PREYmIijh8/ft3z9+zZgwkTJsDT0xPx8fH44IMPbJ4XQmDjxo0ICwuDl5cXkpOTce7cOUd+C0RETsXsbyL3p3iQtnv3bmRmZiIrKwsnTpxAQkICUlJSUFNT0+P5R48exaJFi7B06VJ8+eWXSEtLQ1paGkpKSuRztm7dipdffhk5OTkoLCyEj48PUlJS0NzMvyiJyD0w+5vI/WmEEIruKk1MTMQtt9yCV199FQBgsVgQERGBJ554Ar/97W+7nZ+eng6z2YwDBw7Ix2bMmIEpU6YgJycHQgiEh4fjN7/5DdasWQMAqKurQ2hoKN58800sXLiwzzHV19fD398fdXV18PPzG6DvlIhoYEnZnQBsEgikwI3JRTTYuNu/34rOpLW2tqKoqAjJycnyMa1Wi+TkZBQUFPT4moKCApvzASAlJUU+//z586iqqrI5x9/fH4mJib1+zZaWFtTX19s8iIjUjtnfRO5N0cSBixcvor29HaGhoTbHQ0NDcebMmR5fU1VV1eP5VVVV8vPSsd7OuZbJZMLmzZtv6HsgIlISs7+J3BezOwGsX78emZmZ8uf19fWIiIhQcERERPZj9jeRe1J0uTMoKAg6nQ7V1dU2x6urq2E0Gnt8jdFovO750n/78zUNBgP8/PxsHkRERERKUjRI0+v1mDp1KnJzc+VjFosFubm5SEpK6vE1SUlJNucDwOHDh+Xzo6OjYTQabc6pr69HYWFhr1+TiIiISG0UX+7MzMxERkYGpk2bhunTpyM7OxtmsxlLliwBADz88MMYMWIETCYTAGDVqlWYPXs2tm3bhrvvvhu7du3CF198gddeew0AoNFo8OSTT+K5557D2LFjER0djQ0bNiA8PBxpaWlKfZtERERE/aJ4kJaeno4LFy5g48aNqKqqwpQpU3Do0CF5439ZWRm02s4Jv5kzZ2Lnzp149tln8fTTT2Ps2LHYv38/4uLi5HPWrVsHs9mM5cuXo7a2FrNmzcKhQ4fg6cmijkREROQaFK+TpkbuVmeFiIhoMHC3f78V7zhARERERN0xSCMiIiJSIQZpRERERCrEII2IiIhIhRTP7lQjKZeCPTyJiIhch/TvtrvkRDJI60FDQwMAsDUUERGRC2poaIC/v7/Sw/jJWIKjBxaLBRUVFfD19YVGY9ukWOrrWV5e7hbpvc7C63ZjeN36j9fsxvC63Rhet/5z5DUTQqChoQHh4eE2NVZdFWfSeqDVajFy5MjrnsMenzeG1+3G8Lr1H6/ZjeF1uzG8bv3nqGvmDjNoEtcPM4mIiIjcEIM0IiIiIhVikNZPBoMBWVlZMBgMSg/FpfC63Rhet/7jNbsxvG43htet/3jN7MfEASIiIiIV4kwaERERkQoxSCMiIiJSIQZpRERERCrEII2IiIhIhRik9dP27dsRFRUFT09PJCYm4vjx40oPSbU2bdoEjUZj85gwYYLSw1KdTz75BPPnz0d4eDg0Gg32799v87wQAhs3bkRYWBi8vLyQnJyMc+fOKTNYFenrui1evLjb/ZeamqrMYFXCZDLhlltuga+vL0JCQpCWloazZ8/anNPc3IwVK1YgMDAQQ4cOxX333Yfq6mqFRqwO9ly3n//8593ut0cffVShEavDjh07MHnyZLlobVJSEj788EP5ed5rfWOQ1g+7d+9GZmYmsrKycOLECSQkJCAlJQU1NTVKD021Jk2ahMrKSvnx6aefKj0k1TGbzUhISMD27dt7fH7r1q14+eWXkZOTg8LCQvj4+CAlJQXNzc1OHqm69HXdACA1NdXm/nv77bedOEL1yc/Px4oVK3Ds2DEcPnwYbW1tmDt3Lsxms3zO6tWr8f7772PPnj3Iz89HRUUF7r33XgVHrTx7rhsALFu2zOZ+27p1q0IjVoeRI0diy5YtKCoqwhdffIE77rgDCxYswMmTJwHwXrOLILtNnz5drFixQv68vb1dhIeHC5PJpOCo1CsrK0skJCQoPQyXAkDs27dP/txisQij0Sj+8Ic/yMdqa2uFwWAQb7/9tgIjVKdrr5sQQmRkZIgFCxYoMh5XUVNTIwCI/Px8IYT13vLw8BB79uyRzzl9+rQAIAoKCpQapupce92EEGL27Nli1apVyg3KRQwfPlz85S9/4b1mJ86k2am1tRVFRUVITk6Wj2m1WiQnJ6OgoEDBkanbuXPnEB4ejtGjR+PBBx9EWVmZ0kNyKefPn0dVVZXNfefv74/ExETed3bIy8tDSEgIxo8fj8ceewyXLl1SekiqUldXBwAICAgAABQVFaGtrc3mfpswYQJGjRrF+62La6+b5K233kJQUBDi4uKwfv16NDU1KTE8VWpvb8euXbtgNpuRlJTEe81ObLBup4sXL6K9vR2hoaE2x0NDQ3HmzBmFRqVuiYmJePPNNzF+/HhUVlZi8+bN+NnPfoaSkhL4+voqPTyXUFVVBQA93nfSc9Sz1NRU3HvvvYiOjkZpaSmefvppzJs3DwUFBdDpdEoPT3EWiwVPPvkkbr31VsTFxQGw3m96vR7Dhg2zOZf3W6eerhsA/OpXv0JkZCTCw8Px1Vdf4amnnsLZs2fxzjvvKDha5X399ddISkpCc3Mzhg4din379iE2NhbFxcW81+zAII0cZt68efLHkydPRmJiIiIjI/Gvf/0LS5cuVXBkNBgsXLhQ/jg+Ph6TJ0/GmDFjkJeXhzlz5ig4MnVYsWIFSkpKuE+0n3q7bsuXL5c/jo+PR1hYGObMmYPS0lKMGTPG2cNUjfHjx6O4uBh1dXXYu3cvMjIykJ+fr/SwXAaXO+0UFBQEnU7XLfOkuroaRqNRoVG5lmHDhmHcuHH49ttvlR6Ky5DuLd53P93o0aMRFBTE+w/AypUrceDAARw5cgQjR46UjxuNRrS2tqK2ttbmfN5vVr1dt54kJiYCwKC/3/R6PWJiYjB16lSYTCYkJCTgpZde4r1mJwZpdtLr9Zg6dSpyc3PlYxaLBbm5uUhKSlJwZK6jsbERpaWlCAsLU3ooLiM6OhpGo9Hmvquvr0dhYSHvu3764YcfcOnSpUF9/wkhsHLlSuzbtw8ff/wxoqOjbZ6fOnUqPDw8bO63s2fPoqysbFDfb31dt54UFxcDwKC+33pisVjQ0tLCe81OXO7sh8zMTGRkZGDatGmYPn06srOzYTabsWTJEqWHpkpr1qzB/PnzERkZiYqKCmRlZUGn02HRokVKD01VGhsbbf7aPn/+PIqLixEQEIBRo0bhySefxHPPPYexY8ciOjoaGzZsQHh4ONLS0pQbtApc77oFBARg8+bNuO+++2A0GlFaWop169YhJiYGKSkpCo5aWStWrMDOnTvx7rvvwtfXV9774+/vDy8vL/j7+2Pp0qXIzMxEQEAA/Pz88MQTTyApKQkzZsxQePTK6eu6lZaWYufOnbjrrrsQGBiIr776CqtXr8Ztt92GyZMnKzx65axfvx7z5s3DqFGj0NDQgJ07dyIvLw//+c9/eK/ZS+n0UlfzyiuviFGjRgm9Xi+mT58ujh07pvSQVCs9PV2EhYUJvV4vRowYIdLT08W3336r9LBU58iRIwJAt0dGRoYQwlqGY8OGDSI0NFQYDAYxZ84ccfbsWWUHrQLXu25NTU1i7ty5Ijg4WHh4eIjIyEixbNkyUVVVpfSwFdXT9QIg3njjDfmcK1euiMcff1wMHz5ceHt7i1/84heisrJSuUGrQF/XraysTNx2220iICBAGAwGERMTI9auXSvq6uqUHbjCHnnkEREZGSn0er0IDg4Wc+bMER999JH8PO+1vmmEEMKZQSERERER9Y170oiIiIhUiEEaERERkQoxSCMiIiJSIQZpRERERCrEII2IiIhIhRikEREREakQgzQiIiIiFWKQRkQu580338SwYcPkzzdt2oQpU6Y4/H2joqKQnZ3t8PchIgIYpBHRAFu8eDE0Gg00Gg08PDwQHR2NdevWobm52WHvuWbNGpsegD/VtUGg5PPPP8fy5csH7H2IiK6HvTuJaMClpqbijTfeQFtbG4qKipCRkQGNRoPnn3/eIe83dOhQDB061CFfu6vg4GCHvwcRkYQzaUQ04AwGA4xGIyIiIpCWlobk5GQcPnwYAGCxWGAymRAdHQ0vLy8kJCRg79698mvz8vKg0Whw8OBBTJ48GZ6enpgxYwZKSkp6fb+eljtff/11TJo0CQaDAWFhYVi5cqX83AsvvID4+Hj4+PggIiICjz/+OBobG+X3X7JkCerq6uQZwU2bNgHovtxZVlaGBQsWYOjQofDz88MDDzyA6urqbuP6xz/+gaioKPj7+2PhwoVoaGiQz9m7dy/i4+Ph5eWFwMBAJCcnw2w29/uaE5H7YZBGRA5VUlKCo0ePQq/XAwBMJhP+/ve/IycnBydPnsTq1avx0EMPIT8/3+Z1a9euxbZt2/D5558jODgY8+fPR1tbm13vuWPHDqxYsQLLly/H119/jffeew8xMTHy81qtFi+//DJOnjyJv/3tb/j444+xbt06AMDMmTORnZ0NPz8/VFZWorKyEmvWrOn2HhaLBQsWLMDly5eRn5+Pw4cP47vvvkN6errNeaWlpdi/fz8OHDiAAwcOID8/H1u2bAEAVFZWYtGiRXjkkUdw+vRp5OXl4d577wVbKhMRAEDhBu9E5GYyMjKETqcTPj4+wmAwCABCq9WKvXv3iubmZuHt7S2OHj1q85qlS5eKRYsWCSGEOHLkiAAgdu3aJT9/6dIl4eXlJXbv3i2EEOKNN94Q/v7+8vNZWVkiISFB/jw8PFw888wzdo95z549IjAwUP782q8viYyMFC+++KIQQoiPPvpI6HQ6UVZWJj9/8uRJAUAcP35cHpe3t7eor6+Xz1m7dq1ITEwUQghRVFQkAIjvv//e7rES0eDBPWlENOBuv/127NixA2azGS+++CKGDBmC++67DydPnkRTUxPuvPNOm/NbW1tx00032RxLSkqSPw4ICMD48eNx+vTpPt+7pqYGFRUVmDNnTq/n/Pe//4XJZMKZM2dQX1+Pq1evorm5GU1NTfD29rbrezx9+jQiIiIQEREhH4uNjcWwYcNw+vRp3HLLLQCsS6S+vr7yOWFhYaipqQEAJCQkYM6cOYiPj0dKSgrmzp2LX/7ylxg+fLhdYyAi98blTiIacD4+PoiJiUFCQgJef/11FBYW4q9//au87+vgwYMoLi6WH6dOnbLZl/ZTeHl5Xff577//Hvfccw8mT56Mf//73ygqKsL27dsBWIPFgebh4WHzuUajgcViAQDodDocPnwYH374IWJjY/HKK69g/PjxOH/+/ICPg4hcD4M0InIorVaLp59+Gs8++yxiY2NhMBhQVlaGmJgYm0fXGSkAOHbsmPzxjz/+iG+++QYTJ07s8/18fX0RFRXVa0mOoqIiWCwWbNu2DTNmzMC4ceNQUVFhc45er0d7e/t132fixIkoLy9HeXm5fOzUqVOora1FbGxsn+OUaDQa3Hrrrdi8eTO+/PJL6PV67Nu3z+7XE5H74nInETnc/fffj7Vr1+LPf/4z1qxZg9WrV8NisWDWrFmoq6vDZ599Bj8/P2RkZMiv+d3vfofAwECEhobimWeeQVBQENLS0ux6v02bNuHRRx9FSEgI5s2bh4aGBnz22Wd44oknEBMTg7a2NrzyyiuYP38+PvvsM+Tk5Ni8PioqCo2NjcjNzUVCQgK8vb27LYMmJycjPj4eDz74ILKzs3H16lU8/vjjmD17NqZNm2bXOAsLC5Gbm4u5c+ciJCQEhYWFuHDhgl3BKBG5P86kEZHDDRkyBCtXrsTWrVuxfv16bNiwASaTCRMnTkRqaioOHjyI6Ohom9ds2bIFq1atwtSpU1FVVYX3339fzhDtS0ZGBrKzs/GnP/0JkyZNwj333INz584BsO4De+GFF/D8888jLi4Ob731Fkwmk83rZ86ciUcffRTp6ekIDg7G1q1bu72HRqPBu+++i+HDh+O2225DcnIyRo8ejd27d9t9Xfz8/PDJJ5/grrvuwrhx4/Dss89i27ZtmDdvnt1fg4jcl0YI5noTkXrk5eXh9ttvx48//thj1X8iosGCM2lEREREKsQgjYiIiEiFuNxJREREpEKcSSMiIiJSIQZpRERERCrEII2IiIhIhRikEREREakQgzQiIiIiFWKQRkRERKRCDNKIiIiIVIhBGhEREZEKMUgjIiIiUqH/B6O6PfnLzI04AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias = np.abs( np.array(V_replications[\"V_replications_estimator\"]) -   np.array(V_replications[\"V_replications_M1_pred\"]))\n",
    "\n",
    "num_replications = config[\"num_replications\"]\n",
    "\n",
    "avg_V_bias = np.mean(bias)\n",
    "std_dev_bias = np.std(bias)\n",
    "print(f\"Average bias for the estimator: {np.mean(avg_V_bias)}\")\n",
    "print(f\"Standard Deviation for the estimator: {std_dev_bias}\\n\\n\")\n",
    "\n",
    "plt.plot(range(1, num_replications + 1), bias, 'o-')\n",
    "plt.xlabel(f'Replications')\n",
    "plt.ylabel('Value fn. bias Value')\n",
    "plt.title(f'V bias values for {num_replications} Test Replications (Training Sample Size: {training_validation_prop*config[\"sample_size\"]})')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc3tG6scO4kM"
   },
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ae5da6304040b3b623bccab6987fbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b74f94741b460782b03302a3628d3f",
      "placeholder": "",
      "style": "IPY_MODEL_869dc90565954dfe85024370feaf437c",
      "value": "30/30[12:50&lt;00:00,25.67s/it]"
     }
    },
    "30bd93bc900a453f977c7b45e54a64e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35c0860a48fd47148273906eaf920dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70b096ad51dc490fa5b8e618e7d8694c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30bd93bc900a453f977c7b45e54a64e8",
      "placeholder": "",
      "style": "IPY_MODEL_35c0860a48fd47148273906eaf920dd4",
      "value": "Replications_M1:100%"
     }
    },
    "793bf2a6285d43178a6f96762a9f9c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efafddbf1d724b539fffd04270ee828a",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9169dc77b4c43fc8c55da01d38dd2a1",
      "value": 30
     }
    },
    "869dc90565954dfe85024370feaf437c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ffd24a57774ceda9f2e49c356a48a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d391c23f4ca94548b4096e524e45007c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70b096ad51dc490fa5b8e618e7d8694c",
       "IPY_MODEL_793bf2a6285d43178a6f96762a9f9c42",
       "IPY_MODEL_07ae5da6304040b3b623bccab6987fbb"
      ],
      "layout": "IPY_MODEL_98ffd24a57774ceda9f2e49c356a48a4"
     }
    },
    "e0b74f94741b460782b03302a3628d3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efafddbf1d724b539fffd04270ee828a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9169dc77b4c43fc8c55da01d38dd2a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
