{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EtoqrJZNRXp"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GaGDesd3L5WP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "\n",
    "import sys\n",
    "from itertools import product\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqa9h8xbL5Lr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khh1C95xMIRr"
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hXZ-PCnMEW6"
   },
   "source": [
    "## Simulation run utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7rhKPDQL-qI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 0. Simulation run utils\n",
    "\n",
    "def setup_logging(job_id):\n",
    "    file_name = f\"Output_DS_{job_id}.txt\"\n",
    "    logging.basicConfig(\n",
    "        filename=file_name,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FlushFile:\n",
    "    \"\"\"File-like wrapper that flushes on every write.\"\"\"\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def write(self, x):\n",
    "        self.f.write(x)\n",
    "        self.f.flush()  # Flush output after write\n",
    "\n",
    "    def flush(self):\n",
    "        self.f.flush()\n",
    "\n",
    "\n",
    "\n",
    "def load_config(file_path='config.yaml'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def extract_unique_treatment_values(df, columns_to_process):\n",
    "    unique_values = {}\n",
    "\n",
    "    for key, cols in columns_to_process.items():\n",
    "        unique_values[key] = {}\n",
    "\n",
    "        for col in cols:\n",
    "            all_values = [item for sublist in df[col] for item in sublist]\n",
    "            unique_values[key][col] = set(all_values)\n",
    "\n",
    "    log_message = \"\\nUnique values:\\n\" + \"\\n\".join(f\"{k}: {v}\" for k, v in unique_values.items()) + \"\\n\"\n",
    "    logger.info(log_message)\n",
    "\n",
    "    return unique_values\n",
    "\n",
    "\n",
    "def save_simulation_data(global_df, all_losses_dicts, all_epoch_num_lists, results, folder):\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Define paths for saving files\n",
    "    df_path = os.path.join(folder, 'simulation_data.pkl')\n",
    "    losses_path = os.path.join(folder, 'losses_dicts.pkl')\n",
    "    epochs_path = os.path.join(folder, 'epoch_num_lists.pkl')\n",
    "    results_path = os.path.join(folder, 'simulation_results.pkl')\n",
    "\n",
    "    # Save DataFrame\n",
    "    # global_df.to_csv(df_path, index=False)\n",
    "    with open(df_path, 'wb') as f:\n",
    "        pickle.dump(global_df, f)\n",
    "\n",
    "    # Save lists and dictionaries with pickle\n",
    "\n",
    "    with open(losses_path, 'wb') as f:\n",
    "        pickle.dump(all_losses_dicts, f)\n",
    "    with open(epochs_path, 'wb') as f:\n",
    "        pickle.dump(all_epoch_num_lists, f)\n",
    "    with open(results_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    logger.info(\"Data saved successfully in the folder: %s\", folder)\n",
    "\n",
    "\n",
    "def save_results_to_dataframe(results, folder):\n",
    "    data = {\n",
    "        \"Configuration\": [],\n",
    "        \"Accuracy_A1\": [],\n",
    "        \"Accuracy_A2\": [],\n",
    "        \"Behavioral Value fn.\": [],\n",
    "        \"Method's Value fn.\": [],\n",
    "        \"Optimal Value fn.\": []\n",
    "    }\n",
    "\n",
    "    for config_key, performance in results.items():\n",
    "        data[\"Configuration\"].append(config_key)\n",
    "        data[\"Accuracy_A1\"].append(performance.get(\"Accuracy_A1\", None))\n",
    "        data[\"Accuracy_A2\"].append(performance.get(\"Accuracy_A2\", None))\n",
    "        data[\"Behavioral Value fn.\"].append(performance.get(\"Behavioral Value fn.\", None))\n",
    "        data[\"Method's Value fn.\"].append(performance.get(\"Method's Value fn.\", None))\n",
    "        data[\"Optimal Value fn.\"].append(performance.get(\"Optimal Value fn.\", None))\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Sort the DataFrame by 'Method's Value fn.' in descending order\n",
    "    df = df.sort_values(by=\"Method's Value fn.\", ascending=False)\n",
    "\n",
    "    df.to_csv(f'{folder}/configurations_performance.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_and_process_data(params, folder):\n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Define paths to the files\n",
    "    df_path = os.path.join(folder, 'simulation_data.pkl')\n",
    "    losses_path = os.path.join(folder, 'losses_dicts.pkl')\n",
    "    epochs_path = os.path.join(folder, 'epoch_num_lists.pkl')\n",
    "    results_path = os.path.join(folder, 'simulation_results.pkl')\n",
    "\n",
    "    # Load DataFrame\n",
    "    # global_df = pd.read_csv(df_path)\n",
    "    with open(df_path, 'rb') as f:\n",
    "        global_df = pickle.load(f)\n",
    "\n",
    "    # Load lists and dictionaries with pickle\n",
    "    with open(losses_path, 'rb') as f:\n",
    "        all_losses_dicts = pickle.load(f)\n",
    "    with open(epochs_path, 'rb') as f:\n",
    "        all_epoch_num_lists = pickle.load(f)\n",
    "    with open(results_path, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    # Extract and process unique values\n",
    "    columns_to_process = {\n",
    "        'Predicted': ['Predicted_A1', 'Predicted_A2'],\n",
    "        'Optimal': ['Optimal_A1', 'Optimal_A2']\n",
    "    }\n",
    "    # unique_values = extract_unique_treatment_values(global_df, columns_to_process)\n",
    "\n",
    "    # Process and plot results from all simulations\n",
    "    for i, losses_dict in enumerate(all_losses_dicts):\n",
    "        run_name = f\"Simulation run trainVval_{i}\"\n",
    "        selected_indices = [i for i in range(params['num_replications'])]\n",
    "        if  params['f_model'] == 'surr_opt' :\n",
    "            plot_simulation_surLoss_losses_in_grid(selected_indices, losses_dict, params['n_epoch'], run_name, folder)\n",
    "        else:\n",
    "            plot_simulation_Qlearning_losses_in_grid(selected_indices, losses_dict, run_name, folder)\n",
    "\n",
    "    # Print results for each configuration\n",
    "    logger.info(\"\\n\\n\")\n",
    "    for config_key, performance in results.items():\n",
    "        logger.info(\"Configuration: %s\\nAverage Performance:\\n %s\\n\", config_key, performance.to_string(index=True, header=False))\n",
    "\n",
    "    # Call the function to plot value functions\n",
    "    df = save_results_to_dataframe(results, folder)\n",
    "    # plot_value_functions(results, folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iIfT8mrL-tS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii4ez6YnMK1j"
   },
   "source": [
    "## DGP utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPwTQd7KL-u5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. DGP utils\n",
    "\n",
    "def A_sim(matrix_pi, stage):\n",
    "    N, K = matrix_pi.shape  # sample size and treatment options\n",
    "    if N <= 1 or K <= 1:\n",
    "        logger.error(\"Sample size or treatment options are insufficient! N: %d, K: %d\", N, K)\n",
    "        raise ValueError(\"Sample size or treatment options are insufficient!\")\n",
    "    if torch.any(matrix_pi < 0):\n",
    "        logger.error(\"Treatment probabilities should not be negative!\")\n",
    "        raise ValueError(\"Treatment probabilities should not be negative!\")\n",
    "\n",
    "    # Normalize probabilities to add up to 1 and simulate treatment A for each row\n",
    "    pis = matrix_pi.sum(dim=1, keepdim=True)\n",
    "    probs = matrix_pi / pis\n",
    "    A = torch.multinomial(probs, 1).squeeze()\n",
    "\n",
    "    if stage == 1:\n",
    "        col_names = ['pi_10', 'pi_11', 'pi_12']\n",
    "    else:\n",
    "        col_names = ['pi_20', 'pi_21', 'pi_22']\n",
    "\n",
    "    probs_dict = {name: probs[:, idx] for idx, name in enumerate(col_names)}\n",
    "\n",
    "    return {'A': A, 'probs': probs_dict}\n",
    "\n",
    "def transform_Y(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Adjusts Y1 and Y2 values to ensure they are non-negative.\n",
    "    \"\"\"\n",
    "    # Identify the minimum value among Y1 and Y2, only if they are negative\n",
    "    min_negative_Y = torch.min(torch.cat([Y1, Y2])).item()\n",
    "    if min_negative_Y < 0:\n",
    "        Y1_trans = Y1 - min_negative_Y + 1\n",
    "        Y2_trans = Y2 - min_negative_Y + 1\n",
    "    else:\n",
    "        Y1_trans = Y1\n",
    "        Y2_trans = Y2\n",
    "\n",
    "    return Y1_trans, Y2_trans\n",
    "\n",
    "\n",
    "\n",
    "def M_propen(A, Xs, stage):\n",
    "    \"\"\"Estimate propensity scores using logistic or multinomial regression.\"\"\"\n",
    "    A = np.asarray(A).reshape(-1, 1)\n",
    "    if A.shape[1] != 1:\n",
    "        raise ValueError(\"Cannot handle multiple stages of treatments together!\")\n",
    "    if A.shape[0] != Xs.shape[0]:\n",
    "        print(\"A.shape, Xs.shape: \", A.shape, Xs.shape)\n",
    "        raise ValueError(\"A and Xs do not match in dimension!\")\n",
    "    if len(np.unique(A)) <= 1:\n",
    "        raise ValueError(\"Treatment options are insufficient!\")\n",
    "\n",
    "    # Handle multinomial case using Logistic Regression\n",
    "    encoder = OneHotEncoder(sparse_output=False)  # Updated parameter name\n",
    "    A_encoded = encoder.fit_transform(A)\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    # Suppressing warnings from the solver, if not converged\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "        model.fit(Xs, A.ravel())\n",
    "\n",
    "    # Predicting probabilities\n",
    "    s_p = model.predict_proba(Xs)\n",
    "\n",
    "    if stage == 1:\n",
    "        col_names = ['pi_10', 'pi_11', 'pi_12']\n",
    "    else:\n",
    "        col_names = ['pi_20', 'pi_21', 'pi_22']\n",
    "\n",
    "    #probs_df = pd.DataFrame(s_p, columns=col_names)\n",
    "    #probs_df = {name: s_p[:, idx] for idx, name in enumerate(col_names)}\n",
    "    probs_dict = {name: torch.tensor(s_p[:, idx], dtype=torch.float32) for idx, name in enumerate(col_names)}\n",
    "\n",
    "    return probs_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0xKAxL-L-xm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ssk_EAnMSBV"
   },
   "source": [
    "## Neural networks utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mefjw1wUL-za"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Neural networks utils\n",
    "\n",
    "\n",
    "def initialize_nn(params, stage):\n",
    "    nn = NNClass(\n",
    "        input_dim=params[f'input_dim_stage{stage}'],\n",
    "        hidden_dim=params[f'hidden_dim_stage{stage}'],\n",
    "        output_dim=params[f'output_dim_stage{stage}'],\n",
    "        num_networks=params['num_networks'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        activation_fn_name=params['activation_function'],\n",
    "        num_hidden_layers=params['num_layers'] - 1  # num_layers is the number of hidden layers\n",
    "    ).to(params['device'])\n",
    "    return nn\n",
    "\n",
    "\n",
    "\n",
    "def batches(N, batch_size, seed=0):\n",
    "    # Set the seed for PyTorch random number generator for reproducibility\n",
    "    # torch.manual_seed(seed)\n",
    "\n",
    "    # Create a tensor of indices from 0 to N-1\n",
    "    indices = torch.arange(N)\n",
    "\n",
    "    # Shuffle the indices\n",
    "    indices = indices[torch.randperm(N)]\n",
    "\n",
    "    # Yield batches of indices\n",
    "    for start_idx in range(0, N, batch_size):\n",
    "        batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "        yield batch_indices\n",
    "\n",
    "\n",
    "class NNClass(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate, activation_fn_name, num_hidden_layers):\n",
    "        super(NNClass, self).__init__()\n",
    "        self.networks = nn.ModuleList()\n",
    "\n",
    "        # Map the string name to the actual activation function class\n",
    "        if activation_fn_name.lower() == 'elu':\n",
    "            activation_fn = nn.ELU\n",
    "        elif activation_fn_name.lower() == 'relu':\n",
    "            activation_fn = nn.ReLU\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation_fn_name}\")\n",
    "\n",
    "        for _ in range(num_networks):\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(activation_fn())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            for _ in range(num_hidden_layers):  # Adjusting the hidden layers count\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(activation_fn())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            layers.append(nn.BatchNorm1d(output_dim))\n",
    "\n",
    "            network = nn.Sequential(*layers)\n",
    "            self.networks.append(network)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for network in self.networks:\n",
    "            outputs.append(network(x))\n",
    "        return outputs\n",
    "\n",
    "    def he_initializer(self):\n",
    "        for network in self.networks:\n",
    "            for layer in network:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                    nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "    def reset_weights(self):\n",
    "        for network in self.networks:\n",
    "            for layer in network:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.constant_(layer.weight, 0.1)\n",
    "                    nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate, activation_fn_name):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "\n",
    "#         # Map the string name to the actual activation function class\n",
    "#         if activation_fn_name.lower() == 'elu':\n",
    "#             activation_fn = nn.ELU\n",
    "#         elif activation_fn_name.lower() == 'relu':\n",
    "#             activation_fn = nn.ReLU\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported activation function: {activation_fn_name}\")\n",
    "\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 activation_fn(),  # Instantiate the activation function\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.ELU(alpha=0.4),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.BatchNorm1d(hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "# class NNClass(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_networks, dropout_rate):\n",
    "#         super(NNClass, self).__init__()\n",
    "#         self.networks = nn.ModuleList()\n",
    "#         for _ in range(num_networks):\n",
    "#             network = nn.Sequential(\n",
    "#                 nn.Linear(input_dim, hidden_dim),\n",
    "#                 nn.BatchNorm1d(hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(hidden_dim, hidden_dim),\n",
    "#                 nn.Dropout(dropout_rate),\n",
    "#                 nn.Linear(hidden_dim, hidden_dim),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(hidden_dim, output_dim),\n",
    "#                 nn.BatchNorm1d(output_dim),\n",
    "#             )\n",
    "#             self.networks.append(network)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for network in self.networks:\n",
    "#             outputs.append(network(x))\n",
    "#         return outputs\n",
    "\n",
    "#     def he_initializer(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                     nn.init.constant_(layer.bias, 0)  # Biases can be initialized to zero\n",
    "\n",
    "#     def reset_weights(self):\n",
    "#         for network in self.networks:\n",
    "#             for layer in network:\n",
    "#                 if isinstance(layer, nn.Linear):\n",
    "#                     nn.init.constant_(layer.weight, 0.1)\n",
    "#                     nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40MxSRTCMX73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3dooXKtMZWN"
   },
   "source": [
    "## plotting and summary utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8VHkvqTvMX-3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. plotting and summary utils\n",
    "\n",
    "\n",
    "def plot_v_values(v_dict, num_replications, train_size):\n",
    "\n",
    "    # Plotting all categories of V values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for category, values in v_dict.items():\n",
    "        plt.plot(range(1, num_replications + 1), values, 'o-', label=f'{category} Value function')\n",
    "    plt.xlabel('Replications (Total: {})'.format(num_replications))\n",
    "    plt.ylabel('Value function')\n",
    "    plt.title('Value functions for {} Test Replications (Training Size: {})'.format(num_replications, train_size))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def abbreviate_config(config):\n",
    "    abbreviations = {\n",
    "        \"activation_function\": \"AF\",\n",
    "        \"batch_size\": \"BS\",\n",
    "        \"learning_rate\": \"LR\",\n",
    "        \"num_layers\": \"NL\"\n",
    "    }\n",
    "    abbreviated_config = {abbreviations[k]: v for k, v in config.items()}\n",
    "    return str(abbreviated_config)\n",
    "\n",
    "def plot_value_functions(results, folder):\n",
    "    data = {\n",
    "        \"Configuration\": [],\n",
    "        \"Value Function\": []\n",
    "    }\n",
    "\n",
    "    for config_key, performance in results.items():\n",
    "        config_dict = json.loads(config_key)\n",
    "        abbreviated_config = abbreviate_config(config_dict)\n",
    "        data[\"Configuration\"].append(abbreviated_config)\n",
    "        data[\"Value Function\"].append(performance[\"Method's Value fn.\"])\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Sort the DataFrame by 'Value Function' in descending order\n",
    "    df = df.sort_values(by=\"Value Function\", ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df[\"Configuration\"], df[\"Value Function\"], color='skyblue')\n",
    "    plt.xlabel(\"Value Function\")\n",
    "    plt.title(\"Value Function of Each Method\")\n",
    "    plt.yticks(rotation=0)  # Rotate configuration labels to vertical\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f'{folder}/value_function_plot.png')\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "def plot_epoch_frequency(epoch_num_model_lst, n_epoch, run_name, folder='data'):\n",
    "    \"\"\"\n",
    "    Plots a bar diagram showing the frequency of each epoch number where the model was saved.\n",
    "\n",
    "    Args:\n",
    "        epoch_num_model_lst (list of int): List containing the epoch numbers where models were saved.\n",
    "        n_epoch (int): Total number of epochs for reference in the title.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each number in the list\n",
    "    frequency_counts = Counter(epoch_num_model_lst)\n",
    "\n",
    "    # Separate the keys and values for plotting\n",
    "    keys = sorted(frequency_counts.keys())\n",
    "    values = [frequency_counts[key] for key in keys]\n",
    "\n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(keys, values, color='skyblue')\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'Bar Diagram of Epoch Numbers: n_epoch={n_epoch}')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"plot_epoch_frequency Plot saved as: {plot_filename}\")\n",
    "    # plt.close()  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "\n",
    "def plot_simulation_surLoss_losses_in_grid(selected_indices, losses_dict, n_epoch, run_name, folder, cols=3):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Calculate the number of rows needed based on the number of selected indices and desired number of columns\n",
    "    rows = len(selected_indices) // cols + (len(selected_indices) % cols > 0)\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))  # Adjust figure size as needed\n",
    "    fig.suptitle(f'Training and Validation Loss for Selected Simulations @ n_epoch = {n_epoch}')\n",
    "\n",
    "    # Flatten the axes array for easy indexing, in case of a single row or column\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        train_loss, val_loss = losses_dict[idx]\n",
    "\n",
    "        # Plot on the ith subplot\n",
    "        axes[i].plot(train_loss, label='Training')\n",
    "        axes[i].plot(val_loss, label='Validation')\n",
    "        axes[i].set_title(f'Simulation {idx}')\n",
    "        axes[i].set_xlabel('Epochs')\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the layout to make room for the subtitle\n",
    "    plt.show()\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"TrainVval Plot saved as: {plot_filename}\")\n",
    "    # plt.close(fig)  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "def plot_simulation_Qlearning_losses_in_grid(selected_indices, losses_dict, run_name, folder, cols=3):\n",
    "\n",
    "    all_losses = {\n",
    "        'train_losses_stage1': {},\n",
    "        'train_losses_stage2': {},\n",
    "        'val_losses_stage1': {},\n",
    "        'val_losses_stage2': {}\n",
    "    }\n",
    "\n",
    "    # Iterate over each simulation and extract losses\n",
    "    for simulation, losses in losses_dict.items():\n",
    "        train_losses_stage1, train_losses_stage2, val_losses_stage1, val_losses_stage2 = losses\n",
    "\n",
    "        all_losses['train_losses_stage1'][simulation] = train_losses_stage1\n",
    "        all_losses['train_losses_stage2'][simulation] = train_losses_stage2\n",
    "        all_losses['val_losses_stage1'][simulation] = val_losses_stage1\n",
    "        all_losses['val_losses_stage2'][simulation] = val_losses_stage2\n",
    "\n",
    "\n",
    "    rows = len(selected_indices) // cols + (len(selected_indices) % cols > 0)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    fig.suptitle('Training and Validation Loss for Selected Simulations')\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        # Check if the replication index exists in the losses for each type\n",
    "        if idx in all_losses['train_losses_stage1']:\n",
    "            axes[i].plot(all_losses['train_losses_stage1'][idx], label='Training Stage 1', linestyle='--')\n",
    "            axes[i].plot(all_losses['val_losses_stage1'][idx], label='Validation Stage 1', linestyle='-.')\n",
    "            axes[i].plot(all_losses['train_losses_stage2'][idx], label='Training Stage 2', linestyle='--')\n",
    "            axes[i].plot(all_losses['val_losses_stage2'][idx], label='Validation Stage 2', linestyle='-.')\n",
    "            axes[i].set_title(f'Simulation {idx}')\n",
    "            axes[i].set_xlabel('Epochs')\n",
    "            axes[i].set_ylabel('Loss')\n",
    "            axes[i].legend()\n",
    "        else:\n",
    "            axes[i].set_title(f'Simulation {idx} - Data not available')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # # Save the plot\n",
    "    # plot_filename = os.path.join(folder, f\"{run_name}.png\")\n",
    "    # plt.savefig(plot_filename)\n",
    "    # print(f\"TrainVval Plot Deep Q Learning saved as: {plot_filename}\")\n",
    "    # plt.close(fig)  # Close the plot to free up memory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracies(df, V_replications):\n",
    "    \"\"\"\n",
    "    Calculates and returns accuracies for behavioral and predicted actions against optimal actions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns for Behavioral, Predicted, and Optimal actions.\n",
    "        V_replications (dict): Dictionary containing lists of value functions for further analysis.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing calculated accuracies and value functions.\n",
    "    \"\"\"\n",
    "    correct_behavioral = {'A1': 0, 'A2': 0}\n",
    "    correct_predicted = {'A1': 0, 'A2': 0}\n",
    "    total = {'A1': 0, 'A2': 0}\n",
    "    accuracies = {'Accuracy_A1': [], 'Accuracy_A2': []}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Unpack the row for clearer access\n",
    "        behavioral_A1, behavioral_A2 = row['Behavioral_A1'], row['Behavioral_A2']\n",
    "        predicted_A1, predicted_A2 = row['Predicted_A1'], row['Predicted_A2']\n",
    "        optimal_A1, optimal_A2 = row['Optimal_A1'], row['Optimal_A2']\n",
    "\n",
    "        # Calculate accuracy for each action type and axis\n",
    "        row_corrects = {\n",
    "            'behavioral_A1': sum(a == p for a, p in zip(behavioral_A1, optimal_A1)),\n",
    "            'behavioral_A2': sum(a == p for a, p in zip(behavioral_A2, optimal_A2)),\n",
    "            'predicted_A1': sum(o == p for o, p in zip(optimal_A1, predicted_A1)),\n",
    "            'predicted_A2': sum(o == p for o, p in zip(optimal_A2, predicted_A2)),\n",
    "        }\n",
    "\n",
    "        # Append per-simulation accuracies\n",
    "        accuracies['Accuracy_A1'].append(row_corrects['predicted_A1'] / len(predicted_A1))\n",
    "        accuracies['Accuracy_A2'].append(row_corrects['predicted_A2'] / len(predicted_A2))\n",
    "\n",
    "        # Update running totals for overall accuracy\n",
    "        correct_behavioral['A1'] += row_corrects['behavioral_A1']\n",
    "        correct_behavioral['A2'] += row_corrects['behavioral_A2']\n",
    "        correct_predicted['A1'] += row_corrects['predicted_A1']\n",
    "        correct_predicted['A2'] += row_corrects['predicted_A2']\n",
    "        total['A1'] += len(predicted_A1)\n",
    "        total['A2'] += len(predicted_A2)\n",
    "\n",
    "    # Create DataFrame for accuracies\n",
    "    accuracy_df = pd.DataFrame(accuracies)\n",
    "    accuracy_df[\"Value function\"] = V_replications[\"V_replications_M1_pred\"]\n",
    "    accuracy_df[\"Optimal Value function\"] = V_replications[\"V_replications_M1_optimal\"]\n",
    "\n",
    "    # Calculate and print overall accuracies\n",
    "    overall_accuracy_behavioral = {key: correct_behavioral[key] / total[key] for key in correct_behavioral}\n",
    "    overall_accuracy_predicted = {key: correct_predicted[key] / total[key] for key in correct_predicted}\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Overall Accuracy for Behavioral A1:\", overall_accuracy_behavioral['A1'])\n",
    "    print(\"Overall Accuracy for Behavioral A2:\", overall_accuracy_behavioral['A2'])\n",
    "    print(\"\\n\")\n",
    "    print(\"Overall Accuracy for Predicted A1:\", overall_accuracy_predicted['A1'])\n",
    "    print(\"Overall Accuracy for Predicted A2:\", overall_accuracy_predicted['A2'])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return accuracy_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-Flsln-MYBu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoeb5gn2MpYU"
   },
   "source": [
    "## Loss function and surrogate opt utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j8a_VpnbMYG3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Loss function and surrogate opt utils\n",
    "\n",
    "def compute_phi(x, option):\n",
    "    if option == 1:\n",
    "        return 1 + torch.tanh(5*x)\n",
    "    elif option == 2:\n",
    "        return 1 + 2 * torch.atan(torch.pi * x / 2) / torch.pi\n",
    "    elif option == 3:\n",
    "        return 1 + x / torch.sqrt(1 + x ** 2)\n",
    "    elif option == 4:\n",
    "        return 1 + x / (1 + torch.abs(x))\n",
    "    elif option == 5:\n",
    "        return torch.where(x >= 0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "    else:\n",
    "        logger.error(\"Invalid phi option: %s\", option)\n",
    "        raise ValueError(\"Invalid phi option\")\n",
    "\n",
    "\n",
    "def gamma_function_old_vec(a, b, A, option):\n",
    "    a = a.to(device)\n",
    "    b = b.to(device)\n",
    "\n",
    "    phi_a = compute_phi(a, option)\n",
    "    phi_b = compute_phi(b, option)\n",
    "    phi_b_minus_a = compute_phi(b - a, option)\n",
    "    phi_a_minus_b = compute_phi(a - b, option)\n",
    "    phi_neg_a = compute_phi(-a, option)\n",
    "    phi_neg_b = compute_phi(-b, option)\n",
    "\n",
    "    gamma = torch.where(A == 1, phi_a * phi_b,\n",
    "                        torch.where(A == 2, phi_b_minus_a * phi_neg_a,\n",
    "                                    torch.where(A == 3, phi_a_minus_b * phi_neg_b,\n",
    "                                                torch.tensor(0.0).to(device))))\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def compute_gamma(a, b, option):\n",
    "    # Assume a and b are already tensors, check if they need to be sent to a specific device and ensure they have gradients if required\n",
    "    a = a.detach().requires_grad_(True)\n",
    "    b = b.detach().requires_grad_(True)\n",
    "\n",
    "    # asymmetric\n",
    "    if option == 1:\n",
    "        result = ((torch.exp(a + b) - 1) / ((1 + torch.exp(a)) * (1 + torch.exp(b))) ) +  ( 1 / (1 + torch.exp(a) + torch.exp(b)))\n",
    "    # symmetric\n",
    "    elif option == 2:\n",
    "        result = (torch.exp(a + b) * ((a * (torch.exp(b) - 1))**2 + (torch.exp(a) - 1) * (-torch.exp(a) + (torch.exp(b) - 1) * (torch.exp(a) - torch.exp(b) + b)))) / ((torch.exp(a) - 1)**2 * (torch.exp(b) - 1)**2 * (torch.exp(a) - torch.exp(b)))\n",
    "    else:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "\n",
    "def gamma_function_new_vec(a, b, A, option):\n",
    "    # a, b, and A are torch tensors and move them to the specified device\n",
    "    a = torch.tensor(a, dtype=torch.float32, requires_grad=True).to(device)\n",
    "    b = torch.tensor(b, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "    # a = torch.tensor(a, dtype=torch.float32).to(device)\n",
    "    # b = torch.tensor(b, dtype=torch.float32).to(device)\n",
    "    A = torch.tensor(A, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Apply compute_gamma_vectorized across the entire tensors based on A\n",
    "    result_1 = compute_gamma(a, b, option)\n",
    "    result_2 = compute_gamma(b - a, -a, option)\n",
    "    result_3 = compute_gamma(a - b, -b, option)\n",
    "\n",
    "    gamma = torch.where(A == 1, result_1,\n",
    "                        torch.where(A == 2, result_2,\n",
    "                                    torch.where(A == 3, result_3,\n",
    "                                                torch.tensor(0.0).to(device) )))\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def main_loss_gamma(stage1_outputs, stage2_outputs, A1, A2, Ci, option, surrogate_num):\n",
    "\n",
    "    if surrogate_num == 1:\n",
    "        # # surrogate 1\n",
    "        gamma_stage1 = gamma_function_old_vec(stage1_outputs[:, 0], stage1_outputs[:, 1], A1.int(), option)\n",
    "        gamma_stage2 = gamma_function_old_vec(stage2_outputs[:, 0], stage2_outputs[:, 1], A2.int(), option)\n",
    "    else:\n",
    "        # surrogate 2 - contains symmetric and non symmetic cases\n",
    "        gamma_stage1 = gamma_function_new_vec(stage1_outputs[:, 0], stage1_outputs[:, 1], A1.int(), option)\n",
    "        gamma_stage2 = gamma_function_new_vec(stage2_outputs[:, 0], stage2_outputs[:, 1], A2.int(), option)\n",
    "\n",
    "    loss = -torch.mean(Ci * gamma_stage1 * gamma_stage2)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_batches(model1, model2, data, params, optimizer, is_train=True):\n",
    "    batch_size = params['batch_size']\n",
    "    total_loss = 0\n",
    "    num_batches = (data['input1'].shape[0] + batch_size - 1) // batch_size\n",
    "\n",
    "    if is_train:\n",
    "        model1.train()\n",
    "        model2.train()\n",
    "    else:\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "\n",
    "    for batch_idx in batches(data['input1'].shape[0], batch_size):\n",
    "        batch_data = {k: v[batch_idx].to(params['device']) for k, v in data.items()}\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            outputs_stage1 = model1(batch_data['input1'])\n",
    "            outputs_stage2 = model2(batch_data['input2'])\n",
    "\n",
    "            outputs_stage1 = torch.stack(outputs_stage1, dim=1).squeeze()\n",
    "            outputs_stage2 = torch.stack(outputs_stage2, dim=1).squeeze()\n",
    "\n",
    "            loss = main_loss_gamma(outputs_stage1, outputs_stage2, batch_data['A1'], batch_data['A2'],\n",
    "                                   batch_data['Ci'], option=params['option_sur'], surrogate_num=params['surrogate_num'])\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def initialize_and_prepare_model(stage, params, sample_size):\n",
    "    model = initialize_nn(params, stage).to(params['device'])\n",
    "\n",
    "    # Check for the initializer type in params and apply accordingly\n",
    "    if params['initializer'] == 'he':\n",
    "        model.he_initializer()  # He initialization (aka Kaiming initialization)\n",
    "    else:\n",
    "        model.reset_weights()  # Custom reset weights to a specific constant eg. 0.1\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_optimizer_and_scheduler(nn_stage1, nn_stage2, params):\n",
    "    # Combine parameters from both models\n",
    "    combined_params = list(nn_stage1.parameters()) + list(nn_stage2.parameters())\n",
    "\n",
    "    # Select optimizer based on params\n",
    "    if params['optimizer_type'] == 'adam':\n",
    "        optimizer = optim.Adam(combined_params, lr=params['optimizer_lr'])\n",
    "    elif params['optimizer_type'] == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(combined_params, lr=params['optimizer_lr'], weight_decay=params['optimizer_weight_decay'])\n",
    "    else:\n",
    "        logging.warning(\"No valid optimizer type found in params['optimizer_type'], defaulting to Adam.\")\n",
    "        optimizer = optim.Adam(combined_params, lr=params['optimizer_lr'])  # Default to Adam if none specified\n",
    "\n",
    "    # Initialize scheduler only if use_scheduler is True\n",
    "    scheduler = None\n",
    "    if params.get('use_scheduler', False):  # Defaults to False if 'use_scheduler' is not in params\n",
    "        if params['scheduler_type'] == 'reducelronplateau':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.01, patience=10)\n",
    "        elif params['scheduler_type'] == 'steplr':\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])\n",
    "        elif params['scheduler_type'] == 'cosineannealing':\n",
    "            T_max = (params['sample_size'] // params['batch_size']) * params['n_epoch']\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=0.0001)\n",
    "        else:\n",
    "            logging.warning(\"No valid scheduler type found in params['scheduler_type'], defaulting to StepLR.\")\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])  # Default to StepLR if none specified\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def update_scheduler(scheduler, params, val_loss=None):\n",
    "\n",
    "    if scheduler is None:\n",
    "        logging.warning(\"Scheduler is not initialized but update_scheduler was called.\")\n",
    "        return\n",
    "\n",
    "    # Check the type of scheduler and step accordingly\n",
    "    if params['scheduler_type'] == 'reducelronplateau':\n",
    "        # ReduceLROnPlateau expects a metric, usually the validation loss, to step\n",
    "        if val_loss is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            logging.warning(\"Validation loss required for ReduceLROnPlateau but not provided.\")\n",
    "    else:\n",
    "        # Other schedulers like StepLR or CosineAnnealingLR do not use the validation loss\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om1LW_ABMv35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYnglpGTMxo7"
   },
   "source": [
    "## Q learning utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dTBe-2xmMv6x"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Q learning utils\n",
    "\n",
    "def train_and_validate(model, optimizer, scheduler, train_inputs, train_actions, train_targets, val_inputs, val_actions, val_targets, params, stage_number):\n",
    "\n",
    "    batch_size, device, n_epoch, sample_size = params['batch_size'], params['device'], params['n_epoch'], params['sample_size']\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    epoch_num_model = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx in batches(train_inputs.shape[0], batch_size, epoch):\n",
    "            batch_idx = batch_idx.to(device)\n",
    "            inputs_batch = torch.index_select(train_inputs, 0, batch_idx).to(device)\n",
    "            actions_batch = torch.index_select(train_actions, 0, batch_idx).to(device)\n",
    "            targets_batch = torch.index_select(train_targets, 0, batch_idx).to(device)\n",
    "            combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_inputs)\n",
    "            loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        num_batches_t = (train_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_train_loss = total_train_loss / num_batches_t\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in batches(val_inputs.shape[0], batch_size):\n",
    "                batch_idx = batch_idx.to(device)\n",
    "                inputs_batch = torch.index_select(val_inputs, 0, batch_idx).to(device)\n",
    "                actions_batch = torch.index_select(val_actions, 0, batch_idx).to(device)\n",
    "                targets_batch = torch.index_select(val_targets, 0, batch_idx).to(device)\n",
    "                combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "                outputs = model(combined_inputs)\n",
    "                loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        num_batches_v = (val_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_val_loss = total_val_loss / num_batches_v\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss and epoch > 20:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "\n",
    "        # scheduler.step()\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Save the best model parameters after all epochs\n",
    "    if best_model_params is not None:\n",
    "        model_path = os.path.join(model_dir, f'best_model_stage_Q_{stage_number}_{sample_size}.pt')\n",
    "        torch.save(best_model_params, model_path)\n",
    "\n",
    "    return train_losses, val_losses, epoch_num_model\n",
    "\n",
    "\n",
    "def initialize_model_and_optimizer(params, stage):\n",
    "    nn = initialize_nn(params, stage).to(device)\n",
    "    optimizer = optim.Adam(nn.parameters(), lr=params['optimizer_lr'])\n",
    "    # optimizer = optim.Adam(nn.parameters(), lr=params['optimizer_lr'], betas=params['optimizer_betas'], eps=params['optimizer_eps'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=params['scheduler_step_size'], gamma=params['scheduler_gamma'])\n",
    "    return nn, optimizer, scheduler\n",
    "\n",
    "def evaluate_model_on_actions(model, inputs, action_t):\n",
    "    actions_list = [1, 2, 3]\n",
    "    outputs_list = []\n",
    "    for action_value in actions_list:\n",
    "        action_tensor = torch.full_like(action_t, action_value).unsqueeze(-1)\n",
    "        combined_inputs = torch.cat((inputs, action_tensor), dim=1).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(combined_inputs)\n",
    "        outputs_list.append(outputs[0])\n",
    "\n",
    "    max_outputs, _ = torch.max(torch.cat(outputs_list, dim=1), dim=1)\n",
    "    return max_outputs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_FBP0pRMv83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eN-4SDiM6Ju"
   },
   "source": [
    "## Eval fn utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z8owLGgRMv_q"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5. Eval fn utils\n",
    "\n",
    "def compute_test_outputs(nn, test_input, A_tensor, params, is_stage1=True):\n",
    "    with torch.no_grad():\n",
    "        if params['f_model'] == \"surr_opt\":\n",
    "            # Perform the forward pass\n",
    "            test_outputs_i = nn(test_input)\n",
    "\n",
    "            # Directly stack the required outputs and perform computations in a single step\n",
    "            test_outputs = torch.stack(test_outputs_i[:2], dim=1).squeeze()\n",
    "\n",
    "            # Compute treatment assignments directly without intermediate variables\n",
    "            test_outputs = torch.stack([\n",
    "                torch.zeros_like(test_outputs[:, 0]),\n",
    "                -test_outputs[:, 0],\n",
    "                -test_outputs[:, 1]\n",
    "            ], dim=1)\n",
    "        else:\n",
    "            # Modify input for each action and perform a forward pass\n",
    "            input_tests = [\n",
    "                torch.cat((test_input, torch.full_like(A_tensor, i).unsqueeze(-1)), dim=1).to(params['device'])\n",
    "                for i in range(1, 4)  # Assuming there are 3 actions\n",
    "            ]\n",
    "\n",
    "            # Forward pass for each modified input and stack the results\n",
    "            test_outputs = torch.stack([\n",
    "                nn(input_stage)[0] for input_stage in input_tests\n",
    "            ], dim=1)\n",
    "\n",
    "    # Determine the optimal action based on the computed outputs\n",
    "    optimal_actions = torch.argmax(test_outputs, dim=1) + 1\n",
    "    return optimal_actions.squeeze().to(params['device']), test_outputs\n",
    "\n",
    "def prepare_stage2_test_input(O1_tensor_test, A1, g1_opt_conditions, Z1_tensor_test):\n",
    "\n",
    "    # g1_opt_conditions gives the optimal action, we use it to compute Y1_pred\n",
    "    Y1_pred = torch.exp(1.5 - torch.abs(1.5 * O1_tensor_test[:, 0] + 2) * (A1 - g1_opt_conditions)**2) + Z1_tensor_test\n",
    "\n",
    "    # Form the test input for stage 2 by concatenating the necessary tensors\n",
    "    test_input_stage2 = torch.cat([O1_tensor_test, A1.unsqueeze(1), Y1_pred.unsqueeze(1)], dim=1)\n",
    "\n",
    "    # # DEBUG PRINT\n",
    "    # Y1_stats = [torch.min(Y1_pred), torch.max(Y1_pred), torch.mean(Y1_pred)]\n",
    "    # stats_message = f\"Y1_pred [min, max, mean]: {Y1_stats}\"\n",
    "    # tqdm.write(stats_message)\n",
    "\n",
    "    return test_input_stage2, Y1_pred\n",
    "\n",
    "\n",
    "\n",
    "def prepare_Y2_pred(O1_tensor_test, A1, A2, g2_opt_conditions, Z1_tensor_test, Z2_tensor_test):\n",
    "\n",
    "    # g2_opt_conditions gives the optimal action, we use it to compute Y2_pred\n",
    "    Y2_pred = torch.exp(1.26 - torch.abs(1.5 * O1_tensor_test[:, 2] - 2) * (A2 - g2_opt_conditions)**2) + Z2_tensor_test\n",
    "\n",
    "    # # DEBUG PRINT\n",
    "    # stats_message = f\"Y2_pred [min, max, mean]: [{torch.min(Y2_pred)}, {torch.max(Y2_pred)}, {torch.mean(Y2_pred)}]\"\n",
    "    # tqdm.write(stats_message)\n",
    "\n",
    "    return Y2_pred\n",
    "\n",
    "\n",
    "\n",
    "def calculate_policy_values(Y1_tensor, Y2_tensor, d1_star, d2_star, Y1_pred, Y2_pred, V_replications, Z1_tensor_test, Z2_tensor_test):\n",
    "    # Rewards using Optimal policy\n",
    "    Y1_test_opt = torch.exp(torch.tensor(1.5)) + Z1_tensor_test\n",
    "    Y2_test_opt = torch.exp(torch.tensor(1.26)) + Z2_tensor_test\n",
    "\n",
    "    # DEBUG PRINT\n",
    "    message = f'\\nY1_opt mean: {torch.mean(Y1_test_opt)}, Y2_opt mean: {torch.mean(Y2_test_opt)}, Y1_opt+Y2_opt mean: {torch.mean(Y1_test_opt + Y2_test_opt)} \\n\\n'\n",
    "    print(message)\n",
    "\n",
    "    V_d1_d2_opt = torch.mean(Y1_test_opt + Y2_test_opt).cpu().item()  # Calculate the mean value and convert to Python scalar\n",
    "    V_replications[\"V_replications_M1_optimal\"].append(V_d1_d2_opt)  # Append to the list for optimal policy values\n",
    "\n",
    "    # Value function using Behavioral policy\n",
    "    V_d1_d2 = torch.mean(Y1_tensor + Y2_tensor).cpu().item()  # Calculate the mean value and convert to Python scalar\n",
    "    V_replications[\"V_replications_M1_behavioral\"].append(V_d1_d2)  # Append to the list for behavioral policy values\n",
    "\n",
    "    # Value function using Current method's policy\n",
    "    V_replications[\"V_replications_M1_pred\"].append(torch.mean(Y1_pred + Y2_pred).item())  # Append the mean value as a Python scalar to the list for current approach values\n",
    "\n",
    "    return V_replications\n",
    "\n",
    "\n",
    "\n",
    "def initialize_and_load_model(stage, sample_size, params):\n",
    "    # Initialize the neural network model\n",
    "    nn_model = initialize_nn(params, stage).to(params['device'])\n",
    "\n",
    "    # Define the directory and file name for the model\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    if params['f_model']==\"surr_opt\":\n",
    "        model_filename = f'best_model_stage_surr_{stage}_{sample_size}.pt'\n",
    "    else:\n",
    "        model_filename = f'best_model_stage_Q_{stage}_{sample_size}.pt'\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Check if the model file exists before attempting to load\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.error(f\"No model file found at {model_path}. Please check the file path and model directory.\")\n",
    "        return None  # or handle the error as needed\n",
    "\n",
    "    # Load the model's state dictionary from the file\n",
    "    nn_model.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    nn_model.eval()\n",
    "\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJsdAveRTEQo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McO1KPvjTETr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk2LJR_VTEeO"
   },
   "source": [
    "# Value function Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-Mxk4pNdM-KN"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_and_validate_W_estimator(model, optimizer, scheduler, train_inputs, train_actions, train_targets, val_inputs, val_actions, val_targets, batch_size, device, n_epoch, stage_number, sample_size, params):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params = None\n",
    "    epoch_num_model = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx in batches(train_inputs.shape[0], batch_size, epoch):\n",
    "            batch_idx = batch_idx.to(device)\n",
    "            inputs_batch = torch.index_select(train_inputs, 0, batch_idx).to(device)\n",
    "            actions_batch = torch.index_select(train_actions, 0, batch_idx).to(device)\n",
    "            targets_batch = torch.index_select(train_targets, 0, batch_idx).to(device)\n",
    "            combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_inputs)\n",
    "\n",
    "\n",
    "            loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        num_batches_t = (train_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_train_loss = total_train_loss / num_batches_t\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in batches(val_inputs.shape[0], batch_size):\n",
    "                batch_idx = batch_idx.to(device)\n",
    "                inputs_batch = torch.index_select(val_inputs, 0, batch_idx).to(device)\n",
    "                actions_batch = torch.index_select(val_actions, 0, batch_idx).to(device)\n",
    "                targets_batch = torch.index_select(val_targets, 0, batch_idx).to(device)\n",
    "                combined_inputs = torch.cat((inputs_batch, actions_batch.unsqueeze(-1)), dim=1)\n",
    "\n",
    "\n",
    "                outputs = model(combined_inputs)\n",
    "\n",
    "\n",
    "\n",
    "                loss = F.mse_loss(torch.cat(outputs, dim=0).view(-1), targets_batch)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        num_batches_v = (val_inputs.shape[0] + batch_size - 1) // batch_size\n",
    "        avg_val_loss = total_val_loss / num_batches_v\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss and epoch > 20:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Save the best model parameters after all epochs\n",
    "    if best_model_params is not None:\n",
    "        model_path = os.path.join(model_dir, f\"best_model_stage_Q_{stage_number}_{sample_size}_W_estimator_{params['f_model']}.pt\")\n",
    "        torch.save(best_model_params, model_path)\n",
    "\n",
    "\n",
    "    return train_losses, val_losses, epoch_num_model\n",
    "\n",
    "\n",
    "\n",
    "def valFn_estimate(Qhat1_H1d1, Qhat2_H2d2, Qhat1_H1A1, Qhat2_H2A2, A1_tensor, A2_tensor, A1, A2, Y1_tensor, Y2_tensor , P_A1_given_H1_tensor, P_A2_given_H2_tensor):\n",
    "\n",
    "    # # IPW estimator\n",
    "    # indicator1 = ((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # indicator2 = ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # term = (Y1_tensor + Y2_tensor) * indicator1 * indicator2\n",
    "    # return torch.mean(term).item()\n",
    "\n",
    "    # # term I got\n",
    "    # term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1)) *((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # term_2 = (Y2_tensor - Qhat2_H2A2.squeeze(1) ) * ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # return torch.mean(Qhat1_H1d1.squeeze(1)  + term_1 + term_2 + Qhat2_H2d2.squeeze(1)).item()\n",
    "\n",
    "    # # 1st term on board (incorrect)\n",
    "    # term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1) + Qhat2_H2d2.squeeze(1) ) *((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    # term_2 = (Y2_tensor- Qhat2_H2A2.squeeze(1) ) * ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    # return torch.mean(Qhat1_H1d1.squeeze(1)  + term_1 + term_2).item()\n",
    "\n",
    "    # corrected term in email\n",
    "    indicator1 = ((A1_tensor == A1)/P_A1_given_H1_tensor)\n",
    "    indicator2 = ((A2_tensor == A2)/P_A2_given_H2_tensor)\n",
    "    term_1 = (Y1_tensor - Qhat1_H1A1.squeeze(1) + Qhat2_H2d2.squeeze(1) ) * indicator1\n",
    "    term_2 = (Y2_tensor - Qhat2_H2A2.squeeze(1) ) * indicator1 * indicator2\n",
    "    return torch.mean(Qhat1_H1d1.squeeze(1) ).item() + torch.mean(term_1 + term_2).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_and_train_stage(stage, input_tensor, action_tensor, outcome_tensor, val_input_tensor, val_action_tensor, val_outcome_tensor, params):\n",
    "\n",
    "    sample_size = params['sample_size']\n",
    "\n",
    "    \"\"\"Initialize, train and validate a model for a given stage.\"\"\"\n",
    "    model, optimizer, scheduler = initialize_model_and_optimizer(params, stage)\n",
    "    losses, val_losses, epoch_num = train_and_validate_W_estimator(\n",
    "        model, optimizer, scheduler, input_tensor, action_tensor, outcome_tensor, val_input_tensor, val_action_tensor, val_outcome_tensor,\n",
    "        params['batch_size'], params['device'], params['n_epoch'], stage, sample_size, params\n",
    "    )\n",
    "\n",
    "    # Define the directory and file name for the model\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{stage}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    # Check if the model file exists before attempting to load\n",
    "    if not os.path.exists(model_path):\n",
    "        logger.error(f\"No model file found at {model_path}. Please check the file path and model directory.\")\n",
    "        return None  # or handle the error as needed\n",
    "\n",
    "    # Load the model's state dictionary from the file\n",
    "    model.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def calculate_policy_values_W_estimator(train_tens, params, A1, A2, P_A1_given_H1_tensor, P_A2_given_H2_tensor):\n",
    "\n",
    "\n",
    "    train_size = int(params['training_validation_prop'] * params['sample_size'])\n",
    "    train_test_tensors = [tensor[:train_size] for tensor in train_tens ]\n",
    "    val_test_tensors = [tensor[train_size:] for tensor in train_tens]\n",
    "\n",
    "    test_input_stage1, test_input_stage2,  train_Y1, train_Y2, train_A1, train_A2 = train_test_tensors\n",
    "    val_input_stage1, val_input_stage2, val_Y1, val_Y2, val_A1, val_A2 = val_test_tensors\n",
    "\n",
    "\n",
    "    A1_tr, A2_tr = [tensor[:train_size] for tensor in [A1, A2] ] # actions from chosen policy\n",
    "    A1_val, A2_val = [tensor[train_size:] for tensor in [A1, A2]] # actions from chosen policy\n",
    "\n",
    "\n",
    "\n",
    "    # Duplicate the params dictionary\n",
    "    param_W = params.copy()\n",
    "\n",
    "    # Update specific values in param_W\n",
    "    param_W.update({\n",
    "          'num_networks': 1,\n",
    "          'input_dim_stage1': 6,\n",
    "          'output_dim_stage1': 1,\n",
    "          'input_dim_stage2': 8,\n",
    "          'output_dim_stage2': 1,\n",
    "      })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage2, optimizer_2, scheduler_2 = initialize_model_and_optimizer(param_W, 2)\n",
    "    train_losses_stage2, val_losses_stage2, epoch_num_model_2 = train_and_validate_W_estimator(nn_stage2, optimizer_2, scheduler_2, test_input_stage2, train_A2, train_Y2, val_input_stage2, val_A2, val_Y2, params['batch_size'], device, params['n_epoch'], 2, params['sample_size'], params)\n",
    "\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{2}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    nn_stage2.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "    nn_stage2.eval()\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2_tr.unsqueeze(-1)), dim=1)\n",
    "    test_tr_outputs_stage2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    train_Y1_hat = test_tr_outputs_stage2.squeeze(1) + train_Y1 # pseudo outcome\n",
    "\n",
    "\n",
    "    combined_inputs2val = torch.cat((val_input_stage2, A2_val.unsqueeze(-1)), dim=1)\n",
    "    test_val_outputs_stage2 = nn_stage2(combined_inputs2val)[0]  #compute_test_outputs(nn_stage2, val_input_stage2, A2_val, device, params, is_stage1=False)\n",
    "    val_Y1_hat = test_val_outputs_stage2.squeeze() + val_Y1 # pseudo outcome\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage1, optimizer_1, scheduler_1 = initialize_model_and_optimizer(param_W, 1)\n",
    "    train_losses_stage1, val_losses_stage1, epoch_num_model_1 = train_and_validate_W_estimator(nn_stage1, optimizer_1, scheduler_1, test_input_stage1, train_A1, train_Y1_hat, val_input_stage1, val_A1, val_Y1_hat, params['batch_size'], device, params['n_epoch'], 1, params['sample_size'], params)\n",
    "\n",
    "\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    model_filename = f\"best_model_stage_Q_{1}_{params['sample_size']}_W_estimator_{params['f_model']}.pt\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    nn_stage1.load_state_dict(torch.load(model_path, map_location=params['device']))\n",
    "\n",
    "\n",
    "\n",
    "    nn_stage1.eval()\n",
    "\n",
    "\n",
    "\n",
    "    [test_input_stage1, test_input_stage2, Y1_tensor, Y2_tensor, A1_tensor, A2_tensor] =   train_tens\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2.unsqueeze(-1)), dim=1)\n",
    "    Qhat2_H2d2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    combined_inputs1 = torch.cat((test_input_stage1, A1.unsqueeze(-1)), dim=1)\n",
    "    Qhat1_H1d1 = nn_stage1(combined_inputs1)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "\n",
    "\n",
    "    combined_inputs2 = torch.cat((test_input_stage2, A2_tensor.unsqueeze(-1)), dim=1)\n",
    "    Qhat2_H2A2 = nn_stage2(combined_inputs2)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "    combined_inputs1 = torch.cat((test_input_stage1, A1_tensor.unsqueeze(-1)), dim=1)\n",
    "    Qhat1_H1A1 = nn_stage1(combined_inputs1)[0]  #compute_test_outputs(nn_stage2, test_input_stage2, A2_tr, device, params, is_stage1=False)\n",
    "\n",
    "\n",
    "    V_replications_M1_pred = valFn_estimate(Qhat1_H1d1, Qhat2_H2d2, Qhat1_H1A1, Qhat2_H2A2, A1_tensor, A2_tensor, A1, A2, Y1_tensor, Y2_tensor , P_A1_given_H1_tensor, P_A2_given_H2_tensor)\n",
    "\n",
    "\n",
    "    return V_replications_M1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkRMVRENNO4J"
   },
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDPqJEGgNeSa"
   },
   "source": [
    "## Generate Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5AGXH8vfNfmG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Generate Data\n",
    "def generate_and_preprocess_data(params, replication_seed, run='train'):\n",
    "\n",
    "    # torch.manual_seed(replication_seed)\n",
    "    sample_size = params['sample_size']\n",
    "    device = params['device']\n",
    "\n",
    "    # Simulate baseline covariates\n",
    "    O1 = torch.randn(5, sample_size, device=device)\n",
    "    Z1 = torch.randn(sample_size, device=device)\n",
    "    Z2 = torch.randn(sample_size, device=device)\n",
    "\n",
    "    if params['noiseless']:\n",
    "        Z1.fill_(0)\n",
    "        Z2.fill_(0)\n",
    "\n",
    "    # Stage 1 data simulation\n",
    "        \n",
    "    # Input preparation\n",
    "    input_stage1 = O1.t()\n",
    "    \n",
    "    x1, x2, x3, x4, x5 = O1[0], O1[1], O1[2], O1[3], O1[4]\n",
    "    pi_10 = torch.ones(sample_size, device=device)\n",
    "    pi_11 = torch.exp(0.5 - 0.5 * x3)\n",
    "    pi_12 = torch.exp(0.5 * x4)\n",
    "    matrix_pi1 = torch.stack((pi_10, pi_11, pi_12), dim=0).t()\n",
    "\n",
    "    result1 = A_sim(matrix_pi1, stage=1)\n",
    "    \n",
    "    if  params['use_m_propen']:\n",
    "        A1, _ = result1['A'], result1['probs']\n",
    "        probs1 = M_propen(A1, input_stage1, stage=1)  # multinomial logistic regression with H1\n",
    "#         probs1 = M_propen(A1, O1[[2, 3]].t(), stage=1)  # multinomial logistic regression with X3, X4\n",
    "    else:         \n",
    "        A1, probs1 = result1['A'], result1['probs']\n",
    "\n",
    "    A1 += 1\n",
    "\n",
    "    g1_opt = ((x1 > -1).float() * ((x2 > -0.5).float() + (x2 > 0.5).float())) + 1\n",
    "    Y1 = torch.exp(1.5 - torch.abs(1.5 * x1 + 2) * (A1 - g1_opt).pow(2)) + Z1\n",
    "    \n",
    "    \n",
    "    # Input preparation\n",
    "    input_stage2 = torch.cat([O1.t(), A1.unsqueeze(1), Y1.unsqueeze(1)], dim=1)\n",
    "\n",
    "    # Stage 2 data simulation\n",
    "    pi_20 = torch.ones(sample_size, device=device)\n",
    "    pi_21 = torch.exp(0.2 * Y1 - 1)\n",
    "    pi_22 = torch.exp(0.5 * x4)\n",
    "    matrix_pi2 = torch.stack((pi_20, pi_21, pi_22), dim=0).t()\n",
    "    \n",
    "    result2 = A_sim(matrix_pi2, stage=2)\n",
    "    \n",
    "    \n",
    "    if  params['use_m_propen']:\n",
    "        A2, _ = result2['A'], result2['probs']\n",
    "        probs2 = M_propen(A2, input_stage2, stage=2)  # multinomial logistic regression with H2\n",
    "#         probs2 = M_propen(A2, O1[[0, 4]].t(), stage=2)  # multinomial logistic regression with X1, X5\n",
    "    else:         \n",
    "        A2, probs2 = result2['A'], result2['probs']\n",
    "        \n",
    "    A2 += 1\n",
    "\n",
    "    Y1_opt = torch.exp(torch.tensor(1.5, device=device)) + Z1\n",
    "    g2_opt = (x3 > -1).float() * ((Y1_opt > 0.5).float() + (Y1_opt > 3).float()) + 1\n",
    "\n",
    "    Y2 = torch.exp(1.26 - torch.abs(1.5 * x3 - 2) * (A2 - g2_opt).pow(2)) + Z2\n",
    "\n",
    "    if run != 'test':\n",
    "      # transform Y for direct search\n",
    "      Y1, Y2 = transform_Y(Y1, Y2)\n",
    "\n",
    "    # Propensity score stack\n",
    "    pi_tensor_stack = torch.stack([probs1['pi_10'], probs1['pi_11'], probs1['pi_12'], probs2['pi_20'], probs2['pi_21'], probs2['pi_22']])\n",
    "\n",
    "    # Adjusting A1 and A2 indices\n",
    "    A1_indices = (A1 - 1).long().unsqueeze(0)  # A1 actions, Subtract 1 to match index values (0, 1, 2)\n",
    "    A2_indices = (A2 - 1 + 3).long().unsqueeze(0)   # A2 actions, Add +3 to match index values (3, 4, 5) for A2, with added dimension\n",
    "\n",
    "    # Gathering probabilities based on actions\n",
    "    P_A1_given_H1_tensor = torch.gather(pi_tensor_stack, dim=0, index=A1_indices).squeeze(0)  # Remove the added dimension after gathering\n",
    "    P_A2_given_H2_tensor = torch.gather(pi_tensor_stack, dim=0, index=A2_indices).squeeze(0)  # Remove the added dimension after gathering\n",
    "\n",
    "    # Calculate Ci tensor\n",
    "    Ci = (Y1 + Y2) / (P_A1_given_H1_tensor * P_A2_given_H2_tensor)\n",
    "\n",
    "    if run == 'test':\n",
    "        return input_stage1, input_stage2, Ci, Y1, Y2, A1, A2, P_A1_given_H1_tensor, P_A2_given_H2_tensor, g1_opt, g2_opt, Z1, Z2\n",
    "\n",
    "    # Splitting data into training and validation sets\n",
    "    train_size = int(params['training_validation_prop'] * sample_size)\n",
    "    train_tensors = [tensor[:train_size] for tensor in [input_stage1, input_stage2, Ci, Y1, Y2, A1, A2]]\n",
    "    val_tensors = [tensor[train_size:] for tensor in [input_stage1, input_stage2, Ci, Y1, Y2, A1, A2]]\n",
    "\n",
    "    return tuple(train_tensors), tuple(val_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxsHyCXuNkC4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVg1IOCmNjS2"
   },
   "source": [
    "## surrogate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "69HE80wwNnx1"
   },
   "outputs": [],
   "source": [
    "def surr_opt(tuple_train, tuple_val, params):\n",
    "\n",
    "    sample_size = params['sample_size']\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss, best_model_stage1_params, best_model_stage2_params, epoch_num_model = float('inf'), None, None, 0\n",
    "\n",
    "    nn_stage1 = initialize_and_prepare_model(1, params, sample_size)\n",
    "    nn_stage2 = initialize_and_prepare_model(2, params, sample_size)\n",
    "\n",
    "    optimizer, scheduler = initialize_optimizer_and_scheduler(nn_stage1, nn_stage2, params)\n",
    "\n",
    "    #  Training and Validation data\n",
    "    train_data = {'input1': tuple_train[0], 'input2': tuple_train[1], 'Ci': tuple_train[2], 'A1': tuple_train[5], 'A2': tuple_train[6]}\n",
    "    val_data = {'input1': tuple_val[0], 'input2': tuple_val[1], 'Ci': tuple_val[2], 'A1': tuple_val[5], 'A2': tuple_val[6]}\n",
    "\n",
    "\n",
    "    # Training and Validation loop for both stages\n",
    "    for epoch in range(params['n_epoch']):\n",
    "\n",
    "        train_loss = process_batches(nn_stage1, nn_stage2, train_data, params, optimizer, is_train=True)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = process_batches(nn_stage1, nn_stage2, val_data, params, optimizer, is_train=False)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            epoch_num_model = epoch\n",
    "            best_val_loss = val_loss\n",
    "            best_model_stage1_params = nn_stage1.state_dict()\n",
    "            best_model_stage2_params = nn_stage2.state_dict()\n",
    "\n",
    "        # Update the scheduler with the current epoch's validation loss\n",
    "        update_scheduler(scheduler, params, val_loss)\n",
    "\n",
    "    model_dir = f\"models/{params['job_id']}\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Define file paths for saving models\n",
    "    model_path_stage1 = os.path.join(model_dir, f'best_model_stage_surr_1_{sample_size}.pt')\n",
    "    model_path_stage2 = os.path.join(model_dir, f'best_model_stage_surr_2_{sample_size}.pt')\n",
    "\n",
    "    # Save the models\n",
    "    torch.save(best_model_stage1_params, model_path_stage1)\n",
    "    torch.save(best_model_stage2_params, model_path_stage2)\n",
    "\n",
    "    return (nn_stage1, nn_stage2, (train_losses, val_losses), epoch_num_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36KmGLjvNrln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH_L_V5oNsWI"
   },
   "source": [
    "## DQL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9DFOx69PNrp2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def DQlearning(tuple_train, tuple_val, params):\n",
    "    train_input_stage1, train_input_stage2, _, train_Y1, train_Y2, train_A1, train_A2 = tuple_train\n",
    "    val_input_stage1, val_input_stage2, _, val_Y1, val_Y2, val_A1, val_A2 = tuple_val\n",
    "\n",
    "\n",
    "    nn_stage1, optimizer_1, scheduler_1 = initialize_model_and_optimizer(params, 1)\n",
    "    nn_stage2, optimizer_2, scheduler_2 = initialize_model_and_optimizer(params, 2)\n",
    "\n",
    "    train_losses_stage2, val_losses_stage2, epoch_num_model_2 = train_and_validate(nn_stage2, optimizer_2, scheduler_2, train_input_stage2, train_A2, train_Y2,\n",
    "                                                                                   val_input_stage2, val_A2, val_Y2, params, 2)\n",
    "    # params['batch_size'], device, params['n_epoch'], 2, params['sample_size'], params)\n",
    "\n",
    "    train_Y1_hat = evaluate_model_on_actions(nn_stage2, train_input_stage2, train_A2) + train_Y1\n",
    "    val_Y1_hat = evaluate_model_on_actions(nn_stage2, val_input_stage2, val_A2) + val_Y1\n",
    "\n",
    "    train_losses_stage1, val_losses_stage1, epoch_num_model_1 = train_and_validate(nn_stage1, optimizer_1, scheduler_1, train_input_stage1, train_A1, train_Y1_hat,\n",
    "                                                                                   val_input_stage1, val_A1, val_Y1_hat, params, 1)\n",
    "\n",
    "    return (nn_stage1, nn_stage2, (train_losses_stage1, train_losses_stage2, val_losses_stage1, val_losses_stage2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67Iadt7cNrsq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioq4ivMDNw3E"
   },
   "source": [
    "## Evaluation DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5g24tFFdNruR"
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_DTR(V_replications, num_replications, nn_stage1, nn_stage2, df, params):\n",
    "\n",
    "    # Generate and preprocess data for evaluation\n",
    "    processed_result = generate_and_preprocess_data(params, replication_seed=num_replications, run='test')\n",
    "    test_input_stage1, test_input_stage2, Ci_tensor, Y1_tensor, Y2_tensor, A1_tensor_test, A2_tensor_test, P_A1_g_H1, P_A2_g_H2, d1_star, d2_star, Z1, Z2  = processed_result\n",
    "\n",
    "    nn_stage1 = initialize_and_load_model(1, params['sample_size'] , params)\n",
    "    nn_stage2 = initialize_and_load_model(2, params['sample_size'] , params)\n",
    "\n",
    "    # Calculate test outputs for all networks in stage 1\n",
    "    A1, test_outputs_stage1 = compute_test_outputs(nn = nn_stage1, test_input = test_input_stage1, A_tensor = A1_tensor_test, params=params, is_stage1=True)\n",
    "    test_input_stage2, Y1_pred = prepare_stage2_test_input(O1_tensor_test = test_input_stage1 , A1 = A1,\n",
    "                                                           g1_opt_conditions = d1_star, Z1_tensor_test = Z1)\n",
    "\n",
    "    # Calculate test outputs for all networks in stage 2\n",
    "    A2, test_outputs_stage2 = compute_test_outputs(nn = nn_stage2, test_input = test_input_stage2, A_tensor = A2_tensor_test, params=params, is_stage1=False)\n",
    "    Y2_pred =  prepare_Y2_pred(O1_tensor_test = test_input_stage1, A1 = A1, A2 = A2, g2_opt_conditions = d2_star,\n",
    "                               Z1_tensor_test = Z1, Z2_tensor_test = Z2)\n",
    "\n",
    "\n",
    "    # Append to DataFrame\n",
    "    new_row = {\n",
    "        'Behavioral_A1': A1_tensor_test.cpu().numpy().tolist(),\n",
    "        'Behavioral_A2': A2_tensor_test.cpu().numpy().tolist(),\n",
    "        'Predicted_A1': A1.cpu().numpy().tolist(),\n",
    "        'Predicted_A2':  A2.cpu().numpy().tolist(),\n",
    "        'Optimal_A1': d1_star.cpu().numpy().tolist(),\n",
    "        'Optimal_A2': d2_star.cpu().numpy().tolist()\n",
    "        }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "    message = f'\\nY1_pred mean: {torch.mean(Y1_pred)}, Y2_pred mean:  {torch.mean(Y2_pred)}, Y1_pred+Y2_pred mean: {torch.mean(Y1_pred + Y2_pred)} \\n'\n",
    "    print(message)\n",
    "\n",
    "    V_replications = calculate_policy_values(Y1_tensor=Y1_tensor, Y2_tensor=Y2_tensor,\n",
    "                                             d1_star=d1_star, d2_star=d2_star,\n",
    "                                             Y1_pred=Y1_pred, Y2_pred=Y2_pred,\n",
    "                                             V_replications=V_replications,\n",
    "                                             Z1_tensor_test=Z1, Z2_tensor_test=Z2)\n",
    "\n",
    "    # Calculate policy values using the W estimator for DQL\n",
    "    train_tensors = [test_input_stage1, test_input_stage2, Y1_tensor, Y2_tensor, A1_tensor_test, A2_tensor_test]\n",
    "\n",
    "    V_replications_estimator = calculate_policy_values_W_estimator(train_tensors, params, A1, A2, P_A1_g_H1, P_A2_g_H2)\n",
    "\n",
    "    print(\"Estimated value fn.: \", V_replications_estimator)\n",
    "\n",
    "    V_replications[\"V_replications_estimator\"].append(V_replications_estimator)\n",
    "\n",
    "    return V_replications, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FojOCzJN20Z"
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "q1YeA669Nn0s"
   },
   "outputs": [],
   "source": [
    "\n",
    "def simulations( V_replications, params):\n",
    "    columns = ['Behavioral_A1', 'Behavioral_A2', 'Predicted_A1', 'Predicted_A2', 'Optimal_A1', 'Optimal_A2']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    losses_dict = {}\n",
    "    epoch_num_model_lst = []\n",
    "\n",
    "    for replication in tqdm(range(params['num_replications']), desc=\"Replications_M1\"):\n",
    "        print(f\"Replication # -------------->>>>>  {replication+1}\")\n",
    "\n",
    "        # Generate and preprocess data for training\n",
    "        tuple_train, tuple_val = generate_and_preprocess_data(params, replication_seed=replication, run='train')\n",
    "\n",
    "        # Estimate treatment regime : model --> surr_opt\n",
    "        print(\"Training started!\")\n",
    "        if params['f_model'] == 'DQlearning':\n",
    "            nn_stage1, nn_stage2, trn_val_loss_tpl = DQlearning(tuple_train, tuple_val, params)\n",
    "        else:\n",
    "            nn_stage1, nn_stage2, trn_val_loss_tpl, epoch_num_model = surr_opt(tuple_train, tuple_val, params)\n",
    "            epoch_num_model_lst.append(epoch_num_model)\n",
    "\n",
    "        losses_dict[replication] = trn_val_loss_tpl\n",
    "\n",
    "        # eval_DTR\n",
    "        print(\"Evaluation started\")\n",
    "        V_replications, df = eval_DTR(V_replications, replication, nn_stage1, nn_stage2, df, params)\n",
    "\n",
    "    return V_replications, df, losses_dict, epoch_num_model_lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVSOOddJOBWW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTmbj9n_OF2l"
   },
   "source": [
    "# Change input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d391c23f4ca94548b4096e524e45007c",
      "70b096ad51dc490fa5b8e618e7d8694c",
      "793bf2a6285d43178a6f96762a9f9c42",
      "07ae5da6304040b3b623bccab6987fbb",
      "98ffd24a57774ceda9f2e49c356a48a4",
      "30bd93bc900a453f977c7b45e54a64e8",
      "35c0860a48fd47148273906eaf920dd4",
      "efafddbf1d724b539fffd04270ee828a",
      "f9169dc77b4c43fc8c55da01d38dd2a1",
      "e0b74f94741b460782b03302a3628d3f",
      "869dc90565954dfe85024370feaf437c"
     ]
    },
    "id": "9XBaDKo6O15S",
    "outputId": "e21e963e-ff7e-4e53-b415-e112d7efb643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: %s surr_opt\n",
      "Training size: %d 21000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69420b9683d9444ab38f9467dff7d686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Replications_M1:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication # -------------->>>>>  1\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2473602294921875, Y2_pred mean:  3.4044649600982666, Y1_pred+Y2_pred mean: 7.651824951171875 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.6410582065582275\n",
      "Replication # -------------->>>>>  2\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.226613998413086, Y2_pred mean:  3.3358755111694336, Y1_pred+Y2_pred mean: 7.5624895095825195 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.562584578990936\n",
      "Replication # -------------->>>>>  3\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.245573997497559, Y2_pred mean:  3.4527976512908936, Y1_pred+Y2_pred mean: 7.6983723640441895 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.684737801551819\n",
      "Replication # -------------->>>>>  4\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.27096700668335, Y2_pred mean:  3.479825973510742, Y1_pred+Y2_pred mean: 7.750793933868408 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.755498230457306\n",
      "Replication # -------------->>>>>  5\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.223992824554443, Y2_pred mean:  3.414018154144287, Y1_pred+Y2_pred mean: 7.638010501861572 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.647504925727844\n",
      "Replication # -------------->>>>>  6\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.189569473266602, Y2_pred mean:  3.422008752822876, Y1_pred+Y2_pred mean: 7.611578464508057 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.633141398429871\n",
      "Replication # -------------->>>>>  7\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.200562953948975, Y2_pred mean:  3.429295063018799, Y1_pred+Y2_pred mean: 7.629857063293457 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.630442142486572\n",
      "Replication # -------------->>>>>  8\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.245336055755615, Y2_pred mean:  3.392395496368408, Y1_pred+Y2_pred mean: 7.637731552124023 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.634184777736664\n",
      "Replication # -------------->>>>>  9\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.280675888061523, Y2_pred mean:  3.463609218597412, Y1_pred+Y2_pred mean: 7.744284152984619 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.714458584785461\n",
      "Replication # -------------->>>>>  10\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.146359443664551, Y2_pred mean:  3.3967437744140625, Y1_pred+Y2_pred mean: 7.543103218078613 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.512758493423462\n",
      "Replication # -------------->>>>>  11\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2555084228515625, Y2_pred mean:  3.408142566680908, Y1_pred+Y2_pred mean: 7.663651466369629 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.677317976951599\n",
      "Replication # -------------->>>>>  12\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2724504470825195, Y2_pred mean:  3.4567933082580566, Y1_pred+Y2_pred mean: 7.729243755340576 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.694334506988525\n",
      "Replication # -------------->>>>>  13\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.237359523773193, Y2_pred mean:  3.4244771003723145, Y1_pred+Y2_pred mean: 7.661835193634033 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.680536389350891\n",
      "Replication # -------------->>>>>  14\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.223491668701172, Y2_pred mean:  3.4805312156677246, Y1_pred+Y2_pred mean: 7.704023361206055 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.704749822616577\n",
      "Replication # -------------->>>>>  15\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.1457133293151855, Y2_pred mean:  3.3747689723968506, Y1_pred+Y2_pred mean: 7.520482063293457 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.514425158500671\n",
      "Replication # -------------->>>>>  16\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.1934332847595215, Y2_pred mean:  3.461611270904541, Y1_pred+Y2_pred mean: 7.6550445556640625 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.642950892448425\n",
      "Replication # -------------->>>>>  17\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.295355796813965, Y2_pred mean:  3.4462172985076904, Y1_pred+Y2_pred mean: 7.741572856903076 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.7564502358436584\n",
      "Replication # -------------->>>>>  18\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.16284704208374, Y2_pred mean:  3.461846113204956, Y1_pred+Y2_pred mean: 7.624693393707275 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.6264984011650085\n",
      "Replication # -------------->>>>>  19\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.229102611541748, Y2_pred mean:  3.4188363552093506, Y1_pred+Y2_pred mean: 7.647939205169678 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.639127731323242\n",
      "Replication # -------------->>>>>  20\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.193326473236084, Y2_pred mean:  3.3665428161621094, Y1_pred+Y2_pred mean: 7.559868335723877 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.5781766176223755\n",
      "Replication # -------------->>>>>  21\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.281644344329834, Y2_pred mean:  3.417426109313965, Y1_pred+Y2_pred mean: 7.699070453643799 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.687554717063904\n",
      "Replication # -------------->>>>>  22\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.248987674713135, Y2_pred mean:  3.4181313514709473, Y1_pred+Y2_pred mean: 7.667118072509766 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.661347985267639\n",
      "Replication # -------------->>>>>  23\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.275981426239014, Y2_pred mean:  3.4386959075927734, Y1_pred+Y2_pred mean: 7.7146782875061035 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.7030287981033325\n",
      "Replication # -------------->>>>>  24\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.169393062591553, Y2_pred mean:  3.4667000770568848, Y1_pred+Y2_pred mean: 7.6360931396484375 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.63389778137207\n",
      "Replication # -------------->>>>>  25\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2371978759765625, Y2_pred mean:  3.4845266342163086, Y1_pred+Y2_pred mean: 7.721724033355713 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value fn.:  7.714104235172272\n",
      "Replication # -------------->>>>>  26\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2588324546813965, Y2_pred mean:  3.4170737266540527, Y1_pred+Y2_pred mean: 7.675906181335449 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.662873148918152\n",
      "Replication # -------------->>>>>  27\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.2473578453063965, Y2_pred mean:  3.373669385910034, Y1_pred+Y2_pred mean: 7.621026992797852 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.635958194732666\n",
      "Replication # -------------->>>>>  28\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.309640884399414, Y2_pred mean:  3.419541597366333, Y1_pred+Y2_pred mean: 7.729182720184326 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.7262672781944275\n",
      "Replication # -------------->>>>>  29\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.107420921325684, Y2_pred mean:  3.421773910522461, Y1_pred+Y2_pred mean: 7.529195308685303 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.543217301368713\n",
      "Replication # -------------->>>>>  30\n",
      "Training started!\n",
      "Evaluation started\n",
      "\n",
      "Y1_pred mean: 4.210111618041992, Y2_pred mean:  3.3868727684020996, Y1_pred+Y2_pred mean: 7.596983909606934 \n",
      "\n",
      "\n",
      "Y1_opt mean: 4.481688022613525, Y2_opt mean: 3.525421142578125, Y1_opt+Y2_opt mean: 8.007109642028809 \n",
      "\n",
      "\n",
      "Estimated value fn.:  7.589106440544128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup_logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration and set up the device\n",
    "#config = load_config()\n",
    "\n",
    "config = {\"f_model\": \"surr_opt\", # DQlearning, surr_opt\n",
    "          \"setting\": \"tao\",\n",
    "          \"surrogate_num\": 1,\n",
    "          \"option_sur\": 4,\n",
    "          \"device\": None,\n",
    "          \"noiseless\": True,\n",
    "          \n",
    "          \"sample_size\": 30000,\n",
    "          \"num_replications\": 30,\n",
    "          \"job_id\": \"tao\",\n",
    "          \"training_validation_prop\": 0.7,\n",
    "          \"use_m_propen\": True, # True, False\n",
    "          \n",
    "          \"n_epoch\": 60,\n",
    "          \"batch_size\": 7000,\n",
    "          \"num_networks\": 2,\n",
    "          \"activation_function\": \"relu\",\n",
    "          \"input_dim_stage1\": 5,\n",
    "          \"output_dim_stage1\": 1,\n",
    "          \"input_dim_stage2\": 7,\n",
    "          \"output_dim_stage2\": 1,\n",
    "          \"hidden_dim_stage1\": 20,\n",
    "          \"hidden_dim_stage2\": 20,\n",
    "          \"dropout_rate\": 0.4,\n",
    "          \"num_layers\": 2,\n",
    "          \n",
    "          \"optimizer_type\": \"adam\",\n",
    "          \"optimizer_lr\": 0.07,\n",
    "          \"optimizer_weight_decay\": 0.001,\n",
    "          \n",
    "          \"use_scheduler\": True,\n",
    "          \"scheduler_type\": \"reducelronplateau\",\n",
    "          \"scheduler_step_size\": 30,\n",
    "          \"scheduler_gamma\": 0.8,\n",
    "          \"initializer\": \"he\"\n",
    "          }\n",
    "\n",
    "\n",
    "print(\"Model used: %s\", config['f_model'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config['device'] = device\n",
    "\n",
    "# Get the SLURM_JOB_ID from environment variables\n",
    "job_id = os.getenv('SLURM_JOB_ID')\n",
    "\n",
    "# If job_id is None, set it to the current date and time formatted as a string\n",
    "if job_id is None:\n",
    "    job_id = datetime.now().strftime('%Y%m%d%H%M%S')  # Format: YYYYMMDDHHMMSS\n",
    "\n",
    "config['job_id'] = job_id\n",
    "\n",
    "training_validation_prop = config['training_validation_prop']\n",
    "train_size = int(training_validation_prop * config['sample_size'])\n",
    "print(\"Training size: %d\", train_size)\n",
    "\n",
    "if config['f_model'] != 'surr_opt':\n",
    "    config['input_dim_stage1'] = 6\n",
    "    config['input_dim_stage2'] = 8\n",
    "    config['num_networks'] = 1\n",
    "\n",
    "V_replications = {\n",
    "    \"V_replications_M1_pred\": [],\n",
    "    \"V_replications_M1_behavioral\": [],\n",
    "    \"V_replications_M1_optimal\": [],\n",
    "    \"V_replications_estimator\": []\n",
    "    }\n",
    "\n",
    "V_replications, df, losses_dict, epoch_num_model_lst = simulations( V_replications, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11EFbOC1b8V0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrrQksdhkZ-k"
   },
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze_TrBppYztl",
    "outputId": "a3f058fd-2692-4442-fdd1-114f46deee8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.6410582065582275,\n",
      " 7.562584578990936,\n",
      " 7.684737801551819,\n",
      " 7.755498230457306,\n",
      " 7.647504925727844,\n",
      " 7.633141398429871,\n",
      " 7.630442142486572,\n",
      " 7.634184777736664,\n",
      " 7.714458584785461,\n",
      " 7.512758493423462,\n",
      " 7.677317976951599,\n",
      " 7.694334506988525,\n",
      " 7.680536389350891,\n",
      " 7.704749822616577,\n",
      " 7.514425158500671,\n",
      " 7.642950892448425,\n",
      " 7.7564502358436584,\n",
      " 7.6264984011650085,\n",
      " 7.639127731323242,\n",
      " 7.5781766176223755,\n",
      " 7.687554717063904,\n",
      " 7.661347985267639,\n",
      " 7.7030287981033325,\n",
      " 7.63389778137207,\n",
      " 7.714104235172272,\n",
      " 7.662873148918152,\n",
      " 7.635958194732666,\n",
      " 7.7262672781944275,\n",
      " 7.543217301368713,\n",
      " 7.589106440544128]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(V_replications[\"V_replications_estimator\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GBmljhZ-jNWB"
   },
   "outputs": [],
   "source": [
    "# Average bias for the estimator: 0.038064698378245033\n",
    "# Standard Deviation for the estimator: 0.018973056376149027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "3fAYECnwaLly",
    "outputId": "48ae69aa-19bb-4884-ab2c-49ca97deb2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bias for the estimator: 0.011534863710403442\n",
      "Standard Deviation for the estimator: 0.008777427701588417\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias = np.abs( np.array(V_replications[\"V_replications_estimator\"]) -   np.array(V_replications[\"V_replications_M1_pred\"]))\n",
    "\n",
    "num_replications = config[\"num_replications\"]\n",
    "\n",
    "avg_V_bias = np.mean(bias)\n",
    "std_dev_bias = np.std(bias)\n",
    "print(f\"Average bias for the estimator: {np.mean(avg_V_bias)}\")\n",
    "print(f\"Standard Deviation for the estimator: {std_dev_bias}\\n\\n\")\n",
    "\n",
    "plt.plot(range(1, num_replications + 1), bias, 'o-')\n",
    "plt.xlabel(f'Replications')\n",
    "plt.ylabel('Value fn. bias Value')\n",
    "plt.title(f'V bias values for {num_replications} Test Replications (Training Sample Size: {training_validation_prop*config[\"sample_size\"]})')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Overall Accuracy for Behavioral A1: 0.3293466666666667\n",
      "Overall Accuracy for Behavioral A2: 0.39198777777777777\n",
      "\n",
      "\n",
      "Overall Accuracy for Predicted A1: 0.9115022222222222\n",
      "Overall Accuracy for Predicted A2: 0.9713711111111111\n",
      "\n",
      "\n",
      "    Accuracy_A1  Accuracy_A2  Value function  Optimal Value function\n",
      "0      0.917067     0.965667        7.651825                 8.00711\n",
      "1      0.908733     0.946233        7.562490                 8.00711\n",
      "2      0.931600     0.979400        7.698372                 8.00711\n",
      "3      0.934200     0.987067        7.750794                 8.00711\n",
      "4      0.919733     0.968400        7.638011                 8.00711\n",
      "5      0.916367     0.970667        7.611578                 8.00711\n",
      "6      0.914800     0.972733        7.629857                 8.00711\n",
      "7      0.909500     0.962267        7.637732                 8.00711\n",
      "8      0.916300     0.982467        7.744284                 8.00711\n",
      "9      0.892967     0.963500        7.543103                 8.00711\n",
      "10     0.916933     0.966733        7.663651                 8.00711\n",
      "11     0.938500     0.980533        7.729244                 8.00711\n",
      "12     0.912800     0.971367        7.661835                 8.00711\n",
      "13     0.897533     0.987267        7.704023                 8.00711\n",
      "14     0.878200     0.957267        7.520482                 8.00711\n",
      "15     0.894500     0.981900        7.655045                 8.00711\n",
      "16     0.937967     0.977533        7.741573                 8.00711\n",
      "17     0.885000     0.981967        7.624693                 8.00711\n",
      "18     0.909533     0.969767        7.647939                 8.00711\n",
      "19     0.892100     0.954933        7.559868                 8.00711\n",
      "20     0.924833     0.969367        7.699070                 8.00711\n",
      "21     0.923633     0.969567        7.667118                 8.00711\n",
      "22     0.923800     0.975400        7.714678                 8.00711\n",
      "23     0.884733     0.983333        7.636093                 8.00711\n",
      "24     0.915700     0.988400        7.721724                 8.00711\n",
      "25     0.909033     0.969267        7.675906                 8.00711\n",
      "26     0.925500     0.956867        7.621027                 8.00711\n",
      "27     0.941200     0.969967        7.729183                 8.00711\n",
      "28     0.856000     0.970600        7.529195                 8.00711\n",
      "29     0.916300     0.960700        7.596984                 8.00711\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_df = calculate_accuracies(df, V_replications)\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc3tG6scO4kM"
   },
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "392.977px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ae5da6304040b3b623bccab6987fbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b74f94741b460782b03302a3628d3f",
      "placeholder": "",
      "style": "IPY_MODEL_869dc90565954dfe85024370feaf437c",
      "value": "30/30[12:50&lt;00:00,25.67s/it]"
     }
    },
    "30bd93bc900a453f977c7b45e54a64e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35c0860a48fd47148273906eaf920dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70b096ad51dc490fa5b8e618e7d8694c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30bd93bc900a453f977c7b45e54a64e8",
      "placeholder": "",
      "style": "IPY_MODEL_35c0860a48fd47148273906eaf920dd4",
      "value": "Replications_M1:100%"
     }
    },
    "793bf2a6285d43178a6f96762a9f9c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efafddbf1d724b539fffd04270ee828a",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9169dc77b4c43fc8c55da01d38dd2a1",
      "value": 30
     }
    },
    "869dc90565954dfe85024370feaf437c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98ffd24a57774ceda9f2e49c356a48a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d391c23f4ca94548b4096e524e45007c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70b096ad51dc490fa5b8e618e7d8694c",
       "IPY_MODEL_793bf2a6285d43178a6f96762a9f9c42",
       "IPY_MODEL_07ae5da6304040b3b623bccab6987fbb"
      ],
      "layout": "IPY_MODEL_98ffd24a57774ceda9f2e49c356a48a4"
     }
    },
    "e0b74f94741b460782b03302a3628d3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efafddbf1d724b539fffd04270ee828a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9169dc77b4c43fc8c55da01d38dd2a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
